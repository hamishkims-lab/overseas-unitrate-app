import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

# =========================
# UI Labels / Constants
# =========================
LABEL_SIM_THRESHOLD = "ë§¤ì¹­ ìœ ì‚¬ë„ ê¸°ì¤€ê°’(%)"
LABEL_CUT_RATIO     = "ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)"
LABEL_TARGET_CURR   = "ì‚°ì¶œí†µí™”"

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

# =========================
# Session Init (ì•ˆì „ì¥ì¹˜)
# =========================
def init_session():
    defaults = {
        "selected_feature_ids": [],
        "auto_sites": [],
        "selected_auto_codes": [],
        "selected_extra_codes": [],
        "has_results": False,

        "candidate_pool": None,
        "candidate_pool_sig": None,
        "last_run_sig": None,

        "boq_df": None,
        "result_df_base": None,
        "log_df_base": None,
        "log_df_edited": None,
        "result_df_adjusted": None,

        "ai_last_applied": None,
        "_include_backup": {},
        "_include_backup_all": None,

        "report_summary_df": pd.DataFrame(),
        "report_detail_df": pd.DataFrame(),
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

init_session()

st.markdown("""
<style>
  /* ì „ì²´ ë°°ê²½ */
  .main { background-color: #F6FAFC; }

  /* ====== ì‚¬ì´ë“œë°”ì—ì„œë§Œ ê°•ì œ ì ìš©(ìš°ì„ ìˆœìœ„ â†‘) ====== */
  section[data-testid="stSidebar"] div[data-baseweb="select"] > div{
    background-color: #ffffff !important;
    border: 1px solid #005EB8 !important;
    border-radius: 6px !important;
  }

  /* âœ… ì‚°ì¶œí†µí™”(Selectbox) ì„ íƒ í…ìŠ¤íŠ¸ë¥¼ ê²€ì •ìœ¼ë¡œ ê°•ì œ */
  section[data-testid="stSidebar"] div[data-baseweb="select"] input{
    color:#000000 !important;
    -webkit-text-fill-color:#000000 !important;
    caret-color:#000000 !important;
  }

  /* âœ… placeholder/ë¹„í™œì„± í…ìŠ¤íŠ¸ë„ ê²€ì • ê³„ì—´ë¡œ */
  section[data-testid="stSidebar"] div[data-baseweb="select"] input::placeholder{
    color:#000000 !important;
    -webkit-text-fill-color:#000000 !important;
    opacity: 0.7 !important;
  }

  /* âœ… tag(ì¹©) ìì²´ëŠ” í•œ ì¤„ ê½‰ ì°¨ê²Œ. Xê°€ ì˜ë¦¬ì§€ ì•Šê²Œ */
section[data-testid="stSidebar"] div[data-baseweb="tag"],
section[data-testid="stSidebar"] span[data-baseweb="tag"]{
  width: 100% !important;
  max-width: 100% !important;
  overflow: visible !important;

  display: inline-flex !important;
  align-items: center !important;
  gap: 8px !important;

  background-color:#4DA3FF !important;
  border:1px solid #2F80ED !important;
  color:#ffffff !important;

  padding: 0 10px !important;
  box-sizing: border-box !important;

  height: 30px !important;
  min-height: 30px !important;
}

section[data-testid="stSidebar"] div[data-baseweb="tag"] > span:first-child,
section[data-testid="stSidebar"] span[data-baseweb="tag"] > span:first-child{
  flex: 1 1 auto !important;
  min-width: 0 !important;
  overflow: hidden !important;
  text-overflow: ellipsis !important;
  white-space: nowrap !important;

  font-size: 12px !important;
  line-height: 1 !important;
  color:#ffffff !important;
}

section[data-testid="stSidebar"] div[data-baseweb="tag"] > span:last-child,
section[data-testid="stSidebar"] span[data-baseweb="tag"] > span:last-child{
  flex: 0 0 26px !important;
  width: 26px !important;
  min-width: 26px !important;

  display: inline-flex !important;
  align-items: center !important;
  justify-content: center !important;
}

section[data-testid="stSidebar"] div[data-baseweb="tag"] svg,
section[data-testid="stSidebar"] span[data-baseweb="tag"] svg,
section[data-testid="stSidebar"] div[data-baseweb="tag"] path,
section[data-testid="stSidebar"] span[data-baseweb="tag"] path{
  fill:#ffffff !important;
}

/* âœ… (ë‹«íŒ ìƒíƒœ) ì„ íƒëœ ê°’/ì•„ì´ì½˜ ê²€ì • */
section[data-testid="stSidebar"] div[data-baseweb="select"] > div *{
  color:#000000 !important;
  -webkit-text-fill-color:#000000 !important;
}
section[data-testid="stSidebar"] div[data-baseweb="select"] svg,
section[data-testid="stSidebar"] div[data-baseweb="select"] svg path{
  fill:#000000 !important;
}
</style>
""", unsafe_allow_html=True)

def sidebar_hr(thick: bool = False, mt: int = 6, mb: int = 6):
    color = "#D9DDE3"
    h = "3px" if thick else "1px"
    st.sidebar.markdown(
        f"<hr style='margin:{mt}px 0 {mb}px 0; border:none; border-top:{h} solid {color};' />",
        unsafe_allow_html=True
    )

st.markdown("<div class='gs-header'>ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB</div>", unsafe_allow_html=True)
st.write("")

# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()

# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None

def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()

def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode()); hasher.update(tail.encode())
    return hasher.hexdigest()

def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s

# =========================
# ë³´ì • ë¡œì§
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now  = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None

def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        usd_to   = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0

def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(from_currency).upper(), "ì§€ìˆ˜"].values
        f_to   = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(to_currency).upper(), "ì§€ìˆ˜"].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0

# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"

def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))

def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs

# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index

def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I

# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0

# (ì´í•˜ build_candidate_pool / fast_recompute_from_pool / ì—ì´ì „íŠ¸ / ë³´ê³ ì„œ / ê·¸ë˜í”„ í•¨ìˆ˜ë“¤ì€
#   ì‚¬ìš©ìê°€ ì£¼ì‹  ì›ë¬¸ ê·¸ëŒ€ë¡œì—¬ë„ ë¬´ë°©í•˜ë¯€ë¡œ ìƒëµ ì—†ì´ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì‹œë©´ ë©ë‹ˆë‹¤.)
# -------------------------------------------------------------------
# ì—¬ê¸°ë¶€í„°ëŠ” ì‚¬ìš©ìê°€ ì£¼ì‹  ì›ë¬¸ í•¨ìˆ˜ë“¤ì„ ê·¸ëŒ€ë¡œ ë‘ì…”ë„ ë˜ê³ ,
# ì´ë¯¸ ë¶™ì—¬ì£¼ì‹  ì½”ë“œ ê·¸ëŒ€ë¡œ ì´ì–´ë¶™ì´ì…”ë„ ë©ë‹ˆë‹¤.
# -------------------------------------------------------------------


# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")

cost_db     = load_excel_from_repo("cost_db.xlsx")
price_index = load_excel_from_repo("price_index.xlsx")
exchange    = load_excel_from_repo("exchange.xlsx")
factor      = load_excel_from_repo("Factor.xlsx")
project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
feature_master = load_excel_from_repo("feature_master_FID.xlsx")

# =========================
# âœ… ì»¬ëŸ¼ëª… í‘œì¤€í™” + alias ë§¤í•‘ (KeyError ë°©ì§€)
# =========================
def _std_colname(s: str) -> str:
    s = str(s)
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [_std_colname(c) for c in df.columns]
    return df

def apply_feature_column_alias(df: pd.DataFrame) -> pd.DataFrame:
    """
    feature_master_FID / project_feature_long ì»¬ëŸ¼ì´ ì¡°ê¸ˆ ë‹¬ë¼ë„
    ì•„ë˜ 'í‘œì¤€ ì»¬ëŸ¼ëª…'ìœ¼ë¡œ ê°•ì œ ë§ì¶¤
    """
    df = df.copy()
    col_map = {}

    aliases = {
        "íŠ¹ì„±ID": ["íŠ¹ì„±ID", "íŠ¹ì„± Id", "FeatureID", "Feature Id", "FID"],
        "ëŒ€ê³µì¢…": ["ëŒ€ê³µì¢…", "ëŒ€ ê³µì¢…", "Major", "Main"],
        "ì¤‘ê³µì¢…": ["ì¤‘ê³µì¢…", "ì¤‘ ê³µì¢…", "Middle"],
        "ì†Œê³µì¢…": ["ì†Œê³µì¢…", "ì†Œ ê³µì¢…", "Minor", "Sub"],

        "Cost Driver Type": [
            "Cost Driver Type", "CostDriver Type", "Cost DriverType",
            "Cost Driver_Type", "CostDriver_Type", "Type", "Driver Type"
        ],
        "Cost Driver Method": [
            "Cost Driver Method", "CostDriver Method", "Cost DriverMethod",
            "Cost Driver_Method", "CostDriver_Method", "Method"
        ],
        "Cost Driver Condition": [
            "Cost Driver Condition", "CostDriver Condition", "Cost DriverCondition",
            "Cost Driver_Condition", "CostDriver_Condition", "Condition"
        ],

        "í˜„ì¥ì½”ë“œ": ["í˜„ì¥ì½”ë“œ", "í˜„ì¥ ì½”ë“œ", "Site Code", "SiteCode"],
        "í˜„ì¥ëª…": ["í˜„ì¥ëª…", "í˜„ì¥ ëª…", "Site Name", "SiteName"],
    }

    cols = list(df.columns)
    for std_name, cand_list in aliases.items():
        for cand in cand_list:
            cand_std = _std_colname(cand)
            if cand_std in cols:
                col_map[cand_std] = std_name
                break

    df = df.rename(columns=col_map)

    must_cols = [
        "íŠ¹ì„±ID","ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…",
        "Cost Driver Type","Cost Driver Method","Cost Driver Condition"
    ]
    for c in must_cols:
        if c not in df.columns:
            df[c] = ""

    return df

def ensure_columns(df: pd.DataFrame, must_cols: list, fill_value=None) -> pd.DataFrame:
    df = df.copy()
    for c in must_cols:
        if c not in df.columns:
            df[c] = fill_value
    return df

def normalize_loaded_tables():
    """
    ë¡œë“œ ì§í›„ í‘œì¤€í™” + í•„ìˆ˜ ì»¬ëŸ¼ ë³´ì¥.
    """
    global cost_db, price_index, exchange, factor, project_feature_long, feature_master

    def _safe_df(x):
        return x if isinstance(x, pd.DataFrame) else pd.DataFrame()

    cost_db = _safe_df(cost_db)
    price_index = _safe_df(price_index)
    exchange = _safe_df(exchange)
    factor = _safe_df(factor)
    project_feature_long = _safe_df(project_feature_long)
    feature_master = _safe_df(feature_master)

    cost_db = standardize_columns(cost_db)
    price_index = standardize_columns(price_index)
    exchange = standardize_columns(exchange)
    factor = standardize_columns(factor)
    project_feature_long = standardize_columns(project_feature_long)
    feature_master = standardize_columns(feature_master)

    project_feature_long = apply_feature_column_alias(project_feature_long)
    feature_master = apply_feature_column_alias(feature_master)

    cost_db = ensure_columns(cost_db, [
        "ë‚´ì—­", "Unit", "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…", "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…", "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…"
    ], fill_value="")

    price_index = ensure_columns(price_index, ["êµ­ê°€", "ë…„ì›”", "Index"], fill_value=np.nan)
    exchange = ensure_columns(exchange, ["í†µí™”", "USDë‹¹í™˜ìœ¨"], fill_value=np.nan)
    factor = ensure_columns(factor, ["êµ­ê°€", "ì§€ìˆ˜"], fill_value=np.nan)

normalize_loaded_tables()

# =========================
# Sidebar: ì„¤ì •
# =========================
st.sidebar.header("âš™ï¸ ì„¤ì •")
sidebar_hr(thick=True, mt=6, mb=6)

use_site_filter = True

DEFAULT_W_STR = 0.3
DEFAULT_TOP_K_SEM = 200
w_str = DEFAULT_W_STR
w_sem = 1.0 - w_str
top_k_sem = DEFAULT_TOP_K_SEM

boq_file = None

# =========================
# (1) BOQ ì—…ë¡œë“œ (ë¨¼ì €!)
# =========================
with st.container():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    boq_file = st.file_uploader("ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
    st.markdown("</div>", unsafe_allow_html=True)

# (ì´í•˜ íŠ¹ì„± ì„ íƒ/í˜„ì¥ ì„ íƒ ë¡œì§ì€ ì‚¬ìš©ì ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€)

# =========================
# ê¸°íƒ€ ìŠ¬ë¼ì´ë”/í†µí™” ì„ íƒ  âœ… ì—¬ê¸°ë§Œ â€œì™„ì „ êµì²´â€
# =========================
sidebar_hr(thick=True, mt=10, mb=6)
st.sidebar.subheader("ğŸ§© ì„¤ì •ê°’")
sidebar_hr(thick=False, mt=6, mb=8)

sim_threshold = st.sidebar.slider(LABEL_SIM_THRESHOLD, 0, 100, 60, 5)
cut_ratio = st.sidebar.slider(LABEL_CUT_RATIO, 0, 30, 20, 5) / 100.0

# âœ… target_options / default_idxë¥¼ ë°˜ë“œì‹œ ë¨¼ì € ë§Œë“  ë’¤ selectbox í˜¸ì¶œ
def build_target_options(exchange: pd.DataFrame, factor: pd.DataFrame) -> list:
    opts = set()
    if isinstance(exchange, pd.DataFrame) and "í†µí™”" in exchange.columns:
        opts |= set(exchange["í†µí™”"].astype(str).str.upper().dropna().tolist())
    if isinstance(factor, pd.DataFrame) and "êµ­ê°€" in factor.columns:
        opts |= set(factor["êµ­ê°€"].astype(str).str.upper().dropna().tolist())
    opts = sorted([x.strip() for x in opts if x and x.strip()])
    if not opts:
        opts = ["KRW"]
    return opts

target_options = build_target_options(exchange, factor)
default_idx = target_options.index("KRW") if "KRW" in target_options else 0

target_currency = st.sidebar.selectbox(
    LABEL_TARGET_CURR,
    options=target_options,
    index=default_idx
)

missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper()==target_currency].empty
missing_factor   = factor[factor["êµ­ê°€"].astype(str).str.upper()==target_currency].empty

if missing_exchange:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
if missing_factor:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")

sidebar_hr(thick=True, mt=10, mb=8)


# =========================
# Run / Auto Recompute
# =========================
# âœ… ìë™ ì¬ì‚°ì¶œ í† ê¸€(ì‚¬ì´ë“œë°”)
auto_recompute = True  # âœ… UIëŠ” ìˆ¨ê¸°ì§€ë§Œ ê¸°ëŠ¥ì€ í•­ìƒ ON

def boq_file_signature(uploaded_file) -> str:
    """BOQ íŒŒì¼ì´ ë°”ë€Œì—ˆëŠ”ì§€ ê°ì§€í•˜ê¸° ìœ„í•œ ê°„ë‹¨ ì„œëª…(í•´ì‹œ)."""
    if uploaded_file is None:
        return "no_boq"
    try:
        b = uploaded_file.getvalue()
        # ë„ˆë¬´ í¬ë©´ ì•/ë’¤ ì¼ë¶€ë§Œ í•´ì‹œ
        if len(b) > 2_000_000:
            b = b[:1_000_000] + b[-1_000_000:]
        return hashlib.md5(b).hexdigest()
    except Exception:
        # fallback
        return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

def make_params_signature() -> str:
    payload = {
        "boq": boq_file_signature(boq_file),
        "use_site_filter": bool(use_site_filter),
        "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
        "sim_threshold": float(sim_threshold),
        "cut_ratio": float(cut_ratio),
        "target_currency": str(target_currency),
        "w_str": float(w_str),
        "w_sem": float(w_sem),
        "top_k_sem": int(top_k_sem),
    }
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
    return hashlib.md5(s.encode("utf-8")).hexdigest()

def run_calculation_and_store(run_sig: str):
    """'ì‚°ì¶œ ì‹¤í–‰'ê³¼ ë™ì¼í•œ íš¨ê³¼: ê³„ì‚° â†’ session_state ì €ì¥ â†’ í¸ì§‘ê°’ ì´ˆê¸°í™”"""

    status_box = st.empty()
    progress = st.progress(0.0)
    prog_text = st.empty()

    try:
        if boq_file is None:
            status_box.empty()
            st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            return
        if missing_exchange or missing_factor:
            status_box.empty()
            st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        status_box.markdown("### â³ ì‚°ì¶œì¤‘... (BOQ ë¡œë“œ/í•„í„°ë§)")

        boq = pd.read_excel(boq_file, engine="openpyxl")

        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(f"ì „ì²´ {len(cost_db):,}ê°œ ë‚´ì—­ ì¤‘ {len(cost_db_run):,}ê°œ ë‚´ì—­ìœ¼ë¡œ ì‚°ì¶œ ì‹¤í–‰")

        pool_sig_payload = {
            "boq": boq_file_signature(boq_file),
            "use_site_filter": bool(use_site_filter),
            "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
            "top_k_sem": int(top_k_sem),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "cost_db_rows": int(len(cost_db_run)),
        }
        pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

        need_new_pool = (st.session_state.get("candidate_pool_sig") != pool_sig) or ("candidate_pool" not in st.session_state)

        # 1) í›„ë³´í’€ ìƒì„±
        if need_new_pool:
            status_box.markdown("### â³ ì‚°ì¶œì¤‘... (í›„ë³´ í’€ ìƒì„±)")
            with st.spinner("í›„ë³´ í’€ ìƒì„±(ìµœì´ˆ/í˜„ì¥ë³€ê²½ ì‹œ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)..."):
                pool = build_candidate_pool(
                    cost_db=cost_db_run,
                    boq=boq,
                    price_index=price_index,
                    sim_w_str=w_str,
                    sim_w_sem=w_sem,
                    top_k_sem=top_k_sem,
                    pool_per_boq=400,
                    progress=progress,
                    prog_text=prog_text,
                )
            st.session_state["candidate_pool"] = pool
            st.session_state["candidate_pool_sig"] = pool_sig
        else:
            pool = st.session_state["candidate_pool"]

        # 2) ë¹ ë¥¸ ì¬ê³„ì‚°
        status_box.markdown("### â³ ì‚°ì¶œì¤‘... (ì¡°ê±´ ë°˜ì˜/ì‚°ì¶œí†µí™” ë°˜ì˜)")
        with st.spinner("ë¹ ë¥¸ ì¬ê³„ì‚°(ì¡°ê±´ ë°˜ì˜ ì¤‘)..."):
            result_df, log_df = fast_recompute_from_pool(
                pool=pool,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
            )

        st.session_state["boq_df"] = boq
        st.session_state["result_df_base"] = result_df.copy()
        st.session_state["log_df_base"] = log_df.copy()
        st.session_state["log_df_edited"] = log_df.copy()
        st.session_state.pop("result_df_adjusted", None)
        st.session_state["has_results"] = True
        st.session_state["last_run_sig"] = run_sig

    finally:
        # âœ… ì–´ë–¤ ìƒí™©ì´ë“  ì‚°ì¶œì¤‘ UI ì œê±°
        try:
            prog_text.empty()
            progress.empty()
            status_box.empty()
        except Exception:
            pass

# =========================
# (1) ì‹¤í–‰ íŠ¸ë¦¬ê±° ê²°ì •
# =========================

run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰")

current_sig = make_params_signature()
last_sig = st.session_state.get("last_run_sig", None)

needs_rerun = (last_sig is not None and current_sig != last_sig)

# ìë™ ì¬ì‚°ì¶œ OFFì¸ë° ì¡°ê±´ ë°”ë€ ê²½ìš° â†’ ê²½ê³ 
if st.session_state.get("has_results", False) and needs_rerun and not auto_recompute:
    st.sidebar.warning("âš ï¸ ì¡°ê±´ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‚°ì¶œ ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")

# ìë™ ì¬ì‚°ì¶œ ONì´ê³ , ê²°ê³¼ê°€ ì´ë¯¸ ìˆê³ , ì¡°ê±´ ë°”ë€Œë©´ â†’ ìë™ ì‹¤í–‰
auto_run = st.session_state.get("has_results", False) and needs_rerun and auto_recompute

# ìµœì´ˆ ì‹¤í–‰(ê²°ê³¼ ì—†ìŒ)ì¸ë° auto_recompute ì¼œì ¸ ìˆì–´ë„, ë²„íŠ¼ ì—†ì´ ìë™ ì‹¤í–‰ì€ ë¶€ë‹´ë  ìˆ˜ ìˆì–´ ê¸°ë³¸ì€ ì•ˆ í•¨
# ì›í•˜ë©´ ì•„ë˜ ì¡°ê±´ì„ í™•ì¥í•´ì„œ 'BOQ ì—…ë¡œë“œ ì‹œ ìë™ 1íšŒ ì‹¤í–‰'ë„ ê°€ëŠ¥

# =========================
# (2) ë²„íŠ¼ ì‹¤í–‰ ë˜ëŠ” ìë™ ì‹¤í–‰
# =========================
if run_btn or auto_run:
    # ìë™ ì¬ì‚°ì¶œì´ë©´ ì‚¬ìš©ì í¸ì§‘ì´ ì´ˆê¸°í™”ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆë‚´
    if auto_run:
        st.sidebar.info("â„¹ï¸ ì¡°ê±´ ë³€ê²½ ê°ì§€ â†’ ìë™ ì¬ì‚°ì¶œ ì¤‘ (ë¡œê·¸ í¸ì§‘ê°’ì€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤)")
    run_calculation_and_store(current_sig)


# =========================
# (3) ê²°ê³¼ í™”ë©´: ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ
# =========================
if st.session_state.get("has_results", False):
    boq = st.session_state["boq_df"]
    result_df = st.session_state["result_df_base"]
    log_df = st.session_state["log_df_base"]

    # -------------------------
    # ë¡œê·¸ Include ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ì¬ê³„ì‚° í•¨ìˆ˜
    # -------------------------
    def recompute_result_from_log(edited_log: pd.DataFrame) -> pd.DataFrame:
        base = st.session_state["result_df_base"].copy()

        out_prices = []
        for boq_id, g in edited_log.groupby("BOQ_ID"):
            g2 = g[g["Include"] == True].copy()
            if g2.empty:
                out_prices.append((int(boq_id), None, target_currency, "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)", ""))
                continue
        
            final_price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())
        
            currencies = sorted(g2["í†µí™”"].astype(str).str.upper().unique().tolist())
            reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(g2)}ê°œ ë‚´ì—­ ê·¼ê±°"
        
            vc = g2["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(g2)})" if top_code else ""
        
            out_prices.append((int(boq_id), f"{final_price:,.2f}", target_currency, reason_text, top_work))
        
        upd = pd.DataFrame(out_prices, columns=["BOQ_ID", "Final Price", "ì‚°ì¶œí†µí™”", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"])
        
        base = base.drop(
            columns=[c for c in ["Final Price","ì‚°ì¶œí†µí™”","ì‚°ì¶œê·¼ê±°","ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in base.columns],
            errors="ignore"
        )
        base = base.merge(upd, on="BOQ_ID", how="left")
        return base

    tab1, tab2, tab3 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸(í¸ì§‘ ê°€ëŠ¥)", "ğŸ“ ê·¼ê±° ë³´ê³ ì„œ"])

    with tab2:
        st.caption("âœ… ì²´í¬ í•´ì œí•˜ë©´ í‰ê· ë‹¨ê°€ ì‚°ì¶œì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. ì²´í¬í•˜ë©´ í¬í•¨ë©ë‹ˆë‹¤.")

        if "log_df_edited" not in st.session_state:
            st.session_state["log_df_edited"] = log_df.copy()

        log_all = st.session_state["log_df_edited"]

        # âœ… BOQ ì„ íƒì„ "ID | ë‚´ì—­"ìœ¼ë¡œ í‘œì‹œ
        boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())

        # result_df_baseì—ì„œ BOQ_IDë³„ ë‚´ì—­ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°(ìˆìœ¼ë©´ ë” ì •í™•)
        base_for_label = st.session_state.get("result_df_base", pd.DataFrame()).copy()
        boq_text_col = "ë‚´ì—­" if ("ë‚´ì—­" in base_for_label.columns) else None

        id_to_text = {}
        if boq_text_col and ("BOQ_ID" in base_for_label.columns):
            id_to_text = (
                base_for_label.dropna(subset=["BOQ_ID"])
                .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                .set_index("BOQ_ID")[boq_text_col]
                .astype(str)
                .to_dict()
            )
        else:
            # fallback: log_dfì˜ BOQ_ë‚´ì—­ ì‚¬ìš©
            tmp_map = (
                log_all.dropna(subset=["BOQ_ID"])
                .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                .groupby("BOQ_ID")["BOQ_ë‚´ì—­"].first()
                .astype(str)
                .to_dict()
            )
            id_to_text = tmp_map

        def fmt_boq_id(x: int) -> str:
            t = id_to_text.get(int(x), "")
            t = (t[:60] + "â€¦") if len(t) > 60 else t
            return f"{int(x)} | {t}"

        sel_id = st.selectbox(
            "í¸ì§‘í•  BOQ ì„ íƒ",
            options=boq_ids,
            format_func=fmt_boq_id,
            key="sel_boq_id"
        )

        # âœ… ì„ íƒëœ BOQ í›„ë³´ë§Œ
        log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()
        # =========================
        # ğŸ¤– AI ì¶”ì²œ ì»¨íŠ¸ë¡¤ (í˜„ì¬ BOQ / ì „ì²´ BOQ)
        # =========================
        if "_include_backup" not in st.session_state:
            st.session_state["_include_backup"] = {}
        if "_include_backup_all" not in st.session_state:
            st.session_state["_include_backup_all"] = None

        cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
        with cA:
            agent_mode = st.selectbox("AI ì¶”ì²œ ëª¨ë“œ", ["ë³´ìˆ˜ì ", "ê· í˜•", "ê³µê²©ì "], index=1, key="agent_mode")
        with cB:
            min_keep = st.number_input("ìµœì†Œ í¬í•¨", min_value=1, max_value=20, value=3, step=1, key="agent_min_keep")
        with cC:
            max_keep = st.number_input("ìµœëŒ€ í¬í•¨", min_value=3, max_value=200, value=50, step=1, key="agent_max_keep")
        with cD:
            st.caption("â€» ì ìš© í›„ í™”ë©´ì´ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")

        b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
        with b1:
            btn_ai_one = st.button("ğŸ¤– AI ì ìš©(í˜„ì¬ BOQ)", key="btn_ai_one")
        with b2:
            btn_undo_one = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(í˜„ì¬ BOQ)", key="btn_undo_one")
        with b3:
            btn_ai_all = st.button("ğŸ¤– AI ì ìš©(ì „ì²´ BOQ)", key="btn_ai_all")
        with b4:
            btn_undo_all = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(ì „ì²´ BOQ)", key="btn_undo_all")

        if btn_undo_one:
            backup = st.session_state["_include_backup"].get(int(sel_id))
            if backup is not None and len(backup) == len(log_view_full.index):
                st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(í˜„ì¬ BOQ)")
                st.rerun()
            else:
                st.warning("ë˜ëŒë¦´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í›„ë³´í–‰ì´ ë³€ê²½ë¨).")

        if btn_ai_one:
            st.session_state["_include_backup"][int(sel_id)] = st.session_state["log_df_edited"].loc[log_view_full.index, "Include"].copy()
            updated, summary = apply_agent_to_log(
                log_all=st.session_state["log_df_edited"].copy(),
                boq_id=int(sel_id),
                mode=agent_mode,
                min_keep=int(min_keep),
                max_keep=int(max_keep),
            )
            st.session_state["log_df_edited"] = updated
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
            if summary:
                st.success(f"AI ì ìš© ì™„ë£Œ(í˜„ì¬ BOQ): {summary['kept']}/{summary['total']} í¬í•¨, ëª¨ë“œ={summary['mode']}")
            record_ai_last_applied("í˜„ì¬ BOQ", agent_mode, int(min_keep), int(max_keep), summary, boq_id=int(sel_id))
            st.rerun()

        if btn_ai_all:
            st.session_state["_include_backup_all"] = st.session_state["log_df_edited"][["BOQ_ID", "Include"]].copy()
            updated, sum_df = apply_agent_to_all_boqs(
                log_all=st.session_state["log_df_edited"].copy(),
                mode=agent_mode,
                min_keep=int(min_keep),
                max_keep=int(max_keep),
            )
            st.session_state["log_df_edited"] = updated
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
            st.success("AI ì ìš© ì™„ë£Œ(ì „ì²´ BOQ)")
            if sum_df is not None and not sum_df.empty:
                st.dataframe(sum_df, use_container_width=True)
            record_ai_last_applied("ì „ì²´ BOQ", agent_mode, int(min_keep), int(max_keep), None)
            st.rerun()

        if btn_undo_all:
            backup_all = st.session_state.get("_include_backup_all")
            if backup_all is None or backup_all.empty:
                st.warning("ë˜ëŒë¦´ ì „ì²´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                cur = st.session_state["log_df_edited"].copy()
                b = backup_all.copy()
                b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)

                # BOQ_ID ê¸°ì¤€ Include ë³µì›
                cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                cur["Include"] = cur["Include"].fillna(False).astype(bool)

                st.session_state["log_df_edited"] = cur
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(ì „ì²´ BOQ)")
                st.rerun()

        # -------------------------
        # âœ… í™”ë©´ í‘œì‹œìš© ì»¬ëŸ¼(ì—´ ìˆœì„œ ê³ ì •)
        # - ì‚°ì¶œë‹¨ê°€(__adj_price)ì€ ì•ìª½ ìœ ì§€
        # - ì‚°ì¶œê·¼ê±°: ë¬¼ê°€ â†’ í™˜ìœ¨ â†’ êµ­ê°€ ìˆœ
        # - BOQ_ID/BOQ_ë‚´ì—­/BOQ_Unitì€ í™”ë©´ì—ì„œ ìˆ¨ê¹€(ë‹¤ìš´ë¡œë“œì—ëŠ” ë‚¨ì•„ìˆìŒ)
        # -------------------------
        display_cols = [
            "Include", "DefaultInclude",
            "ë‚´ì—­", "Unit",
            "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
            "__adj_price", "ì‚°ì¶œí†µí™”",
            "__cpi_ratio", "__latest_ym",
            "__fx_ratio",
            "__fac_ratio",
            "__hyb",
            "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
            "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
            "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        ]

        for c in display_cols:
            if c not in log_view_full.columns:
                log_view_full[c] = None

        log_view = log_view_full[display_cols].copy()

        # âœ… í¸ì§‘(Includeë§Œ)
        edited_view = st.data_editor(
            log_view,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Include": st.column_config.CheckboxColumn("í¬í•¨", help="í‰ê· ë‹¨ê°€ ì‚°ì¶œ í¬í•¨/ì œì™¸"),
                "DefaultInclude": st.column_config.CheckboxColumn("ê¸°ë³¸í¬í•¨", help="ì´ˆê¸° ìë™ í¬í•¨ ì—¬ë¶€(ì»· ë¡œì§)"),

                "ë‚´ì—­": st.column_config.TextColumn("ë‚´ì—­", width="large"),
                "Unit": st.column_config.TextColumn("ë‹¨ìœ„(Unit)"),

                "Unit Price": st.column_config.NumberColumn("ì›ë‹¨ê°€", format="%.4f"),
                "í†µí™”": st.column_config.TextColumn("ì›í†µí™”"),
                "ê³„ì•½ë…„ì›”": st.column_config.TextColumn("ê³„ì•½ë…„ì›”"),

                "__adj_price": st.column_config.NumberColumn("ì‚°ì¶œë‹¨ê°€(ì‚°ì¶œí†µí™” ê¸°ì¤€)", format="%.4f"),
                "ì‚°ì¶œí†µí™”": st.column_config.TextColumn("ì‚°ì¶œí†µí™”"),

                "__cpi_ratio": st.column_config.NumberColumn("ë¬¼ê°€ë³´ì •ê³„ìˆ˜(CPI)", format="%.6f"),
                "__latest_ym": st.column_config.TextColumn("ë¬¼ê°€ì§€ìˆ˜ ìµœì‹ ì›”"),

                "__fx_ratio": st.column_config.NumberColumn("í™˜ìœ¨ë³´ì •ê³„ìˆ˜", format="%.6f"),
                "__fac_ratio": st.column_config.NumberColumn("êµ­ê°€ë³´ì •ê³„ìˆ˜(Factor)", format="%.6f"),

                "__hyb": st.column_config.NumberColumn("ìœ ì‚¬ë„ì ìˆ˜", format="%.2f"),

                "ê³µì¢…ì½”ë“œ": st.column_config.TextColumn("ê³µì¢…ì½”ë“œ"),
                "ê³µì¢…ëª…": st.column_config.TextColumn("ê³µì¢…ëª…"),

                "í˜„ì¥ì½”ë“œ": st.column_config.TextColumn("í˜„ì¥ì½”ë“œ"),
                "í˜„ì¥ëª…": st.column_config.TextColumn("í˜„ì¥ëª…"),

                "í˜‘ë ¥ì‚¬ì½”ë“œ": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ì½”ë“œ"),
                "í˜‘ë ¥ì‚¬ëª…": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ëª…"),
            },
            disabled=[c for c in log_view.columns if c not in ["Include"]],
            key="log_editor",
        )

        # âœ… ê°€ì¥ ì•ˆì „í•œ ë°˜ì˜ ë°©ì‹: ì›ë³¸ ì¸ë±ìŠ¤ë¡œ Includeë§Œ ì—…ë°ì´íŠ¸
        st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values

        # âœ… ì¦‰ì‹œ BOQ ê²°ê³¼ ì¬ê³„ì‚°
        st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])

    with tab1:
        show_df = st.session_state.get("result_df_adjusted", result_df).copy()
    
        # (ì›ë˜ ìˆë˜ í†µí™” ì»¬ëŸ¼ ì œê±° ë¡œì§ì€ ìœ ì§€)
        if "í†µí™”" in show_df.columns:
            show_df = show_df.drop(columns=["í†µí™”"])
    
        # âœ… Final Price ë°”ë¡œ ë‹¤ìŒì— ì‚°ì¶œí†µí™” ìœ„ì¹˜ì‹œí‚¤ê¸°
        if "Final Price" in show_df.columns:
            if "ì‚°ì¶œí†µí™”" not in show_df.columns:
                show_df["ì‚°ì¶œí†µí™”"] = target_currency
    
            cols = show_df.columns.tolist()
            cols.remove("ì‚°ì¶œí†µí™”")
            fp_idx = cols.index("Final Price")
            cols.insert(fp_idx + 1, "ì‚°ì¶œí†µí™”")
            show_df = show_df[cols]
    
        st.dataframe(show_df, use_container_width=True)
   
    with tab3:
        st.markdown("## ğŸ“ ê·¼ê±° ë³´ê³ ì„œ(ìë™ ìƒì„±)")
        st.caption("í˜„ì¬ Include(í¬í•¨) ìƒíƒœ + ì¡°ê±´/ì„ íƒ í˜„ì¥/íŠ¹ì„± + (AI ì ìš© ì‹œ) ìµœì¢… ê¸°ì¤€ì„ í¬í•¨í•©ë‹ˆë‹¤.")
    
        base_result = st.session_state.get("result_df_adjusted", st.session_state.get("result_df_base", pd.DataFrame()))
        log_for_report = st.session_state.get("log_df_edited", st.session_state.get("log_df_base", pd.DataFrame()))
    
        # 1) ì°¾ì•„ì•¼ í•  ê³µì¢… íŠ¹ì„±(ì„ íƒëœ í”„ë¡œì íŠ¸ íŠ¹ì„±)
        st.markdown("### 1) ì°¾ì•„ì•¼ í•  ê³µì¢… íŠ¹ì„±(ì„ íƒëœ í”„ë¡œì íŠ¸ íŠ¹ì„±)")
        sel_features = st.session_state.get("selected_feature_ids", [])
        ft = build_feature_context_table(feature_master, sel_features)
        if ft.empty:
            st.info("ì„ íƒëœ íŠ¹ì„±IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(ft, use_container_width=True)
    
        # 2) ì°¾ì€ ì‹¤ì  í˜„ì¥ ë¦¬ìŠ¤íŠ¸(ìµœì¢… ì„ íƒ í˜„ì¥)
        st.markdown("### 2) ì°¾ì€ ì‹¤ì  í˜„ì¥ ë¦¬ìŠ¤íŠ¸(ìµœì¢… ì„ íƒ í˜„ì¥)")
        try:
            _sel_sites = selected_site_codes if (selected_site_codes is not None) else []
        except Exception:
            _sel_sites = []
        st_sites = build_site_context_table(cost_db, _sel_sites)
        if st_sites.empty:
            st.info("ì„ íƒëœ í˜„ì¥ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í˜„ì¥ í•„í„° ë¯¸ì‚¬ìš©).")
        else:
            st.dataframe(st_sites, use_container_width=True)
    
        # 3) ë‹¨ê°€ ì¶”ì¶œ ê·¼ê±°(ì¡°ê±´)
        st.markdown("### 3) ë‹¨ê°€ ì¶”ì¶œ ê·¼ê±°(ì¡°ê±´)")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("ìœ ì‚¬ë„ ì»·ì˜¤í”„ ê¸°ì¤€(%)", f"{float(sim_threshold):.0f}")
        with c2:
            st.metric("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨(%)", f"{float(cut_ratio)*100:.0f}")
        with c3:
            st.metric("ì‚°ì¶œí†µí™”", str(target_currency))
    
        # 4) AI ì ìš© ì‹œ ìµœì¢… ê¸°ì¤€
        st.markdown("### 4) AI ì ìš© ì‹œ ìµœì¢… ê¸°ì¤€")
        st.write(get_ai_effective_rule_text())
    
        # 5) ì‹¤ì  ë‹¨ê°€ BOQ(ê²°ê³¼)
        st.markdown("### 5) ì‹¤ì  ë‹¨ê°€ BOQ(ê²°ê³¼)")
        if base_result is None or base_result.empty:
            st.warning("ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‚°ì¶œ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            st.dataframe(base_result, use_container_width=True)
    
        # 6) ë³´ê³ ì„œ í…Œì´ë¸” ìƒì„±/ê°±ì‹ 
        if st.button("ğŸ“ ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ ", key="btn_build_report"):
            summary_df, detail_df = build_report_tables(log_for_report, base_result)
            st.session_state["report_summary_df"] = summary_df
            st.session_state["report_detail_df"] = detail_df
    
        summary_df = st.session_state.get("report_summary_df", pd.DataFrame())
        detail_df = st.session_state.get("report_detail_df", pd.DataFrame())
    
        st.markdown("### 6) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìš”ì•½)")
        if summary_df is None or summary_df.empty:
            st.info("ë³´ê³ ì„œë¥¼ ë³´ë ¤ë©´ 'ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ 'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            st.dataframe(summary_df, use_container_width=True)
    
        st.markdown("### 7) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìƒì„¸: Include=True í›„ë³´)")
        if detail_df is not None and not detail_df.empty:
            st.dataframe(detail_df, use_container_width=True)
        else:
            st.info("Include=True ìƒì„¸ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤(ì „ë¶€ ì œì™¸ë˜ì—ˆê±°ë‚˜ í›„ë³´ê°€ ì—†ìŒ).")
    
        # 8) ë¶„í¬ ê·¸ë˜í”„(ì „ì²´/ì„ íƒ)
        st.markdown("### 8) ë‚´ì—­ë³„ ë‹¨ê°€ ì ë¶„í¬(ê³„ì•½ë…„ì›” vs ë‹¨ê°€) - í¬í•¨/ë¯¸í¬í•¨")
        render_boq_scatter(log_for_report, base_result)
    
        # ë‹¤ìš´ë¡œë“œë„ ì¡°ì •ê°’ ê¸°ì¤€
        out_result = st.session_state.get("result_df_adjusted", result_df).copy()
        out_log = st.session_state.get("log_df_edited", log_df).copy()

    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        out_result.to_excel(writer, index=False, sheet_name="boq_with_price")
        out_log.to_excel(writer, index=False, sheet_name="calculation_log")
        rep_sum = st.session_state.get("report_summary_df", pd.DataFrame())
        rep_det = st.session_state.get("report_detail_df", pd.DataFrame())
        if rep_sum is not None and not rep_sum.empty:
            rep_sum.to_excel(writer, index=False, sheet_name="report_summary")
        if rep_det is not None and not rep_det.empty:
            rep_det.to_excel(writer, index=False, sheet_name="report_detail")
    bio.seek(0)
    st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")












