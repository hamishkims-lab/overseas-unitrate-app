import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

st.markdown("""
<style>
/* =====================================================
   TOKENS
===================================================== */
:root{
  --bg: #F6F8FC;
  --card: #FFFFFF;
  --text: #0F172A;
  --muted: #64748B;
  --border: rgba(15, 23, 42, 0.10);
  --shadow-sm: 0 6px 14px rgba(15, 23, 42, 0.05);
  --primary: #2563EB;

  --sb-bg: #FFFFFF;
  --sb-border: #E6EAF2;

  --chip-bg: #EEF2FF;
  --chip-border: #C7D2FE;
  --chip-text: #1E3A8A;
}

/* =====================================================
   LAYOUT / TYPO
===================================================== */
[data-testid="stAppViewContainer"]{ background: var(--bg) !important; }
html, body{ font-size: 14px !important; color: var(--text) !important; }
.main{ color: var(--text) !important; }
.main > div{
  padding: 16px 24px 24px 24px !important;
  max-width: 1280px;
  margin: 0 auto;
}

.main h1{ font-size: 26px !important; font-weight: 900 !important; letter-spacing: -0.5px !important; }
.main h2{ font-size: 20px !important; font-weight: 850 !important; letter-spacing: -0.3px !important; }
.main h3{ font-size: 16px !important; font-weight: 850 !important; }
.main .stCaption, .main small{ color: var(--muted) !important; font-size: 12.5px !important; }

/* =====================================================
   CARDS
===================================================== */
.gs-card{
  background: var(--card) !important;
  border: 1px solid var(--border) !important;
  border-radius: 16px !important;
  padding: 18px !important;
  margin: 14px 0 18px 0 !important;
  box-shadow: var(--shadow-sm) !important;
}
.gs-header{
  font-size: 18px !important;
  font-weight: 900 !important;
  letter-spacing: -0.3px !important;
  margin: 6px 0 14px 0 !important;
}

.dash-row{ display:flex; align-items:baseline; justify-content:space-between; gap:10px; margin:0 0 10px 0; }
.dash-title{ font-size: 14px !important; font-weight: 850 !important; letter-spacing: -0.2px !important; }
.dash-muted{ font-size: 12px !important; color: var(--muted) !important; white-space: nowrap !important; }

/* st.container(border=True) ì¹´ë“œí™” */
div[data-testid="stVerticalBlockBorderWrapper"]{
  background: var(--card) !important;
  border: 1px solid var(--border) !important;
  border-radius: 16px !important;
  padding: 18px !important;
  margin: 14px 0 18px 0 !important;
  box-shadow: var(--shadow-sm) !important;
}
div[data-testid="stVerticalBlockBorderWrapper"] > div{ padding: 0 !important; }

/* =====================================================
   SIDEBAR
===================================================== */
section[data-testid="stSidebar"]{
  background: var(--sb-bg) !important;
  border-right: 1px solid var(--sb-border) !important;
}
section[data-testid="stSidebar"] > div{ padding-top: 14px !important; }
section[data-testid="stSidebar"] hr{
  border: none !important;
  border-top: 1px solid var(--sb-border) !important;
  margin: 10px 0 !important;
}

.sb-row{ display:flex; align-items:baseline; justify-content:space-between; gap:10px; margin:2px 0 6px 0; }
.sb-title{ font-size: 14px !important; font-weight: 800 !important; letter-spacing: -0.2px !important; color: var(--text) !important; }
.sb-muted{ font-size: 12px !important; color: var(--muted) !important; white-space: nowrap !important; }
.sb-major{ font-size: 16px !important; font-weight: 900 !important; margin: 6px 0 10px 0 !important; letter-spacing: -0.2px !important; color: var(--text) !important; }

/* =====================================================
   WIDGETS (ìµœì†Œë§Œ)
===================================================== */

/* Select / Multiselect ì»¨íŠ¸ë¡¤ */
div[data-baseweb="select"] > div{
  background: #FFFFFF !important;
  border: 1px solid var(--border) !important;
  border-radius: 12px !important;
  min-height: 42px !important;
  box-shadow: none !important;
}
div[data-baseweb="select"] input{
  color: var(--text) !important;
  -webkit-text-fill-color: var(--text) !important;
  caret-color: var(--text) !important;
  font-size: 13px !important;
}

/* Chip(Tag) */
div[data-baseweb="tag"], span[data-baseweb="tag"]{
  background: var(--chip-bg) !important;
  border: 1px solid var(--chip-border) !important;
  color: var(--chip-text) !important;
  border-radius: 999px !important;
}

/* Text input */
div[data-testid="stTextInput"] div[data-baseweb="input"] > div{
  background: #FFFFFF !important;
  border: 1px solid var(--border) !important;
  border-radius: 12px !important;
  min-height: 42px !important;
  box-shadow: none !important;
}

/* File uploader */
[data-testid="stFileUploaderDropzone"]{
  background: #FFFFFF !important;
  border: 1px dashed rgba(15,23,42,0.18) !important;
  border-radius: 16px !important;
  padding: 16px !important;
}
[data-testid="stFileUploaderDropzone"] button{
  background: var(--primary) !important;
  color: #FFFFFF !important;
  border: 0 !important;
  border-radius: 12px !important;
  font-weight: 800 !important;
}

/* DataFrame/DataEditor: ì»¨í…Œì´ë„ˆë§Œ ë¼ì´íŠ¸ */
div[data-testid="stDataFrame"],
div[data-testid="stDataEditor"]{
  background: #FFFFFF !important;
  border-radius: 16px !important;
}
/* =====================================================
   TABS â€” ì„ íƒë¨/ë¯¸ì„ íƒ í¬ê¸° ë¶„ë¦¬ (ë‹¨ì¼ ì •ì˜ë¡œ ì •ë¦¬)
===================================================== */

/* ê¸°ë³¸(ë¯¸ì„ íƒ) íƒ­ */
div[data-testid="stTabs"] button[role="tab"],
.stTabs button[role="tab"],
.stTabs [data-baseweb="tab"]{
  font-size: 18px !important;
  font-weight: 700 !important;
  padding: 10px 14px !important;
  line-height: 1.2 !important;
}

/* ë¯¸ì„ íƒ íƒ­ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
div[data-testid="stTabs"] button[role="tab"] *,
.stTabs button[role="tab"] *,
.stTabs [data-baseweb="tab"] *{
  font-size: 18px !important;
}

/* ì„ íƒëœ íƒ­ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"],
.stTabs button[role="tab"][aria-selected="true"],
.stTabs [data-baseweb="tab"][aria-selected="true"]{
  font-size: 24px !important;
  font-weight: 900 !important;
}

/* ì„ íƒëœ íƒ­ ë‚´ë¶€ í…ìŠ¤íŠ¸ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"] *,
.stTabs button[role="tab"][aria-selected="true"] *,
.stTabs [data-baseweb="tab"][aria-selected="true"] *{
  font-size: 24px !important;
}

/* ì´ëª¨ì§€/í…ìŠ¤íŠ¸ ì •ë ¬ */
div[data-testid="stTabs"] button[role="tab"] > div,
.stTabs button[role="tab"] > div,
.stTabs [data-baseweb="tab"] > div{
  gap: 6px !important;
}

</style>
""", unsafe_allow_html=True)


def sidebar_hr(thick: bool = False, mt: int = 6, mb: int = 6):
    # âœ… ì—°í•œ íšŒìƒ‰ êµ¬ë¶„ì„  í†µì¼
    color = "#D9DDE3"  # ì—°í•œ íšŒìƒ‰
    h = "3px" if thick else "1px"
    st.sidebar.markdown(
        f"<hr style='margin:{mt}px 0 {mb}px 0; border:none; border-top:{h} solid {color};' />",
        unsafe_allow_html=True
    )

# =========================
# UI Helper (Style-aligned)
# =========================
def gs_header(text: str):
    st.markdown(f"<div class='gs-header'>{text}</div>", unsafe_allow_html=True)

def card_begin():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)

def card_end():
    st.markdown("</div>", unsafe_allow_html=True)

def card_title(title: str, right: str = ""):
    st.markdown(
        f"""
        <div class="dash-row">
          <div class="dash-title">{title}</div>
          <div class="dash-muted">{right}</div>
        </div>
        """,
        unsafe_allow_html=True
    )


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")


model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()


def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None


def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()


def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode())
    hasher.update(tail.encode())
    return hasher.hexdigest()


def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s

def norm_unit_kr(x) -> str:
    if x is None:
        return ""
    s = str(x).strip().lower()
    s = s.replace(" ", "")
    # í•„ìš” ì‹œ ì—¬ê¸°ì„œ ë‹¨ìœ„ aliasë¥¼ ë” ì¶”ê°€í•˜ì„¸ìš”
    alias = {
        "m2": "m2",
        "m3": "m3",
        "ea": "ea",
        "ã¥": "m3",
        "ã¡": "m2",
        "ê°œ": "ea",
    }
    return alias.get(s, s)

def norm_kr_boq_text(name, spec) -> str:
    # BOQ: ëª…ì¹­ + ê·œê²©ì„ í•©ì³ì„œ ë§¤ì¹­ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    a = "" if pd.isna(name) else str(name)
    b = "" if pd.isna(spec) else str(spec)
    return norm_text(f"{a} {b}")

def norm_kr_db_text(exec_name, spec) -> str:
    # êµ­ë‚´ DB: ì‹¤í–‰ëª…ì¹­ + ê·œê²©ì„ í•©ì³ì„œ ë§¤ì¹­ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    a = "" if pd.isna(exec_name) else str(exec_name)
    b = "" if pd.isna(spec) else str(spec)
    return norm_text(f"{a} {b}")

# =========================
# ë³´ì • ë¡œì§
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None


def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[
            exchange["í†µí™”"].astype(str).str.upper() == str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"
        ].values
        usd_to = exchange.loc[
            exchange["í†µí™”"].astype(str).str.upper() == str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"
        ].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0


def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[
            factor["êµ­ê°€"].astype(str).str.upper() == str(from_currency).upper(), "ì§€ìˆ˜"
        ].values
        f_to = factor.loc[
            factor["êµ­ê°€"].astype(str).str.upper() == str(to_currency).upper(), "ì§€ìˆ˜"
        ].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)


def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"


def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))


def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None


@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index


def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0


def build_candidate_pool(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    sim_w_str: float,
    sim_w_sem: float,
    top_k_sem: int,
    pool_per_boq: int = 400,
    progress=None,
    prog_text=None,
) -> pd.DataFrame:
    """
    âœ… 1ë‹¨ê³„(ë¬´ê±°ì›€): BOQë³„ í›„ë³´ í’€ ìƒì„±
    - FAISS ê²€ìƒ‰ + ë¬¸ìì—´ ì ìˆ˜ + __hyb ê³„ì‚°ê¹Œì§€ ì—¬ê¸°ì„œë§Œ ìˆ˜í–‰
    - ì‚°ì¶œí†µí™”(FX/Factor)ëŠ” ì—¬ê¸°ì„œ ê³„ì‚°í•˜ì§€ ì•ŠìŒ(ë¹ ë¥¸ ì¬ê³„ì‚°ì—ì„œ ì²˜ë¦¬)
    - CPIëŠ” í†µí™”/ê³„ì•½ì›”ì—ë§Œ ì˜ì¡´í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ê³„ì‚°í•´ ë‘ 
    """
    work = cost_db.copy()
    work["__ë‚´ì—­_norm"] = work["ë‚´ì—­"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_ê³„ì•½ì›”"] = robust_parse_contract_month(work["ê³„ì•½ë…„ì›”"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_ê³„ì•½ì›”"].notna())].copy()

    price_index2 = price_index.copy()
    price_index2["ë…„ì›”"] = price_index2["ë…„ì›”"].apply(to_year_month_string)

    fp = file_fingerprint(work, ["__ë‚´ì—­_norm", "__Unit_norm", "í†µí™”", "Unit Price", "_ê³„ì•½ì›”"])
    embs = compute_or_load_embeddings(work["__ë‚´ì—­_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    pool_rows = []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"í›„ë³´ í’€ ìƒì„±: {i}/{total} ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i / total)

        boq_item = str(boq_row.get("ë‚´ì—­", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]
            sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        # Unit ì¼ì¹˜ í›„ë³´ë§Œ
        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)
        if unit_df.empty:
            continue

        # __hyb ê³„ì‚°(ë¬¸ìì—´+ì˜ë¯¸ ìœ ì‚¬ë„)
        hyb = hybrid_scores(
            boq_text_norm,
            unit_df["__ë‚´ì—­_norm"],
            unit_df["__sem"].to_numpy(),
            sim_w_str,
            sim_w_sem
        )
        unit_df["__hyb"] = hyb

        # ë„ˆë¬´ í° í’€ ë°©ì§€: hyb ìƒìœ„ Nê°œë§Œ ë³´ê´€
        unit_df = unit_df.sort_values("__hyb", ascending=False).head(pool_per_boq).copy()

        # CPIëŠ” í†µí™”+ê³„ì•½ì›” ê¸°ì¤€ìœ¼ë¡œ ë¯¸ë¦¬ ê³„ì‚° (ì‚°ì¶œí†µí™” ë°”ë€Œì–´ë„ ì¬ì‚¬ìš© ê°€ëŠ¥)
        unit_df["__contract_ym"] = unit_df["_ê³„ì•½ì›”"].apply(to_year_month_string)

        cpi_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("í†µí™”", "")).upper().strip()
            contract_ym = r.get("__contract_ym", None)
            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index2, c_currency, contract_ym)
            cpi_list.append((cpi_ratio, latest_ym))
        unit_df["__cpi_ratio"] = [x[0] for x in cpi_list]
        unit_df["__latest_ym"] = [x[1] for x in cpi_list]

        # BOQ ë©”íƒ€ ë¶™ì´ê¸°
        boq_id = int(i)
        unit_df["BOQ_ID"] = boq_id
        unit_df["BOQ_ë‚´ì—­"] = boq_item
        unit_df["BOQ_Unit"] = boq_unit

        pool_rows.append(unit_df)

    if not pool_rows:
        return pd.DataFrame()

    pool = pd.concat(pool_rows, ignore_index=True)

    keep_cols = [
        "BOQ_ID", "BOQ_ë‚´ì—­", "BOQ_Unit",
        "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
        "ë‚´ì—­", "Unit",
        "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
        "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        "__hyb",
        "__cpi_ratio",
        "__latest_ym",
    ]
    for c in keep_cols:
        if c not in pool.columns:
            pool[c] = None
    return pool[keep_cols].copy()


def fast_recompute_from_pool(
    pool: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    âœ… 2ë‹¨ê³„(ê°€ë²¼ì›€): í›„ë³´ í’€ì—ì„œ ë¹ ë¥¸ ì¬ê³„ì‚°
    - Threshold í•„í„°
    - ì‚°ì¶œí†µí™” ë³€ê²½: __fx_ratio, __fac_ratioë§Œ ë‹¤ì‹œ ê³„ì‚°
    - ì»·ë¹„ìœ¨ë¡œ Include/DefaultInclude ì„¤ì •
    - __adj_price = Unit Price * __cpi_ratio * __fx_ratio * __fac_ratio
    """
    if pool is None or pool.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = pool.copy()

    # 1) Threshold ì ìš©
    df["__hyb"] = pd.to_numeric(df["__hyb"], errors="coerce").fillna(0.0)
    df = df[df["__hyb"] >= float(sim_threshold)].copy()
    if df.empty:
        return pd.DataFrame(), pd.DataFrame()

    # 2) FX/Factor ë§µ(í†µí™”ë³„)
    df["í†µí™”_std"] = df["í†µí™”"].astype(str).str.upper().str.strip()
    currencies = df["í†µí™”_std"].dropna().unique().tolist()

    fx_map = {c: get_exchange_rate(exchange, c, target_currency) for c in currencies}
    fac_map = {c: get_factor_ratio(factor, c, target_currency) for c in currencies}

    df["__fx_ratio"] = df["í†µí™”_std"].map(fx_map).fillna(1.0)
    df["__fac_ratio"] = df["í†µí™”_std"].map(fac_map).fillna(1.0)
    df["ì‚°ì¶œí†µí™”"] = target_currency

    # 3) __adj_price ê³„ì‚°
    unit_price = pd.to_numeric(df["Unit Price"], errors="coerce").fillna(0.0)
    cpi_ratio = pd.to_numeric(df["__cpi_ratio"], errors="coerce").fillna(1.0)
    df["__adj_price"] = unit_price * cpi_ratio * df["__fx_ratio"] * df["__fac_ratio"]

    # 4) BOQë³„ ì»· + Include/DefaultInclude ì„¤ì •
    df["Include"] = False
    df["DefaultInclude"] = False

    for boq_id, gidx in df.groupby("BOQ_ID").groups.items():
        sub = df.loc[gidx].sort_values("__adj_price").copy()
        n = len(sub)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n - cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        kept_index = sub.index[keep_mask]
        df.loc[kept_index, "DefaultInclude"] = True
        df.loc[kept_index, "Include"] = True

    # 5) BOQ ê²°ê³¼(result_df)
    results = []
    for boq_id, sub in df.groupby("BOQ_ID"):
        inc = sub[sub["Include"] == True]

        if inc.empty:
            final_price = None
            reason_text = "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)"
            top_work = ""
        else:
            final_price = float(pd.to_numeric(inc["__adj_price"], errors="coerce").mean())
            currencies2 = sorted(inc["í†µí™”_std"].unique().tolist())
            reason_text = f"{len(currencies2)}ê°œêµ­({', '.join(currencies2)}) {len(inc)}ê°œ ë‚´ì—­ ê·¼ê±°"

            vc = inc["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(inc)})" if top_code else ""

        one = sub.iloc[0]
        results.append({
            "BOQ_ID": int(boq_id),
            "ë‚´ì—­": one.get("BOQ_ë‚´ì—­", ""),
            "Unit": one.get("BOQ_Unit", ""),
            "Final Price": f"{final_price:,.2f}" if final_price is not None else None,
            "ì‚°ì¶œí†µí™”": target_currency,
            "ì‚°ì¶œê·¼ê±°": reason_text,
            "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)": top_work,
        })

    result_df = pd.DataFrame(results).sort_values("BOQ_ID").reset_index(drop=True)

    # 6) ì‚°ì¶œ ë¡œê·¸(log_df)
    log_cols = [
        "BOQ_ID", "BOQ_ë‚´ì—­", "BOQ_Unit",
        "Include", "DefaultInclude",
        "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
        "ë‚´ì—­", "Unit",
        "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
        "__adj_price", "ì‚°ì¶œí†µí™”",
        "__cpi_ratio", "__latest_ym",
        "__fx_ratio", "__fac_ratio",
        "__hyb",
        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
        "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
    ]
    for c in log_cols:
        if c not in df.columns:
            df[c] = None
    log_df = df[log_cols].copy()

    return result_df, log_df

def build_candidate_pool_domestic(
    cost_db_kr: pd.DataFrame,
    boq_kr: pd.DataFrame,
    sim_w_str: float,
    sim_w_sem: float,
    top_k_sem: int,
    pool_per_boq: int = 400,
    progress=None,
    prog_text=None,
) -> pd.DataFrame:
    """
    êµ­ë‚´ 1ë‹¨ê³„(ë¬´ê±°ì›€): BOQë³„ í›„ë³´ í’€ ìƒì„±
    - ë¬¸ìì—´+ì„ë² ë”© í•˜ì´ë¸Œë¦¬ë“œë¡œ í›„ë³´ ìƒì„±
    - ë‹¨ìœ„ ì¼ì¹˜ í•„ìˆ˜
    - ë³´ì •ë‹¨ê°€(ìˆìœ¼ë©´) ìš°ì„ , ì—†ìœ¼ë©´ ê³„ì•½ë‹¨ê°€ë¥¼ __price_rawë¡œ ì‚¬ìš©
    - fast_recompute_from_pool_domesticì—ì„œ threshold/cut/include ì²˜ë¦¬
    """

    if cost_db_kr is None or cost_db_kr.empty or boq_kr is None or boq_kr.empty:
        return pd.DataFrame()

    # 0) BOQ í‘œì¤€ ì»¬ëŸ¼ ë³´ê°•
    b = boq_kr.copy()
    need_boq_cols = ["ëª…ì¹­", "ê·œê²©", "ë‹¨ìœ„", "ìˆ˜ëŸ‰", "ë‹¨ê°€"]
    for c in need_boq_cols:
        if c not in b.columns:
            b[c] = ""

    # 1) DB í‘œì¤€ ì»¬ëŸ¼ ë³´ê°•
    db = cost_db_kr.copy()

    # êµ­ë‚´ DBì—ì„œ ì‚¬ìš©í•  ì»¬ëŸ¼ë“¤(ì—†ìœ¼ë©´ ë¹ˆê°’ ìƒì„±)
    # ì‹¤í–‰ëª…ì¹­/ê·œê²©/ë‹¨ìœ„/ìˆ˜ëŸ‰/ê³„ì•½ë‹¨ê°€/ë³´ì •ë‹¨ê°€/ê³„ì•½ì›”ì€ ì´í›„ ì‚°ì¶œ/ë¡œê·¸ì— í•„ìš”
    must = [
        "í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…","í˜„ì¥íŠ¹ì„±",
        "ì‹¤í–‰ëª…ì¹­","ê·œê²©","ë‹¨ìœ„","ìˆ˜ëŸ‰",
        "ê³„ì•½ë‹¨ê°€","ë³´ì •ë‹¨ê°€","ê³„ì•½ì›”",
        "ì—…ì²´ì½”ë“œ","ì—…ì²´ëª…",
        "ê³µì¢…Codeë¶„ë¥˜","ì„¸ë¶€ë¶„ë¥˜",
    ]
    for c in must:
        if c not in db.columns:
            db[c] = ""

    # 2) ë§¤ì¹­ìš© í…ìŠ¤íŠ¸/ë‹¨ìœ„ ì •ê·œí™”
    db["__db_text_norm"] = db.apply(lambda r: norm_kr_db_text(r.get("ì‹¤í–‰ëª…ì¹­",""), r.get("ê·œê²©","")), axis=1)
    db["__unit_norm"] = db["ë‹¨ìœ„"].apply(norm_unit_kr)

    # ê°€ê²© ì›ì²œ: ë³´ì •ë‹¨ê°€ ìš°ì„ , ì—†ìœ¼ë©´ ê³„ì•½ë‹¨ê°€
    price_adj = pd.to_numeric(db["ë³´ì •ë‹¨ê°€"], errors="coerce")
    price_ctr = pd.to_numeric(db["ê³„ì•½ë‹¨ê°€"], errors="coerce")
    db["__price_raw"] = price_adj.where(price_adj.notna() & (price_adj > 0), price_ctr)
    db = db[pd.to_numeric(db["__price_raw"], errors="coerce").fillna(0) > 0].copy()

    if db.empty:
        return pd.DataFrame()

    # 3) ì„ë² ë”©(êµ­ë‚´ DB)
    fp = file_fingerprint(db, ["__db_text_norm", "__unit_norm", "__price_raw"])
    embs = compute_or_load_embeddings(db["__db_text_norm"], tag=f"costdb_kr_{fp}")

    index = build_faiss_index(embs) if FAISS_OK else None

    pool_rows = []
    total = len(b) if len(b) else 1

    for i, (_, r) in enumerate(b.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"[êµ­ë‚´] í›„ë³´ í’€ ìƒì„±: {i}/{total} ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i / total)

        boq_name = str(r.get("ëª…ì¹­", ""))
        boq_spec = str(r.get("ê·œê²©", ""))
        boq_unit = norm_unit_kr(r.get("ë‹¨ìœ„", ""))

        boq_text_norm = norm_kr_boq_text(boq_name, boq_spec)

        # Query embedding
        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        # semantic topK
        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]
            sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand = db.iloc[cand_idx].copy()
        cand["__sem"] = sem_scores

        # ë‹¨ìœ„ ì¼ì¹˜ í•„ìˆ˜
        cand = cand[cand["__unit_norm"] == boq_unit].reset_index(drop=True)
        if cand.empty:
            continue

        # hybrid score
        hyb = hybrid_scores(
            boq_text_norm,
            cand["__db_text_norm"],
            cand["__sem"].to_numpy(),
            sim_w_str,
            sim_w_sem,
        )
        cand["__hyb"] = hyb

        cand = cand.sort_values("__hyb", ascending=False).head(pool_per_boq).copy()

        # BOQ ë©”íƒ€
        cand["BOQ_ID"] = int(i)
        cand["BOQ_ëª…ì¹­"] = boq_name
        cand["BOQ_ê·œê²©"] = boq_spec
        cand["BOQ_ë‹¨ìœ„"] = boq_unit
        cand["BOQ_ìˆ˜ëŸ‰"] = r.get("ìˆ˜ëŸ‰", "")
        cand["BOQ_ë‹¨ê°€"] = r.get("ë‹¨ê°€", "")

        pool_rows.append(cand)

    if not pool_rows:
        return pd.DataFrame()

    pool = pd.concat(pool_rows, ignore_index=True)

    # ë¡œê·¸/í›„ì† ì²˜ë¦¬ì—ì„œ í•„ìš”í•œ ì»¬ëŸ¼ë“¤ í¬í•¨í•´ì„œ ë°˜í™˜
    keep_cols = [
        "BOQ_ID","BOQ_ëª…ì¹­","BOQ_ê·œê²©","BOQ_ë‹¨ìœ„","BOQ_ìˆ˜ëŸ‰","BOQ_ë‹¨ê°€",
        "í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…","í˜„ì¥íŠ¹ì„±",
        "ì‹¤í–‰ëª…ì¹­","ê·œê²©","ë‹¨ìœ„","ìˆ˜ëŸ‰",
        "ê³„ì•½ë‹¨ê°€","ë³´ì •ë‹¨ê°€","ê³„ì•½ì›”",
        "ì—…ì²´ì½”ë“œ","ì—…ì²´ëª…",
        "ê³µì¢…Codeë¶„ë¥˜","ì„¸ë¶€ë¶„ë¥˜",
        "__price_raw","__hyb",
    ]
    for c in keep_cols:
        if c not in pool.columns:
            pool[c] = None

    return pool[keep_cols].copy()

def fast_recompute_from_pool_domestic(
    pool: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    êµ­ë‚´ 2ë‹¨ê³„(ê°€ë²¼ì›€)
    - threshold ì ìš©
    - ì»· ì ìš© í›„ Include/DefaultInclude ì„¤ì •
    - ì‚°ì¶œë‹¨ê°€ = __price_raw(ë³´ì •ë‹¨ê°€/ê³„ì•½ë‹¨ê°€)
    """
    if pool is None or pool.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = pool.copy()
    df["__hyb"] = pd.to_numeric(df["__hyb"], errors="coerce").fillna(0.0)
    df = df[df["__hyb"] >= float(sim_threshold)].copy()
    if df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df["__adj_price"] = pd.to_numeric(df["__price_raw"], errors="coerce").fillna(0.0)

    df["Include"] = False
    df["DefaultInclude"] = False

    for boq_id, gidx in df.groupby("BOQ_ID").groups.items():
        sub = df.loc[gidx].sort_values("__adj_price").copy()
        n = len(sub)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n - cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        kept_index = sub.index[keep_mask]
        df.loc[kept_index, "DefaultInclude"] = True
        df.loc[kept_index, "Include"] = True

    # BOQ ê²°ê³¼
    results = []
    for boq_id, sub in df.groupby("BOQ_ID"):
        inc = sub[sub["Include"] == True]
        one = sub.iloc[0]

        if inc.empty:
            final_price = None
            reason_text = "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)"
        else:
            final_price = float(pd.to_numeric(inc["__adj_price"], errors="coerce").mean())
            reason_text = f"{len(inc)}ê°œ ë‚´ì—­ í‰ê· (êµ­ë‚´DB)"

        results.append({
            "BOQ_ID": int(boq_id),
            "ëª…ì¹­": one.get("BOQ_ëª…ì¹­", ""),
            "ê·œê²©": one.get("BOQ_ê·œê²©", ""),
            "ë‹¨ìœ„": one.get("BOQ_ë‹¨ìœ„", ""),
            "ìˆ˜ëŸ‰": one.get("BOQ_ìˆ˜ëŸ‰", ""),
            "Final Price": f"{final_price:,.2f}" if final_price is not None else None,
            "ì‚°ì¶œê·¼ê±°": reason_text,
        })

    result_df = pd.DataFrame(results).sort_values("BOQ_ID").reset_index(drop=True)

    log_cols = [
        "BOQ_ID","BOQ_ëª…ì¹­","BOQ_ê·œê²©","BOQ_ë‹¨ìœ„","BOQ_ìˆ˜ëŸ‰","BOQ_ë‹¨ê°€",
        "Include","DefaultInclude",
        "í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…","í˜„ì¥íŠ¹ì„±",
        "ì‹¤í–‰ëª…ì¹­","ê·œê²©","ë‹¨ìœ„","ìˆ˜ëŸ‰",
        "ê³„ì•½ë‹¨ê°€","ë³´ì •ë‹¨ê°€","ê³„ì•½ì›”",
        "ì—…ì²´ì½”ë“œ","ì—…ì²´ëª…",
        "ê³µì¢…Codeë¶„ë¥˜","ì„¸ë¶€ë¶„ë¥˜",
        "__adj_price","__hyb",
    ]
    for c in log_cols:
        if c not in df.columns:
            df[c] = None
    log_df = df[log_cols].copy()

    return result_df, log_df


# =========================
# ğŸ¤– Include ìë™ ì¶”ì²œ ì—ì´ì „íŠ¸(ë£° ê¸°ë°˜)
# =========================
def _to_num(s):
    return pd.to_numeric(s, errors="coerce")


def suggest_include_for_one_boq(
    df_boq: pd.DataFrame,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    d = df_boq.copy()

    hyb = _to_num(d.get("__hyb", 0)).fillna(0.0)
    price = _to_num(d.get("__adj_price", np.nan))

    if mode == "ë³´ìˆ˜ì ":
        hyb_min = 80
        iqr_k = 1.0
    elif mode == "ê³µê²©ì ":
        hyb_min = 60
        iqr_k = 2.0
    else:  # ê· í˜•
        hyb_min = 70
        iqr_k = 1.5

    keep = hyb >= hyb_min

    valid = price[price.notna()]
    low = high = None
    if len(valid) >= 5:
        q1 = valid.quantile(0.25)
        q3 = valid.quantile(0.75)
        iqr = q3 - q1
        low = q1 - iqr_k * iqr
        high = q3 + iqr_k * iqr
        keep = keep & (price.between(low, high) | price.isna())

    keep_idx = d.index[keep].tolist()
    if len(keep_idx) < int(min_keep):
        top_idx = hyb.sort_values(ascending=False).head(int(min_keep)).index.tolist()
        keep_idx = sorted(set(keep_idx) | set(top_idx))

    if len(keep_idx) > int(max_keep):
        keep_idx = hyb.loc[keep_idx].sort_values(ascending=False).head(int(max_keep)).index.tolist()

    include = pd.Series(False, index=d.index)
    include.loc[keep_idx] = True

    reasons = []
    for idx in d.index:
        r = []
        if hyb.loc[idx] < hyb_min:
            r.append(f"ìœ ì‚¬ë„<{hyb_min}")
        if low is not None and high is not None and pd.notna(price.loc[idx]):
            if price.loc[idx] < low or price.loc[idx] > high:
                r.append("ë‹¨ê°€ì´ìƒì¹˜(IQR)")
        if include.loc[idx]:
            reasons.append("í¬í•¨" if not r else "í¬í•¨(ì˜ˆì™¸ë³´ì™„): " + ", ".join(r))
        else:
            reasons.append("ì œì™¸" if not r else "ì œì™¸: " + ", ".join(r))

    summary = {
        "mode": mode,
        "hyb_min": hyb_min,
        "iqr_k": iqr_k,
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
        "kept": int(include.sum()),
        "total": int(len(d)),
    }
    return include, pd.Series(reasons, index=d.index), summary


def apply_agent_to_log(
    log_all: pd.DataFrame,
    boq_id: int,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    mask = log_all["BOQ_ID"].astype(int) == int(boq_id)
    sub = log_all.loc[mask].copy()
    if sub.empty:
        return log_all, None

    inc, reason_s, summary = suggest_include_for_one_boq(sub, mode=mode, min_keep=min_keep, max_keep=max_keep)

    if "AI_ì¶”ì²œì‚¬ìœ " not in log_all.columns:
        log_all["AI_ì¶”ì²œì‚¬ìœ "] = ""
    if "AI_ëª¨ë“œ" not in log_all.columns:
        log_all["AI_ëª¨ë“œ"] = ""

    log_all.loc[mask, "Include"] = inc.values
    log_all.loc[mask, "AI_ì¶”ì²œì‚¬ìœ "] = reason_s.values
    log_all.loc[mask, "AI_ëª¨ë“œ"] = mode

    return log_all, summary


def apply_agent_to_all_boqs(
    log_all: pd.DataFrame,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    rows = []
    for boq_id in sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist()):
        log_all, summary = apply_agent_to_log(log_all, boq_id, mode=mode, min_keep=min_keep, max_keep=max_keep)
        if summary:
            rows.append([boq_id, summary["kept"], summary["total"], summary["mode"]])
    sum_df = pd.DataFrame(rows, columns=["BOQ_ID", "í¬í•¨ìˆ˜", "í›„ë³´ìˆ˜", "ëª¨ë“œ"])
    return log_all, sum_df


# =========================
# ğŸ“ ê·¼ê±° ë³´ê³ ì„œ ìƒì„±(ìš”ì•½/ìƒì„¸)
# =========================
def build_report_tables(log_df: pd.DataFrame, result_df: pd.DataFrame):
    if log_df is None or log_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = log_df.copy()
    df["BOQ_ID"] = df["BOQ_ID"].astype(int)

    inc = df[df["Include"] == True].copy()

    detail_cols = [
        "BOQ_ID", "BOQ_ë‚´ì—­", "BOQ_Unit",
        "ë‚´ì—­", "Unit", "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
        "__adj_price", "ì‚°ì¶œí†µí™”",
        "__cpi_ratio", "__latest_ym", "__fx_ratio", "__fac_ratio", "__hyb",
        "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…", "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        "AI_ëª¨ë“œ", "AI_ì¶”ì²œì‚¬ìœ ",
    ]
    for c in detail_cols:
        if c not in inc.columns:
            inc[c] = None
    detail_df = inc[detail_cols].copy()

    rows = []
    for boq_id, g in df.groupby("BOQ_ID"):
        g_inc = g[g["Include"] == True].copy()
        total_n = len(g)
        inc_n = len(g_inc)

        adj = pd.to_numeric(g_inc.get("__adj_price", np.nan), errors="coerce")
        mean = float(adj.mean()) if inc_n else np.nan
        std = float(adj.std(ddof=0)) if inc_n else np.nan
        vmin = float(adj.min()) if inc_n else np.nan
        vmax = float(adj.max()) if inc_n else np.nan

        countries = sorted(g_inc["í†µí™”"].astype(str).str.upper().unique().tolist()) if inc_n else []
        sites = g_inc["í˜„ì¥ì½”ë“œ"].astype(str).nunique() if inc_n and "í˜„ì¥ì½”ë“œ" in g_inc.columns else 0
        vendors = g_inc["í˜‘ë ¥ì‚¬ì½”ë“œ"].astype(str).nunique() if inc_n and "í˜‘ë ¥ì‚¬ì½”ë“œ" in g_inc.columns else 0

        top_site = ""
        top_vendor = ""
        if inc_n and "í˜„ì¥ì½”ë“œ" in g_inc.columns:
            vc = g_inc["í˜„ì¥ì½”ë“œ"].astype(str).value_counts()
            top_site = f"{vc.index[0]} ({int(vc.iloc[0])}/{inc_n})" if len(vc) else ""
        if inc_n and "í˜‘ë ¥ì‚¬ì½”ë“œ" in g_inc.columns:
            vc2 = g_inc["í˜‘ë ¥ì‚¬ì½”ë“œ"].astype(str).value_counts()
            top_vendor = f"{vc2.index[0]} ({int(vc2.iloc[0])}/{inc_n})" if len(vc2) else ""

        risk = []
        if inc_n == 0:
            risk.append("í¬í•¨í›„ë³´ì—†ìŒ")
        if inc_n and pd.notna(vmax) and pd.notna(vmin) and vmin > 0 and (vmax / vmin > 3):
            risk.append("ë‹¨ê°€í¸ì°¨í¼(>3ë°°)")
        if inc_n and pd.notna(std) and pd.notna(mean) and mean != 0 and (std / mean > 0.5):
            risk.append("ë³€ë™ì„±í¼(CV>0.5)")
        if inc_n and sites == 1 and inc_n >= 3:
            risk.append("í˜„ì¥í¸í–¥(1ê°œí˜„ì¥)")
        if inc_n and vendors == 1 and inc_n >= 3:
            risk.append("ì—…ì²´í¸í–¥(1ê°œì—…ì²´)")

        one = g.iloc[0]
        rows.append({
            "BOQ_ID": int(boq_id),
            "BOQ_ë‚´ì—­": one.get("BOQ_ë‚´ì—­", ""),
            "BOQ_Unit": one.get("BOQ_Unit", ""),
            "í›„ë³´ìˆ˜": int(total_n),
            "í¬í•¨ìˆ˜": int(inc_n),
            "í¬í•¨êµ­ê°€": ", ".join(countries),
            "í¬í•¨í˜„ì¥ìˆ˜": int(sites),
            "í¬í•¨ì—…ì²´ìˆ˜": int(vendors),
            "ì‚°ì¶œë‹¨ê°€í‰ê· ": mean,
            "ì‚°ì¶œë‹¨ê°€í‘œì¤€í¸ì°¨": std,
            "ì‚°ì¶œë‹¨ê°€ìµœì €": vmin,
            "ì‚°ì¶œë‹¨ê°€ìµœê³ ": vmax,
            "ìµœë¹ˆí˜„ì¥": top_site,
            "ìµœë¹ˆì—…ì²´": top_vendor,
            "ë¦¬ìŠ¤í¬": ", ".join(risk),
        })

    summary_df = pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)

    if result_df is not None and not result_df.empty and "BOQ_ID" in result_df.columns:
        tmp = result_df.copy()
        tmp["BOQ_ID"] = tmp["BOQ_ID"].astype(int)
        keep = [c for c in ["BOQ_ID", "Final Price", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in tmp.columns]
        summary_df = summary_df.merge(tmp[keep], on="BOQ_ID", how="left")

    return summary_df, detail_df


# =========================
# ğŸ¤– AI ìµœì¢… ì ìš© ê¸°ì¤€ ê¸°ë¡/í‘œì‹œìš© (TAB3ì—ì„œ ì‚¬ìš©)
# =========================
def record_ai_last_applied(
    scope: str,
    mode: str,
    min_keep: int,
    max_keep: int,
    summary: Optional[dict] = None,
    boq_id: Optional[int] = None,
):
    payload = {
        "scope": str(scope),
        "mode": str(mode),
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
    }
    if boq_id is not None:
        payload["boq_id"] = int(boq_id)

    if isinstance(summary, dict):
        for k in ["hyb_min", "iqr_k", "kept", "total"]:
            if k in summary:
                payload[k] = summary[k]

    st.session_state["ai_last_applied"] = payload


def get_ai_effective_rule_text() -> str:
    info = st.session_state.get("ai_last_applied", None)
    if not isinstance(info, dict) or not info.get("mode"):
        return "AI ìµœì¢…ê¸°ì¤€ ê¸°ë¡ ì—†ìŒ(ìˆ˜ë™ í¸ì§‘ ë˜ëŠ” ê¸°ë³¸ ì»·ë§Œ ì ìš©)"

    scope = info.get("scope", "")
    mode = info.get("mode", "")
    min_keep = info.get("min_keep", "")
    max_keep = info.get("max_keep", "")
    boq_id = info.get("boq_id", None)
    hyb_min = info.get("hyb_min", None)
    iqr_k = info.get("iqr_k", None)

    parts = []
    if scope == "í˜„ì¬ BOQ" and boq_id is not None:
        parts.append(f"ì ìš©ë²”ìœ„={scope}(BOQ_ID={boq_id})")
    else:
        parts.append(f"ì ìš©ë²”ìœ„={scope}")

    parts.append(f"ëª¨ë“œ={mode}")
    parts.append(f"ìµœì†Œí¬í•¨={min_keep}")
    parts.append(f"ìµœëŒ€í¬í•¨={max_keep}")

    if hyb_min is not None:
        parts.append(f"ìœ ì‚¬ë„ìµœì†Œ(hyb_min)={hyb_min}")
    if iqr_k is not None:
        parts.append(f"IQRê³„ìˆ˜(iqr_k)={iqr_k}")

    return " / ".join(parts)


# =========================
# ğŸ§¾ ë³´ê³ ì„œ TAB3 ìœ í‹¸(íŠ¹ì„±/í˜„ì¥/AIê¸°ì¤€/ë¶„í¬ ê·¸ë˜í”„)
# =========================
def build_feature_context_table(feature_master: pd.DataFrame, selected_feature_ids: list) -> pd.DataFrame:
    if not selected_feature_ids:
        return pd.DataFrame(columns=["íŠ¹ì„±ID", "ëŒ€ê³µì¢…", "ì¤‘ê³µì¢…", "ì†Œê³µì¢…", "Cost Driver Method", "Cost Driver Condition"])

    fm = feature_master.copy()
    cols5 = ["ëŒ€ê³µì¢…", "ì¤‘ê³µì¢…", "ì†Œê³µì¢…", "Cost Driver Method", "Cost Driver Condition"]
    keep = ["íŠ¹ì„±ID"] + cols5

    for c in keep:
        if c in fm.columns:
            fm[c] = fm[c].astype(str).fillna("").str.strip()
        else:
            fm[c] = ""

    out = fm[fm["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in selected_feature_ids])][keep].copy()
    out = out.drop_duplicates(subset=["íŠ¹ì„±ID"]).reset_index(drop=True)
    return out


def build_site_context_table(cost_db: pd.DataFrame, selected_site_codes: list) -> pd.DataFrame:
    if not selected_site_codes:
        return pd.DataFrame(columns=["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"])
    tmp = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    tmp = tmp.dropna(subset=["í˜„ì¥ì½”ë“œ"])
    tmp["í˜„ì¥ì½”ë“œ"] = tmp["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    tmp["í˜„ì¥ëª…"] = tmp["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    tmp.loc[tmp["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
    tmp = tmp.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"])
    out = tmp[tmp["í˜„ì¥ì½”ë“œ"].isin([norm_site_code(x) for x in selected_site_codes])].copy()
    out = out.sort_values("í˜„ì¥ì½”ë“œ").reset_index(drop=True)
    return out


def plot_distribution(series: pd.Series, title: str):
    s = pd.to_numeric(series, errors="coerce").dropna()
    fig = plt.figure()
    plt.title(title)
    if len(s) == 0:
        plt.text(0.5, 0.5, "ë°ì´í„° ì—†ìŒ", ha="center", va="center")
    else:
        plt.hist(s.values, bins=30)
        plt.xlabel("ì‚°ì¶œë‹¨ê°€(__adj_price)")
        plt.ylabel("ë¹ˆë„")
    st.pyplot(fig, clear_figure=True)


# =========================
# ğŸ“Š BOQ ë‚´ì—­ë³„ ì‚°ì ë„(ê³„ì•½ë…„ì›” vs ì‚°ì¶œë‹¨ê°€) - í¬í•¨/ë¯¸í¬í•¨ í‘œì‹œ
# =========================
def _parse_contract_month_series(s: pd.Series) -> pd.Series:
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().any():
        s2 = s.astype(str).apply(to_year_month_string)
        dt2 = pd.to_datetime(s2, errors="coerce")
        dt = dt.fillna(dt2)
    return dt


def render_boq_scatter(log_df: pd.DataFrame, base_result: pd.DataFrame):
    if log_df is None or log_df.empty:
        st.info("ë¡œê·¸ ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    keyword = st.text_input("ë‚´ì—­ í‚¤ì›Œë“œ(ì˜ˆ: REBAR)", value="", key="report_kw")
    cand = base_result.copy() if (base_result is not None and not base_result.empty) else None

    if cand is not None and "ë‚´ì—­" in cand.columns and "BOQ_ID" in cand.columns and keyword.strip():
        kw = keyword.strip().lower()
        cand = cand[cand["ë‚´ì—­"].astype(str).str.lower().str.contains(kw, na=False)].copy()

    if cand is not None and not cand.empty:
        boq_ids = cand["BOQ_ID"].dropna().astype(int).unique().tolist()
        boq_ids = sorted(boq_ids)
        id_to_text = cand.set_index(cand["BOQ_ID"].astype(int))["ë‚´ì—­"].astype(str).to_dict()
    else:
        boq_ids = sorted(log_df["BOQ_ID"].dropna().astype(int).unique().tolist())
        id_to_text = (
            log_df.dropna(subset=["BOQ_ID"])
            .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
            .groupby("BOQ_ID")["BOQ_ë‚´ì—­"].first()
            .astype(str).to_dict()
        )

    if not boq_ids:
        st.info("í‘œì‹œí•  BOQ_IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    def fmt(x: int) -> str:
        t = id_to_text.get(int(x), "")
        t = (t[:60] + "â€¦") if len(t) > 60 else t
        return f"{int(x)} | {t}"

    sel = st.selectbox("ê·¸ë˜í”„ ë³¼ BOQ ì„ íƒ", options=boq_ids, format_func=fmt, key="report_boq_pick")

    sub = log_df[log_df["BOQ_ID"].astype(int) == int(sel)].copy()
    if sub.empty:
        st.info("í•´ë‹¹ BOQ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    sub["ê³„ì•½ì›”_dt"] = _parse_contract_month_series(sub["ê³„ì•½ë…„ì›”"])
    sub["ì‚°ì¶œë‹¨ê°€"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
    sub["í¬í•¨ì—¬ë¶€"] = sub["Include"].fillna(False).astype(bool)
    sub["í‘œì‹œë‚´ì—­"] = sub["ë‚´ì—­"].astype(str)

    chart = (
        alt.Chart(sub.dropna(subset=["ê³„ì•½ì›”_dt", "ì‚°ì¶œë‹¨ê°€"]))
        .mark_circle()
        .encode(
            x=alt.X("ê³„ì•½ì›”_dt:T", title="ê³„ì•½ë…„ì›”"),
            y=alt.Y("ì‚°ì¶œë‹¨ê°€:Q", title="ì‚°ì¶œë‹¨ê°€(ì‚°ì¶œí†µí™” ê¸°ì¤€)"),
            color=alt.Color("í¬í•¨ì—¬ë¶€:N", title="í¬í•¨"),
            size=alt.Size("í¬í•¨ì—¬ë¶€:N", title="í¬í•¨(í¬ê¸°)", scale=alt.Scale(range=[40, 140])),
            tooltip=[
                alt.Tooltip("í‘œì‹œë‚´ì—­:N", title="ë‚´ì—­"),
                alt.Tooltip("ì‚°ì¶œë‹¨ê°€:Q", title="ì‚°ì¶œë‹¨ê°€", format=",.4f"),
                alt.Tooltip("í†µí™”:N", title="ì›í†µí™”"),
                alt.Tooltip("ê³„ì•½ë…„ì›”:N", title="ê³„ì•½ë…„ì›”"),
                alt.Tooltip("__hyb:Q", title="ìœ ì‚¬ë„", format=".2f"),
                alt.Tooltip("í˜„ì¥ì½”ë“œ:N", title="í˜„ì¥ì½”ë“œ"),
                alt.Tooltip("í˜‘ë ¥ì‚¬ì½”ë“œ:N", title="í˜‘ë ¥ì‚¬ì½”ë“œ"),
            ],
        )
        .properties(height=420)
        .interactive()
    )
    st.altair_chart(chart, use_container_width=True)


# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"


def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")


@st.cache_data(show_spinner=False)
def load_overseas_data():
    cost_db = load_excel_from_repo("cost_db.xlsx")
    price_index = load_excel_from_repo("price_index.xlsx")
    exchange = load_excel_from_repo("exchange.xlsx")
    factor = load_excel_from_repo("Factor.xlsx")
    project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
    feature_master = load_excel_from_repo("feature_master_FID.xlsx")
    return cost_db, price_index, exchange, factor, project_feature_long, feature_master

@st.cache_data(show_spinner=False)
def load_domestic_data():
    cost_db_kr = load_excel_from_repo("cost_db (kr).xlsx")
    return cost_db_kr

# =========================
# âœ… ì»¬ëŸ¼ëª… í‘œì¤€í™” + alias ë§¤í•‘ (KeyError ë°©ì§€)
# =========================
def _std_colname(s: str) -> str:
    s = str(s)
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [_std_colname(c) for c in df.columns]
    return df


def apply_feature_column_alias(df: pd.DataFrame) -> pd.DataFrame:
    """
    feature_master_FID / project_feature_long ì»¬ëŸ¼ì´ ì¡°ê¸ˆ ë‹¬ë¼ë„
    ì•„ë˜ 'í‘œì¤€ ì»¬ëŸ¼ëª…'ìœ¼ë¡œ ê°•ì œ ë§ì¶¤
    """
    df = df.copy()
    col_map = {}

    aliases = {
        "íŠ¹ì„±ID": ["íŠ¹ì„±ID", "íŠ¹ì„± Id", "FeatureID", "Feature Id", "FID"],
        "ëŒ€ê³µì¢…": ["ëŒ€ê³µì¢…", "ëŒ€ ê³µì¢…", "Major", "Main"],
        "ì¤‘ê³µì¢…": ["ì¤‘ê³µì¢…", "ì¤‘ ê³µì¢…", "Middle"],
        "ì†Œê³µì¢…": ["ì†Œê³µì¢…", "ì†Œ ê³µì¢…", "Minor", "Sub"],

        "Cost Driver Type": [
            "Cost Driver Type", "CostDriver Type", "Cost DriverType",
            "Cost Driver_Type", "CostDriver_Type", "Type", "Driver Type"
        ],
        "Cost Driver Method": [
            "Cost Driver Method", "CostDriver Method", "Cost DriverMethod",
            "Cost Driver_Method", "CostDriver_Method", "Method"
        ],
        "Cost Driver Condition": [
            "Cost Driver Condition", "CostDriver Condition", "Cost DriverCondition",
            "Cost Driver_Condition", "CostDriver_Condition", "Condition"
        ],

        "í˜„ì¥ì½”ë“œ": ["í˜„ì¥ì½”ë“œ", "í˜„ì¥ ì½”ë“œ", "Site Code", "SiteCode"],
        "í˜„ì¥ëª…": ["í˜„ì¥ëª…", "í˜„ì¥ ëª…", "Site Name", "SiteName"],
    }

    cols = list(df.columns)

    for std_name, cand_list in aliases.items():
        for cand in cand_list:
            cand_std = _std_colname(cand)
            if cand_std in cols:
                col_map[cand_std] = std_name
                break

    df = df.rename(columns=col_map)

    must_cols = [
        "íŠ¹ì„±ID", "ëŒ€ê³µì¢…", "ì¤‘ê³µì¢…", "ì†Œê³µì¢…",
        "Cost Driver Type", "Cost Driver Method", "Cost Driver Condition"
    ]
    for c in must_cols:
        if c not in df.columns:
            df[c] = ""

    return df

# =========================
# âœ… ë°ì´í„° ë¡œë“œ + í‘œì¤€í™”/alias ì ìš© (í•¨ìˆ˜ ì •ì˜ ì´í›„ì— 1íšŒë§Œ)
# =========================
cost_db, price_index, exchange, factor, project_feature_long, feature_master = load_overseas_data()
cost_db_kr = load_domestic_data()

# (ê¶Œì¥) DBë„ í‘œì¤€í™”
cost_db = standardize_columns(cost_db)
cost_db_kr = standardize_columns(cost_db_kr)

# feature ê´€ë ¨ í‘œì¤€í™”/alias
project_feature_long = standardize_columns(project_feature_long)
feature_master = standardize_columns(feature_master)

project_feature_long = apply_feature_column_alias(project_feature_long)
feature_master = apply_feature_column_alias(feature_master)



# =========================
# Session init
# =========================
if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []
if "auto_sites" not in st.session_state:
    st.session_state["auto_sites"] = []

# âœ… íƒ­ ì „í™˜ ìƒíƒœ(ì‚¬ì´ë“œë°” ì¤‘ë³µ ë Œë” ë°©ì§€ìš©)
if "active_db" not in st.session_state:
    st.session_state["active_db"] = "overseas"


# ============================================================
# âœ… êµ­ë‚´ íƒ­ (UI skeleton only)
# ============================================================
def render_domestic():
    gs_header("ğŸ“¦ êµ­ë‚´ ì‹¤ì ë‹¨ê°€ DB")

    # -------------------------
    # Sidebar: ì„¤ì •(êµ­ë‚´)
    # -------------------------
    st.sidebar.markdown("<div class='sb-major'>âš™ï¸ ì„¤ì •(êµ­ë‚´)</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    # 1) BOQ ì—…ë¡œë“œ
    with st.container(border=True):
        card_title("ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ(êµ­ë‚´)")
        dom_boq_file = st.file_uploader(
            label="",
            type=["xlsx"],
            key="dom_boq_uploader",
            label_visibility="collapsed",
        )

    # 2) êµ­ë‚´ í•„í„°(í˜„ì¥íŠ¹ì„±/í˜„ì¥)
    # - "í•´ì™¸ íŠ¹ì„± ì„ íƒ"ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , êµ­ë‚´ëŠ” "í˜„ì¥íŠ¹ì„±" ê¸°ì¤€ìœ¼ë¡œ í•„í„° UI ì œê³µ
    kr = cost_db_kr.copy()

    # í˜„ì¥íŠ¹ì„±
    feat_col = "í˜„ì¥íŠ¹ì„±"
    if feat_col not in kr.columns:
        kr[feat_col] = ""

    feat_options = sorted([x for x in kr[feat_col].astype(str).fillna("").unique().tolist() if x.strip() and x != "nan"])
    sel_feat = st.sidebar.multiselect(
        "ğŸ·ï¸ í˜„ì¥íŠ¹ì„±(êµ­ë‚´)",
        options=feat_options,
        default=st.session_state.get("dom_sel_feat", []),
        key="dom_sel_feat",
    )

    if sel_feat:
        kr_view = kr[kr[feat_col].astype(str).isin(sel_feat)].copy()
    else:
        kr_view = kr

    # í˜„ì¥ ì„ íƒ(êµ­ë‚´)
    if "í˜„ì¥ì½”ë“œ" not in kr_view.columns:
        kr_view["í˜„ì¥ì½”ë“œ"] = ""
    if "í˜„ì¥ëª…" not in kr_view.columns:
        kr_view["í˜„ì¥ëª…"] = ""

    site_df = kr_view[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    site_df = site_df.dropna(subset=["í˜„ì¥ì½”ë“œ"])
    site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
    site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"]).reset_index(drop=True)

    all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()
    code_to_name = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["í˜„ì¥ëª…"]))

    def fmt_site(code: str) -> str:
        name = code_to_name.get(code, "").strip()
        return (name[:25] + "â€¦") if len(name) > 25 else name

    st.sidebar.markdown(
        f"""
        <div class="sb-row">
          <div class="sb-title">ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ(êµ­ë‚´)</div>
          <div class="sb-muted">ê°€ëŠ¥ í˜„ì¥: {len(all_codes)}ê°œ</div>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    dom_selected_sites = st.sidebar.multiselect(
        "êµ­ë‚´ ì‹¤ì í˜„ì¥",
        options=all_codes,
        default=st.session_state.get("dom_selected_site_codes", []),
        key="dom_selected_site_codes",
        format_func=fmt_site,
    )

    # 3) ì„¤ì •ê°’
    st.sidebar.markdown("<div class='sb-title'>ğŸ§© ì„¤ì •ê°’(êµ­ë‚´)</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    # í•´ì™¸ë‘ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€
    DEFAULT_W_STR = 0.35
    w_str = DEFAULT_W_STR
    w_sem = 1.0 - w_str
    top_k_sem = 200

    dom_sim_threshold = st.sidebar.slider("ë§¤ì¹­ ìœ ì‚¬ë„ ê¸°ì¤€ê°’(%)", 0, 100, 65, 5, key="dom_sim_threshold")
    dom_cut_ratio = st.sidebar.slider("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)", 0, 30, 20, 5, key="dom_cut_ratio") / 100.0

    sidebar_hr(thick=True, mt=10, mb=8)

    # -------------------------
    # Run / Auto Recompute(êµ­ë‚´)
    # -------------------------
    def dom_boq_file_signature(uploaded_file) -> str:
        if uploaded_file is None:
            return "no_boq"
        try:
            b = uploaded_file.getvalue()
            if len(b) > 2_000_000:
                b = b[:1_000_000] + b[-1_000_000:]
            return hashlib.md5(b).hexdigest()
        except Exception:
            return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

    def make_dom_params_signature() -> str:
        payload = {
            "boq": dom_boq_file_signature(dom_boq_file),
            "sel_feat": sorted([str(x) for x in (sel_feat or [])]),
            "sel_sites": sorted([norm_site_code(x) for x in (dom_selected_sites or [])]),
            "sim_threshold": float(dom_sim_threshold),
            "cut_ratio": float(dom_cut_ratio),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "top_k_sem": int(top_k_sem),
        }
        s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(s.encode("utf-8")).hexdigest()

    def run_domestic_and_store(run_sig: str):
        status_box = st.empty()

        if dom_boq_file is None:
            status_box.empty()
            st.warning("êµ­ë‚´ BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            return

        progress = st.progress(0.0)
        prog_text = st.empty()

        status_box.markdown("### â³ [êµ­ë‚´] ì‚°ì¶œì¤‘... (BOQ ë¡œë“œ)")
        boq_kr = pd.read_excel(dom_boq_file, engine="openpyxl")

        # êµ­ë‚´ BOQ ì»¬ëŸ¼ ë³´ê°•(ì²« ì—´: ëª…ì¹­ ê·œê²© ë‹¨ìœ„ ìˆ˜ëŸ‰ ë‹¨ê°€)
        need_boq_cols = ["ëª…ì¹­","ê·œê²©","ë‹¨ìœ„","ìˆ˜ëŸ‰","ë‹¨ê°€"]
        for c in need_boq_cols:
            if c not in boq_kr.columns:
                boq_kr[c] = ""

        # êµ­ë‚´ DB í•„í„° ì ìš©(í˜„ì¥íŠ¹ì„±/í˜„ì¥)
        db_run = cost_db_kr.copy()
        if sel_feat:
            db_run = db_run[db_run["í˜„ì¥íŠ¹ì„±"].astype(str).isin([str(x) for x in sel_feat])].copy()
        if dom_selected_sites:
            db_run = db_run[db_run["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in dom_selected_sites])].copy()

        st.sidebar.caption(f"[êµ­ë‚´] ì „ì²´ {len(cost_db_kr):,}ê°œ ì¤‘ {len(db_run):,}ê°œë¡œ ì‚°ì¶œ")

        pool_sig_payload = {
            "boq": dom_boq_file_signature(dom_boq_file),
            "sel_feat": sorted([str(x) for x in (sel_feat or [])]),
            "sel_sites": sorted([norm_site_code(x) for x in (dom_selected_sites or [])]),
            "top_k_sem": int(top_k_sem),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "db_rows": int(len(db_run)),
        }
        pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

        need_new_pool = (st.session_state.get("dom_candidate_pool_sig") != pool_sig) or ("dom_candidate_pool" not in st.session_state)

        if need_new_pool:
            status_box.markdown("### â³ [êµ­ë‚´] ì‚°ì¶œì¤‘... (í›„ë³´ í’€ ìƒì„±)")
            with st.spinner("[êµ­ë‚´] í›„ë³´ í’€ ìƒì„± ì¤‘..."):
                pool = build_candidate_pool_domestic(
                    cost_db_kr=db_run,
                    boq_kr=boq_kr,
                    sim_w_str=w_str,
                    sim_w_sem=w_sem,
                    top_k_sem=top_k_sem,
                    pool_per_boq=400,
                    progress=progress,
                    prog_text=prog_text,
                )
            st.session_state["dom_candidate_pool"] = pool
            st.session_state["dom_candidate_pool_sig"] = pool_sig
        else:
            pool = st.session_state["dom_candidate_pool"]

        status_box.markdown("### â³ [êµ­ë‚´] ì‚°ì¶œì¤‘...")
        with st.spinner("[êµ­ë‚´] ë¹ ë¥¸ ì¬ê³„ì‚° ì¤‘..."):
            result_df, log_df = fast_recompute_from_pool_domestic(
                pool=pool,
                sim_threshold=dom_sim_threshold,
                cut_ratio=dom_cut_ratio,
            )

        st.session_state["dom_boq_df"] = boq_kr
        st.session_state["dom_result_df_base"] = result_df.copy()
        st.session_state["dom_log_df_base"] = log_df.copy()
        st.session_state["dom_log_df_edited"] = log_df.copy()
        st.session_state["dom_has_results"] = True
        st.session_state["dom_last_run_sig"] = run_sig

    run_dom_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰(êµ­ë‚´)", key="dom_run_btn")

    cur_sig = make_dom_params_signature()
    last_sig = st.session_state.get("dom_last_run_sig", None)
    needs_rerun = (last_sig is not None and cur_sig != last_sig)

    # ìë™ì¬ì‚°ì¶œì€ êµ­ë‚´ë„ ON(ì›í•˜ë©´ Falseë¡œ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤)
    auto_recompute = True
    auto_run = st.session_state.get("dom_has_results", False) and needs_rerun and auto_recompute

    if run_dom_btn or auto_run:
        run_domestic_and_store(cur_sig)

    # -------------------------
    # Tabs(êµ­ë‚´)
    # -------------------------
    tab1, tab2, tab3 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼(êµ­ë‚´)", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸(êµ­ë‚´)", "â¬‡ï¸ ë‹¤ìš´ë¡œë“œ(êµ­ë‚´)"])

    with tab1:
        if not st.session_state.get("dom_has_results", False):
            st.info("êµ­ë‚´ BOQ ì—…ë¡œë“œ í›„ 'ì‚°ì¶œ ì‹¤í–‰(êµ­ë‚´)'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            show_df = st.session_state.get("dom_result_df_base", pd.DataFrame()).copy()
            st.dataframe(show_df, use_container_width=True)

    with tab2:
        if not st.session_state.get("dom_has_results", False):
            st.info("ì‚°ì¶œ ì‹¤í–‰ í›„ ë¡œê·¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
        else:
            st.caption("âœ… BOQë¥¼ ì„ íƒí•œ ë’¤, Include ì²´í¬ë¡œ í¬í•¨/ì œì™¸ë¥¼ í¸ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í•´ì™¸ íƒ­ê³¼ ë™ì¼ UX)")
    
            # í˜„ì¬ í¸ì§‘ ëŒ€ìƒ: ì „ì²´ ë¡œê·¸(edited)
            if "dom_log_df_edited" not in st.session_state:
                st.session_state["dom_log_df_edited"] = st.session_state.get("dom_log_df_base", pd.DataFrame()).copy()
    
            log_all = st.session_state["dom_log_df_edited"]
            if log_all is None or log_all.empty:
                st.warning("ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                # --- BOQ ì„ íƒ ---
                boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())
    
                # ë¼ë²¨(BOQ_ID | ëª…ì¹­/ê·œê²©) ë§Œë“¤ê¸°
                id_to_text = (
                    log_all.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .groupby("BOQ_ID")
                    .apply(lambda g: f'{str(g["BOQ_ëª…ì¹­"].iloc[0])} / {str(g["BOQ_ê·œê²©"].iloc[0])}')
                    .to_dict()
                )
    
                def fmt_boq_id(x: int) -> str:
                    t = id_to_text.get(int(x), "")
                    t = (t[:60] + "â€¦") if len(t) > 60 else t
                    return f"{int(x)} | {t}"
    
                sel_id = st.selectbox(
                    "í¸ì§‘í•  BOQ ì„ íƒ(êµ­ë‚´)",
                    options=boq_ids,
                    format_func=fmt_boq_id,
                    key="dom_sel_boq_id",
                )
    
                # í˜„ì¬ BOQ í›„ë³´ë§Œ ë³´ê¸°
                log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()
                if log_view_full.empty:
                    st.info("í•´ë‹¹ BOQ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # --- ë°±ì—…(ë˜ëŒë¦¬ê¸°) ì €ì¥ì†Œ ---
                    if "dom_include_backup" not in st.session_state:
                        st.session_state["dom_include_backup"] = {}
                    if "dom_include_backup_all" not in st.session_state:
                        st.session_state["dom_include_backup_all"] = None
    
                    # --- AI íŒŒë¼ë¯¸í„°(UI) ---
                    cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
                    with cA:
                        agent_mode = st.selectbox("AI ì¶”ì²œ ëª¨ë“œ(êµ­ë‚´)", ["ë³´ìˆ˜ì ", "ê· í˜•", "ê³µê²©ì "], index=1, key="dom_agent_mode")
                    with cB:
                        min_keep = st.number_input("ìµœì†Œ í¬í•¨", min_value=1, max_value=20, value=3, step=1, key="dom_agent_min_keep")
                    with cC:
                        max_keep = st.number_input("ìµœëŒ€ í¬í•¨", min_value=3, max_value=200, value=50, step=1, key="dom_agent_max_keep")
                    with cD:
                        st.caption("â€» ì ìš© í›„ í™”ë©´ì´ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")
    
                    # --- ë²„íŠ¼(í•´ì™¸ì™€ ë™ì¼) ---
                    b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
                    with b1:
                        btn_ai_one = st.button("ğŸ¤– AI ì ìš©(í˜„ì¬ BOQ)", key="dom_btn_ai_one")
                    with b2:
                        btn_undo_one = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(í˜„ì¬ BOQ)", key="dom_btn_undo_one")
                    with b3:
                        btn_ai_all = st.button("ğŸ¤– AI ì ìš©(ì „ì²´ BOQ)", key="dom_btn_ai_all")
                    with b4:
                        btn_undo_all = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(ì „ì²´ BOQ)", key="dom_btn_undo_all")
    
                    # --- ê²°ê³¼ ì¬ê³„ì‚°(Include ê¸°ë°˜) í•¨ìˆ˜ ---
                    def recompute_dom_result_from_log(cur_log: pd.DataFrame) -> pd.DataFrame:
                        rows = []
                        for boq_id, g in cur_log.groupby("BOQ_ID"):
                            g2 = g[g["Include"] == True]
                            one = g.iloc[0]
                            if g2.empty:
                                price = None
                                reason = "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)"
                            else:
                                price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())
                                reason = f"{len(g2)}ê°œ ë‚´ì—­ í‰ê· (êµ­ë‚´DB)"
                            rows.append({
                                "BOQ_ID": int(boq_id),
                                "ëª…ì¹­": one.get("BOQ_ëª…ì¹­", ""),
                                "ê·œê²©": one.get("BOQ_ê·œê²©", ""),
                                "ë‹¨ìœ„": one.get("BOQ_ë‹¨ìœ„", ""),
                                "ìˆ˜ëŸ‰": one.get("BOQ_ìˆ˜ëŸ‰", ""),
                                "Final Price": f"{price:,.2f}" if price is not None else None,
                                "ì‚°ì¶œê·¼ê±°": reason,
                            })
                        return pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)
    
                    # --- ë˜ëŒë¦¬ê¸°(í˜„ì¬ BOQ) ---
                    if btn_undo_one:
                        backup = st.session_state["dom_include_backup"].get(int(sel_id))
                        if backup is not None and len(backup) == len(log_view_full.index):
                            st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(í˜„ì¬ BOQ)")
                            st.rerun()
                        else:
                            st.warning("ë˜ëŒë¦´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í›„ë³´í–‰ì´ ë³€ê²½ë¨).")
    
                    # --- AI ì ìš©(í˜„ì¬ BOQ) ---
                    if btn_ai_one:
                        # í˜„ì¬ BOQ Include ë°±ì—…
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
    
                        updated, summary = apply_agent_to_log(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            boq_id=int(sel_id),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        if summary:
                            st.success(f"AI ì ìš© ì™„ë£Œ(í˜„ì¬ BOQ): {summary['kept']}/{summary['total']} í¬í•¨, ëª¨ë“œ={summary['mode']}")
                        st.rerun()
    
                    # --- AI ì ìš©(ì „ì²´ BOQ) ---
                    if btn_ai_all:
                        st.session_state["dom_include_backup_all"] = st.session_state["dom_log_df_edited"][["BOQ_ID", "Include"]].copy()
    
                        updated, sum_df = apply_agent_to_all_boqs(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        st.success("AI ì ìš© ì™„ë£Œ(ì „ì²´ BOQ)")
                        if sum_df is not None and not sum_df.empty:
                            st.dataframe(sum_df, use_container_width=True)
                        st.rerun()
    
                    # --- ë˜ëŒë¦¬ê¸°(ì „ì²´ BOQ) ---
                    if btn_undo_all:
                        backup_all = st.session_state.get("dom_include_backup_all")
                        if backup_all is None or backup_all.empty:
                            st.warning("ë˜ëŒë¦´ ì „ì²´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            cur = st.session_state["dom_log_df_edited"].copy()
                            b = backup_all.copy()
                            b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                            cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)
    
                            cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                            cur["Include"] = cur["Include"].fillna(False).astype(bool)
    
                            st.session_state["dom_log_df_edited"] = cur
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(ì „ì²´ BOQ)")
                            st.rerun()

                    # =========================
                    # (êµ­ë‚´) í•„í„°/ì»· ì¡°ì • UI (í˜„ì¬ BOQ)
                    # =========================
                    # í•„í„° ëŒ€ìƒ ì»¬ëŸ¼ ë³´ê°•
                    for c in ["í˜„ì¥ëª…", "ì„¸ë¶€ë¶„ë¥˜", "__hyb", "__adj_price"]:
                        if c not in log_view_full.columns:
                            log_view_full[c] = None
                    
                    # ìˆ«ìí˜• ì •ë¦¬
                    log_view_full["__hyb_num"] = pd.to_numeric(log_view_full["__hyb"], errors="coerce").fillna(0.0)
                    log_view_full["__price_num"] = pd.to_numeric(log_view_full["__adj_price"], errors="coerce").fillna(np.nan)
                    
                    with st.expander("ğŸ” í•„í„°(í˜„ì¥ëª…/ì„¸ë¶€ë¶„ë¥˜/ìœ ì‚¬ë„) + ì»· ë¹„ìœ¨ ì¡°ì •", expanded=True):
                        # 1) í˜„ì¥ëª… í•„í„°
                        site_opts = sorted([
                            x for x in log_view_full["í˜„ì¥ëª…"].astype(str).fillna("").unique().tolist()
                            if x.strip() and x not in ["nan", "None"]
                        ])
                        sel_sites_nm = st.multiselect(
                            "í˜„ì¥ëª… í•„í„°(ì„ íƒ ì‹œ í•´ë‹¹ í˜„ì¥ë§Œ í‘œì‹œ/ì ìš©)",
                            options=site_opts,
                            default=st.session_state.get("dom_f_site_nm", []),
                            key="dom_f_site_nm",
                        )
                    
                        # 2) ì„¸ë¶€ë¶„ë¥˜ í•„í„°
                        sub_opts = sorted([
                            x for x in log_view_full["ì„¸ë¶€ë¶„ë¥˜"].astype(str).fillna("").unique().tolist()
                            if x.strip() and x not in ["nan", "None"]
                        ])
                        sel_sub = st.multiselect(
                            "ì„¸ë¶€ë¶„ë¥˜ í•„í„°(ì„ íƒ ì‹œ í•´ë‹¹ ë¶„ë¥˜ë§Œ í‘œì‹œ/ì ìš©)",
                            options=sub_opts,
                            default=st.session_state.get("dom_f_sub", []),
                            key="dom_f_sub",
                        )
                    
                        # 3) ìœ ì‚¬ë„ í•„í„°(ë²”ìœ„)
                        hyb_min_default = float(st.session_state.get("dom_f_hyb_min", 0.0))
                        hyb_max_default = float(st.session_state.get("dom_f_hyb_max", 100.0))
                        hyb_min, hyb_max = st.slider(
                            "ìœ ì‚¬ë„(__hyb) ë²”ìœ„",
                            min_value=0.0,
                            max_value=100.0,
                            value=(hyb_min_default, hyb_max_default),
                            step=1.0,
                            key="dom_f_hyb_range",
                        )
                        st.session_state["dom_f_hyb_min"] = hyb_min
                        st.session_state["dom_f_hyb_max"] = hyb_max
                    
                        # 4) ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨(í˜„ì¬ BOQ ì „ìš©)
                        cut_pct = st.slider(
                            "ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨(í˜„ì¬ BOQ, %)",
                            min_value=0,
                            max_value=30,
                            value=int(st.session_state.get("dom_cut_pct_tab2", 20)),
                            step=5,
                            key="dom_cut_pct_tab2",
                        )
                        cut_ratio_local = float(cut_pct) / 100.0
                    
                        cbtn1, cbtn2, cbtn3 = st.columns([1.4, 1.2, 1.4])
                        with cbtn1:
                            btn_apply_filter_cut = st.button("âœ‚ï¸ í•„í„°+ì»· ì ìš©(Include ìë™ ì¬ì„¤ì •)", key="dom_btn_apply_filter_cut")
                        with cbtn2:
                            btn_reset_to_default = st.button("â†©ï¸ DefaultIncludeë¡œ ì´ˆê¸°í™”(í˜„ì¬ BOQ)", key="dom_btn_reset_default")
                        with cbtn3:
                            st.caption("â€» â€˜í•„í„°+ì»· ì ìš©â€™ì€ í˜„ì¬ BOQì˜ Includeë¥¼ í•„í„° ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ì„¸íŒ…í•©ë‹ˆë‹¤.")
                    
                    # --- í•„í„° ë§ˆìŠ¤í¬ ìƒì„±(í‘œì‹œ + ì»· ì ìš©ì— ê³µí†µ ì‚¬ìš©) ---
                    mask = pd.Series(True, index=log_view_full.index)
                    
                    if sel_sites_nm:
                        mask &= log_view_full["í˜„ì¥ëª…"].astype(str).isin([str(x) for x in sel_sites_nm])
                    
                    if sel_sub:
                        mask &= log_view_full["ì„¸ë¶€ë¶„ë¥˜"].astype(str).isin([str(x) for x in sel_sub])
                    
                    mask &= log_view_full["__hyb_num"].between(float(hyb_min), float(hyb_max))
                    
                    # í‘œì‹œìš©(í•„í„° ì ìš©ëœ í›„ë³´ë§Œ ë³´ì—¬ì¤Œ)
                    log_view_full_filtered = log_view_full.loc[mask].copy()
                    
                    # --- DefaultInclude ì´ˆê¸°í™”(í˜„ì¬ BOQ) ---
                    if btn_reset_to_default:
                        # ë°±ì—… ì €ì¥(í˜„ì¬ BOQ)
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
                    
                        # DefaultInclude ê¸°ì¤€ìœ¼ë¡œ Include ë³µì›
                        base_inc = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "DefaultInclude"].fillna(False).astype(bool)
                        st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = base_inc.values
                    
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        st.success("í˜„ì¬ BOQë¥¼ DefaultInclude ê¸°ì¤€ìœ¼ë¡œ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    
                    # --- í•„í„°+ì»· ì ìš©(í˜„ì¬ BOQ) ---
                    if btn_apply_filter_cut:
                        # ë°±ì—… ì €ì¥(í˜„ì¬ BOQ)
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
                    
                        # 1) í˜„ì¬ BOQ ì „ì²´ Includeë¥¼ ìš°ì„  Falseë¡œ
                        st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = False
                    
                        # 2) í•„í„° í†µê³¼ í›„ë³´ë§Œ ê°€ì§€ê³  ì»· ì ìš©
                        sub = log_view_full.loc[mask].copy()
                        sub["__price_num"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
                    
                        sub = sub.dropna(subset=["__price_num"]).sort_values("__price_num").copy()
                        n = len(sub)
                        cut = max(0, int(n * cut_ratio_local)) if n > 5 else 0
                    
                        if n == 0:
                            st.warning("í•„í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            if cut > 0:
                                keep_mask = np.zeros(n, dtype=bool)
                                keep_mask[cut:n - cut] = True
                            else:
                                keep_mask = np.ones(n, dtype=bool)
                    
                            kept_index = sub.index[keep_mask]
                            st.session_state["dom_log_df_edited"].loc[kept_index, "Include"] = True
                    
                            # DefaultIncludeë„ ê°™ì´ ê°±ì‹ (ì›í•˜ë©´ ì œê±° ê°€ëŠ¥)
                            st.session_state["dom_log_df_edited"].loc[log_view_full.index, "DefaultInclude"] = False
                            st.session_state["dom_log_df_edited"].loc[kept_index, "DefaultInclude"] = True
                    
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success(f"í•„í„°+ì»· ì ìš© ì™„ë£Œ: {len(kept_index)}/{n} í¬í•¨")
                        st.rerun()
                        
                    # ì´í›„ í¸ì§‘ í™”ë©´ì€ 'í•„í„°ëœ í›„ë³´'ë¥¼ ë³´ì—¬ì£¼ë„ë¡ êµì²´
                    log_view_full = log_view_full_filtered
                    
    
                    # --- í™”ë©´ì— ë³´ì—¬ì¤„ ì»¬ëŸ¼(êµ­ë‚´) ---
                    display_cols = [
                        "Include", "DefaultInclude",
                        "ì‹¤í–‰ëª…ì¹­", "ê·œê²©", "ë‹¨ìœ„", "ìˆ˜ëŸ‰",
                        "ë³´ì •ë‹¨ê°€", "ê³„ì•½ë‹¨ê°€", "ê³„ì•½ì›”",
                        "__adj_price", "__hyb",
                        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…", "í˜„ì¥íŠ¹ì„±",
                        "ì—…ì²´ì½”ë“œ", "ì—…ì²´ëª…",
                        "ê³µì¢…Codeë¶„ë¥˜", "ì„¸ë¶€ë¶„ë¥˜",
                    ]
                    for c in display_cols:
                        if c not in log_view_full.columns:
                            log_view_full[c] = None
    
                    log_view = log_view_full[display_cols].copy()
    
                    edited_view = st.data_editor(
                        log_view,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "Include": st.column_config.CheckboxColumn("í¬í•¨", help="í‰ê· ë‹¨ê°€ ì‚°ì¶œ í¬í•¨/ì œì™¸"),
                            "DefaultInclude": st.column_config.CheckboxColumn("ê¸°ë³¸í¬í•¨", help="ì´ˆê¸° ìë™ í¬í•¨ ì—¬ë¶€(ì»· ë¡œì§)"),
                            "__adj_price": st.column_config.NumberColumn("ì‚°ì¶œë‹¨ê°€", format="%.2f"),
                            "__hyb": st.column_config.NumberColumn("ìœ ì‚¬ë„", format="%.2f"),
                            "ë³´ì •ë‹¨ê°€": st.column_config.NumberColumn("ë³´ì •ë‹¨ê°€", format="%.2f"),
                            "ê³„ì•½ë‹¨ê°€": st.column_config.NumberColumn("ê³„ì•½ë‹¨ê°€", format="%.2f"),
                        },
                        disabled=[c for c in log_view.columns if c not in ["Include"]],
                        key="dom_log_editor_oneboq",
                    )
    
                    # --- í¸ì§‘ ë°˜ì˜(í˜„ì¬ BOQ rowsë§Œ) ---
                    st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values
    
                    # --- ê²°ê³¼ ì¬ê³„ì‚°(Include ë°˜ì˜) ---
                    st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
    
                    # ì°¸ê³ ìš©: í˜„ì¬ BOQ í¬í•¨ í›„ë³´ ìˆ˜
                    inc_n = int(pd.Series(edited_view["Include"]).sum())
                    st.caption(f"í˜„ì¬ BOQ í¬í•¨ í›„ë³´: {inc_n}ê°œ")

    with tab3:
        if not st.session_state.get("dom_has_results", False):
            st.info("ì‚°ì¶œ ì‹¤í–‰ í›„ ë‹¤ìš´ë¡œë“œê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            out_result = st.session_state.get("dom_result_df_adjusted", st.session_state.get("dom_result_df_base", pd.DataFrame())).copy()
            out_log = st.session_state.get("dom_log_df_edited", st.session_state.get("dom_log_df_base", pd.DataFrame())).copy()

            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as writer:
                out_result.to_excel(writer, index=False, sheet_name="boq_with_price_kr")
                out_log.to_excel(writer, index=False, sheet_name="calculation_log_kr")
            bio.seek(0)

            st.download_button(
                "â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ(êµ­ë‚´)",
                data=bio.read(),
                file_name="result_unitrate_kr.xlsx",
                key="dom_download_btn",
            )


# ============================================================
# âœ… í•´ì™¸ íƒ­ (ê¸°ì¡´ ì½”ë“œ ì „ì²´ë¥¼ í•¨ìˆ˜ë¡œ ê°ì‹¼ ë²„ì „)
# ============================================================
def render_overseas():
    gs_header("ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB")

    # =========================
    # Sidebar: ì„¤ì •
    # =========================
    st.sidebar.markdown("<div class='sb-major'>âš™ï¸ ì„¤ì •</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    use_site_filter = True

    DEFAULT_W_STR = 0.3
    DEFAULT_TOP_K_SEM = 200
    w_str = DEFAULT_W_STR
    w_sem = 1.0 - w_str
    top_k_sem = DEFAULT_TOP_K_SEM

    boq_file = None

    # =========================
    # (1) BOQ ì—…ë¡œë“œ (ë¨¼ì €!)
    # =========================
    with st.container(border=True):
        card_title("ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ")
    
        boq_file = st.file_uploader(
            label="",
            type=["xlsx"],
            label_visibility="collapsed",
            key="boq_uploader_overseas",
        )
    # =========================
    # (2) ë©”ì¸: BOQ ì—…ë¡œë“œ ì•„ë˜ íŠ¹ì„± ì„ íƒ UI
    # =========================
    auto_sites = []
    
    if boq_file is not None:
        with st.container(border=True):
            card_title("ğŸ·ï¸ í”„ë¡œì íŠ¸ íŠ¹ì„± ì„ íƒ", "")
            st.markdown(
                "<div class='dash-muted'>í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•˜ë©´ ê´€ë ¨ í˜„ì¥ì´ ìë™ìœ¼ë¡œ ì¶”ì²œë©ë‹ˆë‹¤.</div>",
                unsafe_allow_html=True
            )
    
            fm = feature_master.copy()
    
            cols6 = ["ëŒ€ê³µì¢…", "ì¤‘ê³µì¢…", "ì†Œê³µì¢…", "Cost Driver Type", "Cost Driver Method", "Cost Driver Condition"]
            need_cols = ["íŠ¹ì„±ID"] + cols6
    
            for c in need_cols:
                if c not in fm.columns:
                    fm[c] = ""
                fm[c] = fm[c].astype(str).fillna("").str.strip()
    
            if ("íŠ¹ì„±ID" in project_feature_long.columns) and ("í˜„ì¥ì½”ë“œ" in project_feature_long.columns):
                site_cnt = project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"].nunique().astype(int).to_dict()
            else:
                site_cnt = {}
    
            fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)
    
            fm["ë¼ë²¨"] = fm.apply(
                lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | '
                          f'{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                          f'í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
                axis=1
            )
    
            keyword = st.text_input(
                "íŠ¹ì„± ëª©ë¡ í•„í„°(í‚¤ì›Œë“œ)",
                value="",
                placeholder="ì˜ˆ: DCM, Jet, ì§€ë°˜ê°œëŸ‰, ë„ì‹¬ ...",
                key="feature_keyword_overseas",
            )
    
            fm_view = fm
            if keyword.strip():
                kw = keyword.strip().lower()
                fm_view = fm[fm["ë¼ë²¨"].str.lower().str.contains(kw, na=False)].copy()
    
            options = fm_view["ë¼ë²¨"].tolist()
            label_to_id = dict(zip(fm_view["ë¼ë²¨"], fm_view["íŠ¹ì„±ID"]))
    
            # âœ… í•„í„° ë°”ê¿”ë„ ê¸°ì¡´ ì„ íƒ ìœ ì§€
            master_label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
            master_id_to_label = {}
            for lab, fid in master_label_to_id.items():
                master_id_to_label.setdefault(fid, lab)
    
            current_selected_ids = st.session_state.get("selected_feature_ids", [])
            current_labels = [master_id_to_label[fid] for fid in current_selected_ids if fid in master_id_to_label]
    
            new_selected_labels = st.multiselect(
                "íŠ¹ì„± ì„ íƒ(ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
                options=options,
                default=[lab for lab in current_labels if lab in options],
                key="selected_features_labels_overseas",
            )
    
            new_ids = [label_to_id[lab] for lab in new_selected_labels]
            kept_ids = [
                fid for fid in current_selected_ids
                if (fid in master_id_to_label and master_id_to_label[fid] not in options)
            ]
            merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))
            st.session_state["selected_feature_ids"] = merged_ids
    
            # âœ… auto_sites ê³„ì‚°/ì €ì¥(ê¸°ëŠ¥ ìœ ì§€)
            if merged_ids:
                auto_sites = (
                    project_feature_long[
                        project_feature_long["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in merged_ids])
                    ]["í˜„ì¥ì½”ë“œ"].astype(str).unique().tolist()
                )
            else:
                auto_sites = []
    
            new_auto_sites = sorted({
                norm_site_code(x)
                for x in (auto_sites or [])
                if norm_site_code(x)
            })
            st.session_state["auto_sites"] = new_auto_sites
    
    else:
        st.info("BOQ ì—…ë¡œë“œ í›„ í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # =========================
    # (3) ì‚¬ì´ë“œë°”: ì‹¤ì  í˜„ì¥ ì„ íƒ
    # =========================
    selected_site_codes = None

    if use_site_filter:
        _sel_cnt = len(set(
            st.session_state.get("selected_auto_codes", [])
            + st.session_state.get("selected_extra_codes", [])
        ))
        
        st.sidebar.markdown(
            f"""
            <div class="sb-row">
              <div class="sb-title">ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ</div>
              <div class="sb-muted">ì„ íƒ í˜„ì¥: {_sel_cnt}ê°œ</div>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

        auto_sites = st.session_state.get("auto_sites", [])

        # 1) cost_dbì—ì„œ ì „ì²´ í˜„ì¥ ëª©ë¡ ë§Œë“¤ê¸°
        site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
        site_df = site_df.dropna(subset=["í˜„ì¥ì½”ë“œ"])

        site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
        site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
        site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
        site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"]).reset_index(drop=True)

        all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()
        code_to_name = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["í˜„ì¥ëª…"]))

        auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
        auto_codes = [c for c in auto_codes_raw if c in code_to_name]
        other_codes = [c for c in all_codes if c not in set(auto_codes)]

        def fmt_site_code(code: str) -> str:
            name = code_to_name.get(code, "")
            name = name.strip()
            if len(name) > 25:
                return name[:25] + "â€¦"
            return name

        # âœ… auto í›„ë³´ê°€ ë°”ë€Œë©´ ì¦‰ì‹œ ì „ì²´ ì„ íƒ ìƒíƒœ
        auto_sig = "|".join(auto_codes)
        if st.session_state.get("_auto_sig") != auto_sig:
            st.session_state["_auto_sig"] = auto_sig
            st.session_state["selected_auto_codes"] = list(auto_codes)

        if "selected_auto_codes" not in st.session_state:
            st.session_state["selected_auto_codes"] = list(auto_codes)
        if "selected_extra_codes" not in st.session_state:
            st.session_state["selected_extra_codes"] = []

        selected_auto_codes = st.sidebar.multiselect(
            "ì‹¤ì í˜„ì¥",
            options=auto_codes,
            key="selected_auto_codes",
            format_func=fmt_site_code,
        )

        selected_extra_codes = st.sidebar.multiselect(
            "ì¶”ê°€ ì‹¤ì í˜„ì¥",
            options=other_codes,
            key="selected_extra_codes",
            format_func=fmt_site_code,
        )

        selected_site_codes = sorted(set(selected_auto_codes + selected_extra_codes))

    # =========================
    # ê¸°íƒ€ ìŠ¬ë¼ì´ë”/í†µí™” ì„ íƒ
    # =========================
    st.sidebar.markdown("<div class='sb-title'>ğŸ§© ì„¤ì •ê°’</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    sim_threshold = st.sidebar.slider("ë§¤ì¹­ ìœ ì‚¬ë„ ê¸°ì¤€ê°’(%)", 0, 100, 60, 5)
    cut_ratio = st.sidebar.slider("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)", 0, 30, 20, 5) / 100.0

    target_options = sorted(factor["êµ­ê°€"].astype(str).str.upper().unique().tolist())
    default_idx = target_options.index("KRW") if "KRW" in target_options else 0
    target_currency = st.sidebar.selectbox("ì‚°ì¶œí†µí™”", options=target_options, index=default_idx)

    missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper() == target_currency].empty
    missing_factor = factor[factor["êµ­ê°€"].astype(str).str.upper() == target_currency].empty

    if missing_exchange:
        st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
    if missing_factor:
        st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")

    sidebar_hr(thick=True, mt=10, mb=8)

    # =========================
    # Run / Auto Recompute
    # =========================
    auto_recompute = True  # UIëŠ” ìˆ¨ê¸°ì§€ë§Œ ê¸°ëŠ¥ì€ í•­ìƒ ON

    def boq_file_signature(uploaded_file) -> str:
        if uploaded_file is None:
            return "no_boq"
        try:
            b = uploaded_file.getvalue()
            if len(b) > 2_000_000:
                b = b[:1_000_000] + b[-1_000_000:]
            return hashlib.md5(b).hexdigest()
        except Exception:
            return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

    def make_params_signature() -> str:
        payload = {
            "boq": boq_file_signature(boq_file),
            "use_site_filter": bool(use_site_filter),
            "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
            "sim_threshold": float(sim_threshold),
            "cut_ratio": float(cut_ratio),
            "target_currency": str(target_currency),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "top_k_sem": int(top_k_sem),
        }
        s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(s.encode("utf-8")).hexdigest()

    def run_calculation_and_store(run_sig: str):
        status_box = st.empty()

        if boq_file is None:
            status_box.empty()
            st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
            return
        if missing_exchange or missing_factor:
            status_box.empty()
            st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        progress = st.progress(0.0)
        prog_text = st.empty()

        status_box.markdown("### â³ ì‚°ì¶œì¤‘... (BOQ ë¡œë“œ/í•„í„°ë§)")
        boq = pd.read_excel(boq_file, engine="openpyxl")

        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(f"ì „ì²´ {len(cost_db):,}ê°œ ë‚´ì—­ ì¤‘ {len(cost_db_run):,}ê°œ ë‚´ì—­ìœ¼ë¡œ ì‚°ì¶œ ì‹¤í–‰")

        pool_sig_payload = {
            "boq": boq_file_signature(boq_file),
            "use_site_filter": bool(use_site_filter),
            "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
            "top_k_sem": int(top_k_sem),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "cost_db_rows": int(len(cost_db_run)),
        }
        pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

        need_new_pool = (st.session_state.get("candidate_pool_sig") != pool_sig) or ("candidate_pool" not in st.session_state)

        if need_new_pool:
            status_box.markdown("### â³ ì‚°ì¶œì¤‘... (í›„ë³´ í’€ ìƒì„±)")
            with st.spinner("í›„ë³´ í’€ ìƒì„±(ìµœì´ˆ/í˜„ì¥ë³€ê²½ ì‹œ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)..."):
                pool = build_candidate_pool(
                    cost_db=cost_db_run,
                    boq=boq,
                    price_index=price_index,
                    sim_w_str=w_str,
                    sim_w_sem=w_sem,
                    top_k_sem=top_k_sem,
                    pool_per_boq=400,
                    progress=progress,
                    prog_text=prog_text,
                )
            st.session_state["candidate_pool"] = pool
            st.session_state["candidate_pool_sig"] = pool_sig
        else:
            pool = st.session_state["candidate_pool"]

        status_box.markdown("### â³ ì‚°ì¶œì¤‘...")
        with st.spinner("ë¹ ë¥¸ ì¬ê³„ì‚° ì¤‘)..."):
            result_df, log_df = fast_recompute_from_pool(
                pool=pool,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
            )
        # âœ… ì‚°ì¶œ ì™„ë£Œ í›„ ì§„í–‰ ë¬¸êµ¬/í”„ë¡œê·¸ë ˆìŠ¤ ì œê±° (ë‚¨ëŠ” ë¬¸êµ¬ ë°©ì§€)
        try:
            status_box.empty()
        except Exception:
            pass
        try:
            progress.empty()
        except Exception:
            pass
        try:
            prog_text.empty()
        except Exception:
            pass

        st.session_state["boq_df"] = boq
        st.session_state["result_df_base"] = result_df.copy()
        st.session_state["log_df_base"] = log_df.copy()
        st.session_state["log_df_edited"] = log_df.copy()
        st.session_state.pop("result_df_adjusted", None)
        st.session_state["has_results"] = True
        st.session_state["last_run_sig"] = run_sig

    run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰")
    current_sig = make_params_signature()
    last_sig = st.session_state.get("last_run_sig", None)
    needs_rerun = (last_sig is not None and current_sig != last_sig)

    if st.session_state.get("has_results", False) and needs_rerun and not auto_recompute:
        st.sidebar.warning("âš ï¸ ì¡°ê±´ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‚°ì¶œ ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    auto_run = st.session_state.get("has_results", False) and needs_rerun and auto_recompute

    if run_btn or auto_run:
        if auto_run:
            st.sidebar.info("â„¹ï¸ ì¡°ê±´ ë³€ê²½ ê°ì§€ â†’ ìë™ ì¬ì‚°ì¶œ ì¤‘ (ë¡œê·¸ í¸ì§‘ê°’ì€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤)")
        run_calculation_and_store(current_sig)

    if st.session_state.get("has_results", False):
        boq = st.session_state["boq_df"]
        result_df = st.session_state["result_df_base"]
        log_df = st.session_state["log_df_base"]

        def recompute_result_from_log(edited_log: pd.DataFrame) -> pd.DataFrame:
            base = st.session_state["result_df_base"].copy()

            out_prices = []
            for boq_id, g in edited_log.groupby("BOQ_ID"):
                g2 = g[g["Include"] == True].copy()
                if g2.empty:
                    out_prices.append((int(boq_id), None, target_currency, "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)", ""))
                    continue

                final_price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())

                currencies = sorted(g2["í†µí™”"].astype(str).str.upper().unique().tolist())
                reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(g2)}ê°œ ë‚´ì—­ ê·¼ê±°"

                vc = g2["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
                top_code = vc.index[0] if len(vc) else ""
                top_cnt = int(vc.iloc[0]) if len(vc) else 0
                top_work = f"{top_code} ({top_cnt}/{len(g2)})" if top_code else ""

                out_prices.append((int(boq_id), f"{final_price:,.2f}", target_currency, reason_text, top_work))

            upd = pd.DataFrame(out_prices, columns=["BOQ_ID", "Final Price", "ì‚°ì¶œí†µí™”", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"])

            base = base.drop(
                columns=[c for c in ["Final Price", "ì‚°ì¶œí†µí™”", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in base.columns],
                errors="ignore"
            )
            base = base.merge(upd, on="BOQ_ID", how="left")
            return base

        tab1, tab2, tab3 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸(í¸ì§‘ ê°€ëŠ¥)", "ğŸ“ ê·¼ê±° ë³´ê³ ì„œ"])

        with tab2:
            st.caption("âœ… ì²´í¬ í•´ì œí•˜ë©´ í‰ê· ë‹¨ê°€ ì‚°ì¶œì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. ì²´í¬í•˜ë©´ í¬í•¨ë©ë‹ˆë‹¤.")

            if "log_df_edited" not in st.session_state:
                st.session_state["log_df_edited"] = log_df.copy()

            log_all = st.session_state["log_df_edited"]

            boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())

            base_for_label = st.session_state.get("result_df_base", pd.DataFrame()).copy()
            boq_text_col = "ë‚´ì—­" if ("ë‚´ì—­" in base_for_label.columns) else None

            if boq_text_col and ("BOQ_ID" in base_for_label.columns):
                id_to_text = (
                    base_for_label.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .set_index("BOQ_ID")[boq_text_col]
                    .astype(str)
                    .to_dict()
                )
            else:
                id_to_text = (
                    log_all.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .groupby("BOQ_ID")["BOQ_ë‚´ì—­"].first()
                    .astype(str)
                    .to_dict()
                )

            def fmt_boq_id(x: int) -> str:
                t = id_to_text.get(int(x), "")
                t = (t[:60] + "â€¦") if len(t) > 60 else t
                return f"{int(x)} | {t}"

            sel_id = st.selectbox(
                "í¸ì§‘í•  BOQ ì„ íƒ",
                options=boq_ids,
                format_func=fmt_boq_id,
                key="sel_boq_id"
            )

            log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()

            if "_include_backup" not in st.session_state:
                st.session_state["_include_backup"] = {}
            if "_include_backup_all" not in st.session_state:
                st.session_state["_include_backup_all"] = None

            cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
            with cA:
                agent_mode = st.selectbox("AI ì¶”ì²œ ëª¨ë“œ", ["ë³´ìˆ˜ì ", "ê· í˜•", "ê³µê²©ì "], index=1, key="agent_mode")
            with cB:
                min_keep = st.number_input("ìµœì†Œ í¬í•¨", min_value=1, max_value=20, value=3, step=1, key="agent_min_keep")
            with cC:
                max_keep = st.number_input("ìµœëŒ€ í¬í•¨", min_value=3, max_value=200, value=50, step=1, key="agent_max_keep")
            with cD:
                st.caption("â€» ì ìš© í›„ í™”ë©´ì´ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")

            b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
            with b1:
                btn_ai_one = st.button("ğŸ¤– AI ì ìš©(í˜„ì¬ BOQ)", key="btn_ai_one")
            with b2:
                btn_undo_one = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(í˜„ì¬ BOQ)", key="btn_undo_one")
            with b3:
                btn_ai_all = st.button("ğŸ¤– AI ì ìš©(ì „ì²´ BOQ)", key="btn_ai_all")
            with b4:
                btn_undo_all = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(ì „ì²´ BOQ)", key="btn_undo_all")

            if btn_undo_one:
                backup = st.session_state["_include_backup"].get(int(sel_id))
                if backup is not None and len(backup) == len(log_view_full.index):
                    st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                    st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                    st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(í˜„ì¬ BOQ)")
                    st.rerun()
                else:
                    st.warning("ë˜ëŒë¦´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í›„ë³´í–‰ì´ ë³€ê²½ë¨).")

            if btn_ai_one:
                st.session_state["_include_backup"][int(sel_id)] = st.session_state["log_df_edited"].loc[log_view_full.index, "Include"].copy()
                updated, summary = apply_agent_to_log(
                    log_all=st.session_state["log_df_edited"].copy(),
                    boq_id=int(sel_id),
                    mode=agent_mode,
                    min_keep=int(min_keep),
                    max_keep=int(max_keep),
                )
                st.session_state["log_df_edited"] = updated
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                if summary:
                    st.success(f"AI ì ìš© ì™„ë£Œ(í˜„ì¬ BOQ): {summary['kept']}/{summary['total']} í¬í•¨, ëª¨ë“œ={summary['mode']}")
                record_ai_last_applied("í˜„ì¬ BOQ", agent_mode, int(min_keep), int(max_keep), summary, boq_id=int(sel_id))
                st.rerun()

            if btn_ai_all:
                st.session_state["_include_backup_all"] = st.session_state["log_df_edited"][["BOQ_ID", "Include"]].copy()
                updated, sum_df = apply_agent_to_all_boqs(
                    log_all=st.session_state["log_df_edited"].copy(),
                    mode=agent_mode,
                    min_keep=int(min_keep),
                    max_keep=int(max_keep),
                )
                st.session_state["log_df_edited"] = updated
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("AI ì ìš© ì™„ë£Œ(ì „ì²´ BOQ)")
                if sum_df is not None and not sum_df.empty:
                    st.dataframe(sum_df, use_container_width=True)
                record_ai_last_applied("ì „ì²´ BOQ", agent_mode, int(min_keep), int(max_keep), None)
                st.rerun()

            if btn_undo_all:
                backup_all = st.session_state.get("_include_backup_all")
                if backup_all is None or backup_all.empty:
                    st.warning("ë˜ëŒë¦´ ì „ì²´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    cur = st.session_state["log_df_edited"].copy()
                    b = backup_all.copy()
                    b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                    cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)

                    cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                    cur["Include"] = cur["Include"].fillna(False).astype(bool)

                    st.session_state["log_df_edited"] = cur
                    st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                    st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(ì „ì²´ BOQ)")
                    st.rerun()

            display_cols = [
                "Include", "DefaultInclude",
                "ë‚´ì—­", "Unit",
                "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
                "__adj_price", "ì‚°ì¶œí†µí™”",
                "__cpi_ratio", "__latest_ym",
                "__fx_ratio",
                "__fac_ratio",
                "__hyb",
                "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
                "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
                "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
            ]

            for c in display_cols:
                if c not in log_view_full.columns:
                    log_view_full[c] = None

            log_view = log_view_full[display_cols].copy()

            edited_view = st.data_editor(
                log_view,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Include": st.column_config.CheckboxColumn("í¬í•¨", help="í‰ê· ë‹¨ê°€ ì‚°ì¶œ í¬í•¨/ì œì™¸"),
                    "DefaultInclude": st.column_config.CheckboxColumn("ê¸°ë³¸í¬í•¨", help="ì´ˆê¸° ìë™ í¬í•¨ ì—¬ë¶€(ì»· ë¡œì§)"),
                    "ë‚´ì—­": st.column_config.TextColumn("ë‚´ì—­", width="large"),
                    "Unit": st.column_config.TextColumn("ë‹¨ìœ„(Unit)"),
                    "Unit Price": st.column_config.NumberColumn("ì›ë‹¨ê°€", format="%.4f"),
                    "í†µí™”": st.column_config.TextColumn("ì›í†µí™”"),
                    "ê³„ì•½ë…„ì›”": st.column_config.TextColumn("ê³„ì•½ë…„ì›”"),
                    "__adj_price": st.column_config.NumberColumn("ì‚°ì¶œë‹¨ê°€(ì‚°ì¶œí†µí™” ê¸°ì¤€)", format="%.4f"),
                    "ì‚°ì¶œí†µí™”": st.column_config.TextColumn("ì‚°ì¶œí†µí™”"),
                    "__cpi_ratio": st.column_config.NumberColumn("ë¬¼ê°€ë³´ì •ê³„ìˆ˜(CPI)", format="%.6f"),
                    "__latest_ym": st.column_config.TextColumn("ë¬¼ê°€ì§€ìˆ˜ ìµœì‹ ì›”"),
                    "__fx_ratio": st.column_config.NumberColumn("í™˜ìœ¨ë³´ì •ê³„ìˆ˜", format="%.6f"),
                    "__fac_ratio": st.column_config.NumberColumn("êµ­ê°€ë³´ì •ê³„ìˆ˜(Factor)", format="%.6f"),
                    "__hyb": st.column_config.NumberColumn("ìœ ì‚¬ë„ì ìˆ˜", format="%.2f"),
                    "ê³µì¢…ì½”ë“œ": st.column_config.TextColumn("ê³µì¢…ì½”ë“œ"),
                    "ê³µì¢…ëª…": st.column_config.TextColumn("ê³µì¢…ëª…"),
                    "í˜„ì¥ì½”ë“œ": st.column_config.TextColumn("í˜„ì¥ì½”ë“œ"),
                    "í˜„ì¥ëª…": st.column_config.TextColumn("í˜„ì¥ëª…"),
                    "í˜‘ë ¥ì‚¬ì½”ë“œ": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ì½”ë“œ"),
                    "í˜‘ë ¥ì‚¬ëª…": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ëª…"),
                },
                disabled=[c for c in log_view.columns if c not in ["Include"]],
                key="log_editor",
            )

            st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])

        with tab1:
            show_df = st.session_state.get("result_df_adjusted", result_df).copy()

            if "í†µí™”" in show_df.columns:
                show_df = show_df.drop(columns=["í†µí™”"])

            if "Final Price" in show_df.columns:
                if "ì‚°ì¶œí†µí™”" not in show_df.columns:
                    show_df["ì‚°ì¶œí†µí™”"] = target_currency

                cols = show_df.columns.tolist()
                cols.remove("ì‚°ì¶œí†µí™”")
                fp_idx = cols.index("Final Price")
                cols.insert(fp_idx + 1, "ì‚°ì¶œí†µí™”")
                show_df = show_df[cols]

            st.dataframe(show_df, use_container_width=True)

        with tab3:
            st.markdown("## ğŸ“ ê·¼ê±° ë³´ê³ ì„œ(ìë™ ìƒì„±)")
            st.caption("í˜„ì¬ Include(í¬í•¨) ìƒíƒœ + ì¡°ê±´/ì„ íƒ í˜„ì¥/íŠ¹ì„± + (AI ì ìš© ì‹œ) ìµœì¢… ê¸°ì¤€ì„ í¬í•¨í•©ë‹ˆë‹¤.")

            base_result = st.session_state.get("result_df_adjusted", st.session_state.get("result_df_base", pd.DataFrame()))
            log_for_report = st.session_state.get("log_df_edited", st.session_state.get("log_df_base", pd.DataFrame()))

            st.markdown("### 1) ì°¾ì•„ì•¼ í•  ê³µì¢… íŠ¹ì„±(ì„ íƒëœ í”„ë¡œì íŠ¸ íŠ¹ì„±)")
            sel_features = st.session_state.get("selected_feature_ids", [])
            ft = build_feature_context_table(feature_master, sel_features)
            if ft.empty:
                st.info("ì„ íƒëœ íŠ¹ì„±IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(ft, use_container_width=True)

            st.markdown("### 2) ì°¾ì€ ì‹¤ì  í˜„ì¥ ë¦¬ìŠ¤íŠ¸(ìµœì¢… ì„ íƒ í˜„ì¥)")
            try:
                _sel_sites = selected_site_codes if (selected_site_codes is not None) else []
            except Exception:
                _sel_sites = []
            st_sites = build_site_context_table(cost_db, _sel_sites)
            if st_sites.empty:
                st.info("ì„ íƒëœ í˜„ì¥ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í˜„ì¥ í•„í„° ë¯¸ì‚¬ìš©).")
            else:
                st.dataframe(st_sites, use_container_width=True)

            st.markdown("### 3) ë‹¨ê°€ ì¶”ì¶œ ê·¼ê±°(ì¡°ê±´)")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("Threshold(ì»· ê¸°ì¤€, %)", f"{float(sim_threshold):.0f}")
            with c2:
                st.metric("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨(%)", f"{float(cut_ratio) * 100:.0f}")
            with c3:
                st.metric("ì‚°ì¶œí†µí™”", str(target_currency))

            st.markdown("### 4) AI ì ìš© ì‹œ ìµœì¢… ê¸°ì¤€")
            st.write(get_ai_effective_rule_text())

            st.markdown("### 5) ì‹¤ì  ë‹¨ê°€ BOQ(ê²°ê³¼)")
            if base_result is None or base_result.empty:
                st.warning("ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‚°ì¶œ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            else:
                st.dataframe(base_result, use_container_width=True)

            if st.button("ğŸ“ ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ ", key="btn_build_report"):
                summary_df, detail_df = build_report_tables(log_for_report, base_result)
                st.session_state["report_summary_df"] = summary_df
                st.session_state["report_detail_df"] = detail_df

            summary_df = st.session_state.get("report_summary_df", pd.DataFrame())
            detail_df = st.session_state.get("report_detail_df", pd.DataFrame())

            st.markdown("### 6) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìš”ì•½)")
            if summary_df is None or summary_df.empty:
                st.info("ë³´ê³ ì„œë¥¼ ë³´ë ¤ë©´ 'ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ 'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
            else:
                st.dataframe(summary_df, use_container_width=True)

            st.markdown("### 7) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìƒì„¸: Include=True í›„ë³´)")
            if detail_df is not None and not detail_df.empty:
                st.dataframe(detail_df, use_container_width=True)
            else:
                st.info("Include=True ìƒì„¸ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤(ì „ë¶€ ì œì™¸ë˜ì—ˆê±°ë‚˜ í›„ë³´ê°€ ì—†ìŒ).")

            st.markdown("### 8) ë‚´ì—­ë³„ ë‹¨ê°€ ì ë¶„í¬(ê³„ì•½ë…„ì›” vs ë‹¨ê°€) - í¬í•¨/ë¯¸í¬í•¨")
            render_boq_scatter(log_for_report, base_result)

            out_result = st.session_state.get("result_df_adjusted", result_df).copy()
            out_log = st.session_state.get("log_df_edited", log_df).copy()

        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as writer:
            out_result.to_excel(writer, index=False, sheet_name="boq_with_price")
            out_log.to_excel(writer, index=False, sheet_name="calculation_log")
            rep_sum = st.session_state.get("report_summary_df", pd.DataFrame())
            rep_det = st.session_state.get("report_detail_df", pd.DataFrame())
            if rep_sum is not None and not rep_sum.empty:
                rep_sum.to_excel(writer, index=False, sheet_name="report_summary")
            if rep_det is not None and not rep_det.empty:
                rep_det.to_excel(writer, index=False, sheet_name="report_detail")
        bio.seek(0)
        st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")


# ============================================================
# âœ… ìƒë‹¨ íƒ­(í•´ì™¸/êµ­ë‚´) + ì‚¬ì´ë“œë°” ì¤‘ë³µ ë Œë” ë°©ì§€ ë¡œì§
# - Streamlitì€ íƒ­ì´ ìˆì–´ë„ ì½”ë“œê°€ ë‘˜ ë‹¤ ì‹¤í–‰ë˜ëŠ” ê²½ìš°ê°€ ë§ì•„ì„œ,
#   active_db ìƒíƒœë¡œ "í•œìª½ë§Œ" ì‹¤ì œ ë Œë”í•˜ë„ë¡ êµ¬ì„±
# ============================================================
tab_over, tab_dom = st.tabs(["ğŸŒ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB", "ğŸ‡°ğŸ‡· êµ­ë‚´ ì‹¤ì ë‹¨ê°€ DB"])

with tab_over:
    if st.session_state["active_db"] != "overseas":
        if st.button("ì´ íƒ­ìœ¼ë¡œ ì „í™˜", key="switch_to_overseas"):
            st.session_state["active_db"] = "overseas"
            st.rerun()
        st.info("í˜„ì¬ í™œì„± í™”ë©´ì€ êµ­ë‚´ íƒ­ì…ë‹ˆë‹¤. ì „í™˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ í™œì„±í™”í•˜ì„¸ìš”.")
    else:
        render_overseas()

with tab_dom:
    if st.session_state["active_db"] != "domestic":
        if st.button("ì´ íƒ­ìœ¼ë¡œ ì „í™˜", key="switch_to_domestic"):
            st.session_state["active_db"] = "domestic"
            st.rerun()
        st.info("í˜„ì¬ í™œì„± í™”ë©´ì€ í•´ì™¸ íƒ­ì…ë‹ˆë‹¤. ì „í™˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ í™œì„±í™”í•˜ì„¸ìš”.")
    else:
        render_domestic()













