import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer
import matplotlib.pyplot as plt


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

st.markdown("""
<style>
/* =====================================================
   TOKENS
===================================================== */
:root{
  --bg: #F6F8FC;
  --card: #FFFFFF;
  --text: #0F172A;
  --muted: #64748B;
  --border: rgba(15, 23, 42, 0.10);
  --shadow-sm: 0 6px 14px rgba(15, 23, 42, 0.05);
  --primary: #2563EB;

  --sb-bg: #FFFFFF;
  --sb-border: #E6EAF2;

  --chip-bg: #EEF2FF;
  --chip-border: #C7D2FE;
  --chip-text: #1E3A8A;
}

/* =====================================================
   LAYOUT / TYPO
===================================================== */
[data-testid="stAppViewContainer"]{ background: var(--bg) !important; }
html, body{ font-size: 14px !important; color: var(--text) !important; }
.main{ color: var(--text) !important; }
.main > div{
  padding: 16px 24px 24px 24px !important;
  max-width: 1280px;
  margin: 0 auto;
}

.main h1{ font-size: 26px !important; font-weight: 900 !important; letter-spacing: -0.5px !important; }
.main h2{ font-size: 20px !important; font-weight: 850 !important; letter-spacing: -0.3px !important; }
.main h3{ font-size: 16px !important; font-weight: 850 !important; }
.main .stCaption, .main small{ color: var(--muted) !important; font-size: 12.5px !important; }

/* =====================================================
   CARDS
===================================================== */
.gs-card{
  background: var(--card) !important;
  border: 1px solid var(--border) !important;
  border-radius: 16px !important;
  padding: 18px !important;
  margin: 14px 0 18px 0 !important;
  box-shadow: var(--shadow-sm) !important;
}
.gs-header{
  font-size: 18px !important;
  font-weight: 900 !important;
  letter-spacing: -0.3px !important;
  margin: 6px 0 14px 0 !important;
}

.dash-row{ display:flex; align-items:baseline; justify-content:space-between; gap:10px; margin:0 0 10px 0; }
.dash-title{ font-size: 14px !important; font-weight: 850 !important; letter-spacing: -0.2px !important; }
.dash-muted{ font-size: 12px !important; color: var(--muted) !important; white-space: nowrap !important; }

/* st.container(border=True) Ïπ¥ÎìúÌôî */
div[data-testid="stVerticalBlockBorderWrapper"]{
  background: var(--card) !important;
  border: 1px solid var(--border) !important;
  border-radius: 16px !important;
  padding: 18px !important;
  margin: 14px 0 18px 0 !important;
  box-shadow: var(--shadow-sm) !important;
}
div[data-testid="stVerticalBlockBorderWrapper"] > div{ padding: 0 !important; }

/* =====================================================
   SIDEBAR
===================================================== */
section[data-testid="stSidebar"]{
  background: var(--sb-bg) !important;
  border-right: 1px solid var(--sb-border) !important;
}
section[data-testid="stSidebar"] > div{ padding-top: 14px !important; }
section[data-testid="stSidebar"] hr{
  border: none !important;
  border-top: 1px solid var(--sb-border) !important;
  margin: 10px 0 !important;
}

.sb-row{ display:flex; align-items:baseline; justify-content:space-between; gap:10px; margin:2px 0 6px 0; }
.sb-title{ font-size: 14px !important; font-weight: 800 !important; letter-spacing: -0.2px !important; color: var(--text) !important; }
.sb-muted{ font-size: 12px !important; color: var(--muted) !important; white-space: nowrap !important; }
.sb-major{ font-size: 16px !important; font-weight: 900 !important; margin: 6px 0 10px 0 !important; letter-spacing: -0.2px !important; color: var(--text) !important; }

/* =====================================================
   WIDGETS (ÏµúÏÜåÎßå)
===================================================== */

/* Select / Multiselect Ïª®Ìä∏Î°§ */
div[data-baseweb="select"] > div{
  background: #FFFFFF !important;
  border: 1px solid var(--border) !important;
  border-radius: 12px !important;
  min-height: 42px !important;
  box-shadow: none !important;
}
div[data-baseweb="select"] input{
  color: var(--text) !important;
  -webkit-text-fill-color: var(--text) !important;
  caret-color: var(--text) !important;
  font-size: 13px !important;
}

/* Chip(Tag) */
div[data-baseweb="tag"], span[data-baseweb="tag"]{
  background: var(--chip-bg) !important;
  border: 1px solid var(--chip-border) !important;
  color: var(--chip-text) !important;
  border-radius: 999px !important;
}

/* Text input */
div[data-testid="stTextInput"] div[data-baseweb="input"] > div{
  background: #FFFFFF !important;
  border: 1px solid var(--border) !important;
  border-radius: 12px !important;
  min-height: 42px !important;
  box-shadow: none !important;
}

/* File uploader */
[data-testid="stFileUploaderDropzone"]{
  background: #FFFFFF !important;
  border: 1px dashed rgba(15,23,42,0.18) !important;
  border-radius: 16px !important;
  padding: 16px !important;
}
[data-testid="stFileUploaderDropzone"] button{
  background: var(--primary) !important;
  color: #FFFFFF !important;
  border: 0 !important;
  border-radius: 12px !important;
  font-weight: 800 !important;
}

/* DataFrame/DataEditor: Ïª®ÌÖåÏù¥ÎÑàÎßå ÎùºÏù¥Ìä∏ */
div[data-testid="stDataFrame"],
div[data-testid="stDataEditor"]{
  background: #FFFFFF !important;
  border-radius: 16px !important;
}
/* =====================================================
   TABS ‚Äî ÏÑ†ÌÉùÎê®/ÎØ∏ÏÑ†ÌÉù ÌÅ¨Í∏∞ Î∂ÑÎ¶¨ (Îã®Ïùº Ï†ïÏùòÎ°ú Ï†ïÎ¶¨)
===================================================== */

/* Í∏∞Î≥∏(ÎØ∏ÏÑ†ÌÉù) ÌÉ≠ */
div[data-testid="stTabs"] button[role="tab"],
.stTabs button[role="tab"],
.stTabs [data-baseweb="tab"]{
  font-size: 18px !important;
  font-weight: 700 !important;
  padding: 10px 14px !important;
  line-height: 1.2 !important;
}

/* ÎØ∏ÏÑ†ÌÉù ÌÉ≠ ÎÇ¥Î∂Ä ÌÖçÏä§Ìä∏ */
div[data-testid="stTabs"] button[role="tab"] *,
.stTabs button[role="tab"] *,
.stTabs [data-baseweb="tab"] *{
  font-size: 18px !important;
}

/* ÏÑ†ÌÉùÎêú ÌÉ≠ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"],
.stTabs button[role="tab"][aria-selected="true"],
.stTabs [data-baseweb="tab"][aria-selected="true"]{
  font-size: 24px !important;
  font-weight: 900 !important;
}

/* ÏÑ†ÌÉùÎêú ÌÉ≠ ÎÇ¥Î∂Ä ÌÖçÏä§Ìä∏ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"] *,
.stTabs button[role="tab"][aria-selected="true"] *,
.stTabs [data-baseweb="tab"][aria-selected="true"] *{
  font-size: 24px !important;
}

/* Ïù¥Î™®ÏßÄ/ÌÖçÏä§Ìä∏ Ï†ïÎ†¨ */
div[data-testid="stTabs"] button[role="tab"] > div,
.stTabs button[role="tab"] > div,
.stTabs [data-baseweb="tab"] > div{
  gap: 6px !important;
}

</style>
""", unsafe_allow_html=True)


def sidebar_hr(thick: bool = False, mt: int = 6, mb: int = 6):
    # ‚úÖ Ïó∞Ìïú ÌöåÏÉâ Íµ¨Î∂ÑÏÑ† ÌÜµÏùº
    color = "#D9DDE3"  # Ïó∞Ìïú ÌöåÏÉâ
    h = "3px" if thick else "1px"
    st.sidebar.markdown(
        f"<hr style='margin:{mt}px 0 {mb}px 0; border:none; border-top:{h} solid {color};' />",
        unsafe_allow_html=True
    )

# =========================
# UI Helper (Style-aligned)
# =========================
def gs_header(text: str):
    st.markdown(f"<div class='gs-header'>{text}</div>", unsafe_allow_html=True)

def card_begin():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)

def card_end():
    st.markdown("</div>", unsafe_allow_html=True)

def card_title(title: str, right: str = ""):
    st.markdown(
        f"""
        <div class="dash-row">
          <div class="dash-title">{title}</div>
          <div class="dash-muted">{right}</div>
        </div>
        """,
        unsafe_allow_html=True
    )


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")


model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()


def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None


def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()


def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode())
    hasher.update(tail.encode())
    return hasher.hexdigest()


def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s

def norm_unit_kr(x) -> str:
    if x is None:
        return ""
    s = str(x).strip().lower()
    s = s.replace(" ", "")
    # ÌïÑÏöî Ïãú Ïó¨Í∏∞ÏÑú Îã®ÏúÑ aliasÎ•º Îçî Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî
    alias = {
        "m2": "m2",
        "m3": "m3",
        "ea": "ea",
        "„é•": "m3",
        "„é°": "m2",
        "Í∞ú": "ea",
    }
    return alias.get(s, s)

def norm_kr_boq_text(name, spec) -> str:
    # BOQ: Î™ÖÏπ≠ + Í∑úÍ≤©ÏùÑ Ìï©Ï≥êÏÑú Îß§Ïπ≠ ÌÖçÏä§Ìä∏Î°ú ÏÇ¨Ïö©
    a = "" if pd.isna(name) else str(name)
    b = "" if pd.isna(spec) else str(spec)
    return norm_text(f"{a} {b}")

def norm_kr_db_text(exec_name, spec) -> str:
    # Íµ≠ÎÇ¥ DB: Ïã§ÌñâÎ™ÖÏπ≠ + Í∑úÍ≤©ÏùÑ Ìï©Ï≥êÏÑú Îß§Ïπ≠ ÌÖçÏä§Ìä∏Î°ú ÏÇ¨Ïö©
    a = "" if pd.isna(exec_name) else str(exec_name)
    b = "" if pd.isna(spec) else str(spec)
    return norm_text(f"{a} {b}")

# =========================
# Î≥¥Ï†ï Î°úÏßÅ
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["Íµ≠Í∞Ä"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ÎÖÑÏõî_std"] = df["ÎÖÑÏõî"].apply(to_year_month_string)
        latest_ym = df["ÎÖÑÏõî_std"].dropna().max()
        base = df.loc[df["ÎÖÑÏõî_std"] == contract_ym, "Index"].values
        now = df.loc[df["ÎÖÑÏõî_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None


def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[
            exchange["ÌÜµÌôî"].astype(str).str.upper() == str(from_currency).upper(), "USDÎãπÌôòÏú®"
        ].values
        usd_to = exchange.loc[
            exchange["ÌÜµÌôî"].astype(str).str.upper() == str(to_currency).upper(), "USDÎãπÌôòÏú®"
        ].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0


def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[
            factor["Íµ≠Í∞Ä"].astype(str).str.upper() == str(from_currency).upper(), "ÏßÄÏàò"
        ].values
        f_to = factor.loc[
            factor["Íµ≠Í∞Ä"].astype(str).str.upper() == str(to_currency).upper(), "ÏßÄÏàò"
        ].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud Ìò∏Ìôò: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)


def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"


def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))


def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None


@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index


def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0


def build_candidate_pool(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    sim_w_str: float,
    sim_w_sem: float,
    top_k_sem: int,
    pool_per_boq: int = 400,
    progress=None,
    prog_text=None,
) -> pd.DataFrame:
    """
    ‚úÖ 1Îã®Í≥Ñ(Î¨¥Í±∞ÏõÄ): BOQÎ≥Ñ ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±
    - FAISS Í≤ÄÏÉâ + Î¨∏ÏûêÏó¥ Ï†êÏàò + __hyb Í≥ÑÏÇ∞ÍπåÏßÄ Ïó¨Í∏∞ÏÑúÎßå ÏàòÌñâ
    - ÏÇ∞Ï∂úÌÜµÌôî(FX/Factor)Îäî Ïó¨Í∏∞ÏÑú Í≥ÑÏÇ∞ÌïòÏßÄ ÏïäÏùå(Îπ†Î•∏ Ïû¨Í≥ÑÏÇ∞ÏóêÏÑú Ï≤òÎ¶¨)
    - CPIÎäî ÌÜµÌôî/Í≥ÑÏïΩÏõîÏóêÎßå ÏùòÏ°¥ÌïòÎØÄÎ°ú Ïó¨Í∏∞ÏÑú ÎØ∏Î¶¨ Í≥ÑÏÇ∞Ìï¥ Îë†
    """
    work = cost_db.copy()
    work["__ÎÇ¥Ïó≠_norm"] = work["ÎÇ¥Ïó≠"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_Í≥ÑÏïΩÏõî"] = robust_parse_contract_month(work["Í≥ÑÏïΩÎÖÑÏõî"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_Í≥ÑÏïΩÏõî"].notna())].copy()

    price_index2 = price_index.copy()
    price_index2["ÎÖÑÏõî"] = price_index2["ÎÖÑÏõî"].apply(to_year_month_string)

    fp = file_fingerprint(work, ["__ÎÇ¥Ïó≠_norm", "__Unit_norm", "ÌÜµÌôî", "Unit Price", "_Í≥ÑÏïΩÏõî"])
    embs = compute_or_load_embeddings(work["__ÎÇ¥Ïó≠_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    pool_rows = []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±: {i}/{total} Ï≤òÎ¶¨ Ï§ë‚Ä¶")
        if progress is not None:
            progress.progress(i / total)

        boq_item = str(boq_row.get("ÎÇ¥Ïó≠", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]
            sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        # Unit ÏùºÏπò ÌõÑÎ≥¥Îßå
        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)
        if unit_df.empty:
            continue

        # __hyb Í≥ÑÏÇ∞(Î¨∏ÏûêÏó¥+ÏùòÎØ∏ Ïú†ÏÇ¨ÎèÑ)
        hyb = hybrid_scores(
            boq_text_norm,
            unit_df["__ÎÇ¥Ïó≠_norm"],
            unit_df["__sem"].to_numpy(),
            sim_w_str,
            sim_w_sem
        )
        unit_df["__hyb"] = hyb

        # ÎÑàÎ¨¥ ÌÅ∞ ÌíÄ Î∞©ÏßÄ: hyb ÏÉÅÏúÑ NÍ∞úÎßå Î≥¥Í¥Ä
        unit_df = unit_df.sort_values("__hyb", ascending=False).head(pool_per_boq).copy()

        # CPIÎäî ÌÜµÌôî+Í≥ÑÏïΩÏõî Í∏∞Ï§ÄÏúºÎ°ú ÎØ∏Î¶¨ Í≥ÑÏÇ∞ (ÏÇ∞Ï∂úÌÜµÌôî Î∞îÎÄåÏñ¥ÎèÑ Ïû¨ÏÇ¨Ïö© Í∞ÄÎä•)
        unit_df["__contract_ym"] = unit_df["_Í≥ÑÏïΩÏõî"].apply(to_year_month_string)

        cpi_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("ÌÜµÌôî", "")).upper().strip()
            contract_ym = r.get("__contract_ym", None)
            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index2, c_currency, contract_ym)
            cpi_list.append((cpi_ratio, latest_ym))
        unit_df["__cpi_ratio"] = [x[0] for x in cpi_list]
        unit_df["__latest_ym"] = [x[1] for x in cpi_list]

        # BOQ Î©îÌÉÄ Î∂ôÏù¥Í∏∞
        boq_id = int(i)
        unit_df["BOQ_ID"] = boq_id
        unit_df["BOQ_ÎÇ¥Ïó≠"] = boq_item
        unit_df["BOQ_Unit"] = boq_unit

        pool_rows.append(unit_df)

    if not pool_rows:
        return pd.DataFrame()

    pool = pd.concat(pool_rows, ignore_index=True)

    keep_cols = [
        "BOQ_ID", "BOQ_ÎÇ¥Ïó≠", "BOQ_Unit",
        "Í≥µÏ¢ÖÏΩîÎìú", "Í≥µÏ¢ÖÎ™Ö",
        "ÎÇ¥Ïó≠", "Unit",
        "Unit Price", "ÌÜµÌôî", "Í≥ÑÏïΩÎÖÑÏõî",
        "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö",
        "ÌòëÎ†•ÏÇ¨ÏΩîÎìú", "ÌòëÎ†•ÏÇ¨Î™Ö",
        "__hyb",
        "__cpi_ratio",
        "__latest_ym",
    ]
    for c in keep_cols:
        if c not in pool.columns:
            pool[c] = None
    return pool[keep_cols].copy()


def fast_recompute_from_pool(
    pool: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    ‚úÖ 2Îã®Í≥Ñ(Í∞ÄÎ≤ºÏõÄ): ÌõÑÎ≥¥ ÌíÄÏóêÏÑú Îπ†Î•∏ Ïû¨Í≥ÑÏÇ∞
    - Threshold ÌïÑÌÑ∞
    - ÏÇ∞Ï∂úÌÜµÌôî Î≥ÄÍ≤Ω: __fx_ratio, __fac_ratioÎßå Îã§Ïãú Í≥ÑÏÇ∞
    - Ïª∑ÎπÑÏú®Î°ú Include/DefaultInclude ÏÑ§Ï†ï
    - __adj_price = Unit Price * __cpi_ratio * __fx_ratio * __fac_ratio
    """
    if pool is None or pool.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = pool.copy()

    # 1) Threshold Ï†ÅÏö©
    df["__hyb"] = pd.to_numeric(df["__hyb"], errors="coerce").fillna(0.0)
    df = df[df["__hyb"] >= float(sim_threshold)].copy()
    if df.empty:
        return pd.DataFrame(), pd.DataFrame()

    # 2) FX/Factor Îßµ(ÌÜµÌôîÎ≥Ñ)
    df["ÌÜµÌôî_std"] = df["ÌÜµÌôî"].astype(str).str.upper().str.strip()
    currencies = df["ÌÜµÌôî_std"].dropna().unique().tolist()

    fx_map = {c: get_exchange_rate(exchange, c, target_currency) for c in currencies}
    fac_map = {c: get_factor_ratio(factor, c, target_currency) for c in currencies}

    df["__fx_ratio"] = df["ÌÜµÌôî_std"].map(fx_map).fillna(1.0)
    df["__fac_ratio"] = df["ÌÜµÌôî_std"].map(fac_map).fillna(1.0)
    df["ÏÇ∞Ï∂úÌÜµÌôî"] = target_currency

    # 3) __adj_price Í≥ÑÏÇ∞
    unit_price = pd.to_numeric(df["Unit Price"], errors="coerce").fillna(0.0)
    cpi_ratio = pd.to_numeric(df["__cpi_ratio"], errors="coerce").fillna(1.0)
    df["__adj_price"] = unit_price * cpi_ratio * df["__fx_ratio"] * df["__fac_ratio"]

    # 4) BOQÎ≥Ñ Ïª∑ + Include/DefaultInclude ÏÑ§Ï†ï
    df["Include"] = False
    df["DefaultInclude"] = False

    for boq_id, gidx in df.groupby("BOQ_ID").groups.items():
        sub = df.loc[gidx].sort_values("__adj_price").copy()
        n = len(sub)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n - cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        kept_index = sub.index[keep_mask]
        df.loc[kept_index, "DefaultInclude"] = True
        df.loc[kept_index, "Include"] = True

    # 5) BOQ Í≤∞Í≥º(result_df)
    results = []
    for boq_id, sub in df.groupby("BOQ_ID"):
        inc = sub[sub["Include"] == True]

        if inc.empty:
            final_price = None
            reason_text = "Îß§Ïπ≠ ÌõÑÎ≥¥ ÏóÜÏùå(ÎòêÎäî Ï†ÑÎ∂Ä Ï†úÏô∏)"
            top_work = ""
        else:
            final_price = float(pd.to_numeric(inc["__adj_price"], errors="coerce").mean())
            currencies2 = sorted(inc["ÌÜµÌôî_std"].unique().tolist())
            reason_text = f"{len(currencies2)}Í∞úÍµ≠({', '.join(currencies2)}) {len(inc)}Í∞ú ÎÇ¥Ïó≠ Í∑ºÍ±∞"

            vc = inc["Í≥µÏ¢ÖÏΩîÎìú"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(inc)})" if top_code else ""

        one = sub.iloc[0]
        results.append({
            "BOQ_ID": int(boq_id),
            "ÎÇ¥Ïó≠": one.get("BOQ_ÎÇ¥Ïó≠", ""),
            "Unit": one.get("BOQ_Unit", ""),
            "Final Price": f"{final_price:,.2f}" if final_price is not None else None,
            "ÏÇ∞Ï∂úÌÜµÌôî": target_currency,
            "ÏÇ∞Ï∂úÍ∑ºÍ±∞": reason_text,
            "Í∑ºÍ±∞Í≥µÏ¢Ö(ÏµúÎπà)": top_work,
        })

    result_df = pd.DataFrame(results).sort_values("BOQ_ID").reset_index(drop=True)

    # 6) ÏÇ∞Ï∂ú Î°úÍ∑∏(log_df)
    log_cols = [
        "BOQ_ID", "BOQ_ÎÇ¥Ïó≠", "BOQ_Unit",
        "Include", "DefaultInclude",
        "Í≥µÏ¢ÖÏΩîÎìú", "Í≥µÏ¢ÖÎ™Ö",
        "ÎÇ¥Ïó≠", "Unit",
        "Unit Price", "ÌÜµÌôî", "Í≥ÑÏïΩÎÖÑÏõî",
        "__adj_price", "ÏÇ∞Ï∂úÌÜµÌôî",
        "__cpi_ratio", "__latest_ym",
        "__fx_ratio", "__fac_ratio",
        "__hyb",
        "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö",
        "ÌòëÎ†•ÏÇ¨ÏΩîÎìú", "ÌòëÎ†•ÏÇ¨Î™Ö",
    ]
    for c in log_cols:
        if c not in df.columns:
            df[c] = None
    log_df = df[log_cols].copy()

    return result_df, log_df

def build_candidate_pool_domestic(
    cost_db_kr: pd.DataFrame,
    boq_kr: pd.DataFrame,
    sim_w_str: float,
    sim_w_sem: float,
    top_k_sem: int,
    pool_per_boq: int = 400,
    progress=None,
    prog_text=None,
) -> pd.DataFrame:
    """
    Íµ≠ÎÇ¥ 1Îã®Í≥Ñ(Î¨¥Í±∞ÏõÄ): BOQÎ≥Ñ ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±
    - Î¨∏ÏûêÏó¥+ÏûÑÎ≤†Îî© ÌïòÏù¥Î∏åÎ¶¨ÎìúÎ°ú ÌõÑÎ≥¥ ÏÉùÏÑ±
    - Îã®ÏúÑ ÏùºÏπò ÌïÑÏàò
    - Î≥¥Ï†ïÎã®Í∞Ä(ÏûàÏúºÎ©¥) Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ Í≥ÑÏïΩÎã®Í∞ÄÎ•º __price_rawÎ°ú ÏÇ¨Ïö©
    - fast_recompute_from_pool_domesticÏóêÏÑú threshold/cut/include Ï≤òÎ¶¨
    """

    if cost_db_kr is None or cost_db_kr.empty or boq_kr is None or boq_kr.empty:
        return pd.DataFrame()

    # 0) BOQ ÌëúÏ§Ä Ïª¨Îüº Î≥¥Í∞ï
    b = boq_kr.copy()
    need_boq_cols = ["Î™ÖÏπ≠", "Í∑úÍ≤©", "Îã®ÏúÑ", "ÏàòÎüâ", "Îã®Í∞Ä"]
    for c in need_boq_cols:
        if c not in b.columns:
            b[c] = ""

    # 1) DB ÌëúÏ§Ä Ïª¨Îüº Î≥¥Í∞ï
    db = cost_db_kr.copy()

    # Íµ≠ÎÇ¥ DBÏóêÏÑú ÏÇ¨Ïö©Ìï† Ïª¨ÎüºÎì§(ÏóÜÏúºÎ©¥ ÎπàÍ∞í ÏÉùÏÑ±)
    # Ïã§ÌñâÎ™ÖÏπ≠/Í∑úÍ≤©/Îã®ÏúÑ/ÏàòÎüâ/Í≥ÑÏïΩÎã®Í∞Ä/Î≥¥Ï†ïÎã®Í∞Ä/Í≥ÑÏïΩÏõîÏùÄ Ïù¥ÌõÑ ÏÇ∞Ï∂ú/Î°úÍ∑∏Ïóê ÌïÑÏöî
    must = [
        "ÌòÑÏû•ÏΩîÎìú","ÌòÑÏû•Î™Ö","ÌòÑÏû•ÌäπÏÑ±",
        "Ïã§ÌñâÎ™ÖÏπ≠","Í∑úÍ≤©","Îã®ÏúÑ","ÏàòÎüâ",
        "Í≥ÑÏïΩÎã®Í∞Ä","Î≥¥Ï†ïÎã®Í∞Ä","Í≥ÑÏïΩÏõî",
        "ÏóÖÏ≤¥ÏΩîÎìú","ÏóÖÏ≤¥Î™Ö",
        "Í≥µÏ¢ÖCodeÎ∂ÑÎ•ò","ÏÑ∏Î∂ÄÎ∂ÑÎ•ò",
    ]
    for c in must:
        if c not in db.columns:
            db[c] = ""

    # 2) Îß§Ïπ≠Ïö© ÌÖçÏä§Ìä∏/Îã®ÏúÑ Ï†ïÍ∑úÌôî
    db["__db_text_norm"] = db.apply(lambda r: norm_kr_db_text(r.get("Ïã§ÌñâÎ™ÖÏπ≠",""), r.get("Í∑úÍ≤©","")), axis=1)
    db["__unit_norm"] = db["Îã®ÏúÑ"].apply(norm_unit_kr)

    # Í∞ÄÍ≤© ÏõêÏ≤ú: Î≥¥Ï†ïÎã®Í∞Ä Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ Í≥ÑÏïΩÎã®Í∞Ä
    price_adj = pd.to_numeric(db["Î≥¥Ï†ïÎã®Í∞Ä"], errors="coerce")
    price_ctr = pd.to_numeric(db["Í≥ÑÏïΩÎã®Í∞Ä"], errors="coerce")
    db["__price_raw"] = price_adj.where(price_adj.notna() & (price_adj > 0), price_ctr)
    db = db[pd.to_numeric(db["__price_raw"], errors="coerce").fillna(0) > 0].copy()

    if db.empty:
        return pd.DataFrame()

    # 3) ÏûÑÎ≤†Îî©(Íµ≠ÎÇ¥ DB)
    fp = file_fingerprint(db, ["__db_text_norm", "__unit_norm", "__price_raw"])
    embs = compute_or_load_embeddings(db["__db_text_norm"], tag=f"costdb_kr_{fp}")

    index = build_faiss_index(embs) if FAISS_OK else None

    pool_rows = []
    total = len(b) if len(b) else 1

    for i, (_, r) in enumerate(b.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"[Íµ≠ÎÇ¥] ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±: {i}/{total} Ï≤òÎ¶¨ Ï§ë‚Ä¶")
        if progress is not None:
            progress.progress(i / total)

        boq_name = str(r.get("Î™ÖÏπ≠", ""))
        boq_spec = str(r.get("Í∑úÍ≤©", ""))
        boq_unit = norm_unit_kr(r.get("Îã®ÏúÑ", ""))

        boq_text_norm = norm_kr_boq_text(boq_name, boq_spec)

        # Query embedding
        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        # semantic topK
        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]
            sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand = db.iloc[cand_idx].copy()
        cand["__sem"] = sem_scores

        # Îã®ÏúÑ ÏùºÏπò ÌïÑÏàò
        cand = cand[cand["__unit_norm"] == boq_unit].reset_index(drop=True)
        if cand.empty:
            continue

        # hybrid score
        hyb = hybrid_scores(
            boq_text_norm,
            cand["__db_text_norm"],
            cand["__sem"].to_numpy(),
            sim_w_str,
            sim_w_sem,
        )
        cand["__hyb"] = hyb

        cand = cand.sort_values("__hyb", ascending=False).head(pool_per_boq).copy()

        # BOQ Î©îÌÉÄ
        cand["BOQ_ID"] = int(i)
        cand["BOQ_Î™ÖÏπ≠"] = boq_name
        cand["BOQ_Í∑úÍ≤©"] = boq_spec
        cand["BOQ_Îã®ÏúÑ"] = boq_unit
        cand["BOQ_ÏàòÎüâ"] = r.get("ÏàòÎüâ", "")
        cand["BOQ_Îã®Í∞Ä"] = r.get("Îã®Í∞Ä", "")

        pool_rows.append(cand)

    if not pool_rows:
        return pd.DataFrame()

    pool = pd.concat(pool_rows, ignore_index=True)

    # Î°úÍ∑∏/ÌõÑÏÜç Ï≤òÎ¶¨ÏóêÏÑú ÌïÑÏöîÌïú Ïª¨ÎüºÎì§ Ìè¨Ìï®Ìï¥ÏÑú Î∞òÌôò
    keep_cols = [
        "BOQ_ID","BOQ_Î™ÖÏπ≠","BOQ_Í∑úÍ≤©","BOQ_Îã®ÏúÑ","BOQ_ÏàòÎüâ","BOQ_Îã®Í∞Ä",
        "ÌòÑÏû•ÏΩîÎìú","ÌòÑÏû•Î™Ö","ÌòÑÏû•ÌäπÏÑ±",
        "Ïã§ÌñâÎ™ÖÏπ≠","Í∑úÍ≤©","Îã®ÏúÑ","ÏàòÎüâ",
        "Í≥ÑÏïΩÎã®Í∞Ä","Î≥¥Ï†ïÎã®Í∞Ä","Í≥ÑÏïΩÏõî",
        "ÏóÖÏ≤¥ÏΩîÎìú","ÏóÖÏ≤¥Î™Ö",
        "Í≥µÏ¢ÖCodeÎ∂ÑÎ•ò","ÏÑ∏Î∂ÄÎ∂ÑÎ•ò",
        "__price_raw","__hyb",
    ]
    for c in keep_cols:
        if c not in pool.columns:
            pool[c] = None

    return pool[keep_cols].copy()

def fast_recompute_from_pool_domestic(
    pool: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Íµ≠ÎÇ¥ 2Îã®Í≥Ñ(Í∞ÄÎ≤ºÏõÄ)
    - threshold Ï†ÅÏö©
    - Ïª∑ Ï†ÅÏö© ÌõÑ Include/DefaultInclude ÏÑ§Ï†ï
    - ÏÇ∞Ï∂úÎã®Í∞Ä = __price_raw(Î≥¥Ï†ïÎã®Í∞Ä/Í≥ÑÏïΩÎã®Í∞Ä)
    """
    if pool is None or pool.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = pool.copy()
    df["__hyb"] = pd.to_numeric(df["__hyb"], errors="coerce").fillna(0.0)
    df = df[df["__hyb"] >= float(sim_threshold)].copy()
    if df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df["__adj_price"] = pd.to_numeric(df["__price_raw"], errors="coerce").fillna(0.0)

    df["Include"] = False
    df["DefaultInclude"] = False

    for boq_id, gidx in df.groupby("BOQ_ID").groups.items():
        sub = df.loc[gidx].sort_values("__adj_price").copy()
        n = len(sub)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n - cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        kept_index = sub.index[keep_mask]
        df.loc[kept_index, "DefaultInclude"] = True
        df.loc[kept_index, "Include"] = True

    # BOQ Í≤∞Í≥º
    results = []
    for boq_id, sub in df.groupby("BOQ_ID"):
        inc = sub[sub["Include"] == True]
        one = sub.iloc[0]

        if inc.empty:
            final_price = None
            reason_text = "Îß§Ïπ≠ ÌõÑÎ≥¥ ÏóÜÏùå(ÎòêÎäî Ï†ÑÎ∂Ä Ï†úÏô∏)"
        else:
            final_price = float(pd.to_numeric(inc["__adj_price"], errors="coerce").mean())
            reason_text = f"{len(inc)}Í∞ú ÎÇ¥Ïó≠ ÌèâÍ∑†(Íµ≠ÎÇ¥DB)"

        results.append({
            "BOQ_ID": int(boq_id),
            "Î™ÖÏπ≠": one.get("BOQ_Î™ÖÏπ≠", ""),
            "Í∑úÍ≤©": one.get("BOQ_Í∑úÍ≤©", ""),
            "Îã®ÏúÑ": one.get("BOQ_Îã®ÏúÑ", ""),
            "ÏàòÎüâ": one.get("BOQ_ÏàòÎüâ", ""),
            "Final Price": f"{final_price:,.2f}" if final_price is not None else None,
            "ÏÇ∞Ï∂úÍ∑ºÍ±∞": reason_text,
        })

    result_df = pd.DataFrame(results).sort_values("BOQ_ID").reset_index(drop=True)

    log_cols = [
        "BOQ_ID","BOQ_Î™ÖÏπ≠","BOQ_Í∑úÍ≤©","BOQ_Îã®ÏúÑ","BOQ_ÏàòÎüâ","BOQ_Îã®Í∞Ä",
        "Include","DefaultInclude",
        "ÌòÑÏû•ÏΩîÎìú","ÌòÑÏû•Î™Ö","ÌòÑÏû•ÌäπÏÑ±",
        "Ïã§ÌñâÎ™ÖÏπ≠","Í∑úÍ≤©","Îã®ÏúÑ","ÏàòÎüâ",
        "Í≥ÑÏïΩÎã®Í∞Ä","Î≥¥Ï†ïÎã®Í∞Ä","Í≥ÑÏïΩÏõî",
        "ÏóÖÏ≤¥ÏΩîÎìú","ÏóÖÏ≤¥Î™Ö",
        "Í≥µÏ¢ÖCodeÎ∂ÑÎ•ò","ÏÑ∏Î∂ÄÎ∂ÑÎ•ò",
        "__adj_price","__hyb",
    ]
    for c in log_cols:
        if c not in df.columns:
            df[c] = None
    log_df = df[log_cols].copy()

    return result_df, log_df


# =========================
# ü§ñ Include ÏûêÎèô Ï∂îÏ≤ú ÏóêÏù¥Ï†ÑÌä∏(Î£∞ Í∏∞Î∞ò)
# =========================
def _to_num(s):
    return pd.to_numeric(s, errors="coerce")


def suggest_include_for_one_boq(
    df_boq: pd.DataFrame,
    mode: str = "Í∑†Ìòï",
    min_keep: int = 3,
    max_keep: int = 50,
):
    d = df_boq.copy()

    hyb = _to_num(d.get("__hyb", 0)).fillna(0.0)
    price = _to_num(d.get("__adj_price", np.nan))

    if mode == "Î≥¥ÏàòÏ†Å":
        hyb_min = 80
        iqr_k = 1.0
    elif mode == "Í≥µÍ≤©Ï†Å":
        hyb_min = 60
        iqr_k = 2.0
    else:  # Í∑†Ìòï
        hyb_min = 70
        iqr_k = 1.5

    keep = hyb >= hyb_min

    valid = price[price.notna()]
    low = high = None
    if len(valid) >= 5:
        q1 = valid.quantile(0.25)
        q3 = valid.quantile(0.75)
        iqr = q3 - q1
        low = q1 - iqr_k * iqr
        high = q3 + iqr_k * iqr
        keep = keep & (price.between(low, high) | price.isna())

    keep_idx = d.index[keep].tolist()
    if len(keep_idx) < int(min_keep):
        top_idx = hyb.sort_values(ascending=False).head(int(min_keep)).index.tolist()
        keep_idx = sorted(set(keep_idx) | set(top_idx))

    if len(keep_idx) > int(max_keep):
        keep_idx = hyb.loc[keep_idx].sort_values(ascending=False).head(int(max_keep)).index.tolist()

    include = pd.Series(False, index=d.index)
    include.loc[keep_idx] = True

    reasons = []
    for idx in d.index:
        r = []
        if hyb.loc[idx] < hyb_min:
            r.append(f"Ïú†ÏÇ¨ÎèÑ<{hyb_min}")
        if low is not None and high is not None and pd.notna(price.loc[idx]):
            if price.loc[idx] < low or price.loc[idx] > high:
                r.append("Îã®Í∞ÄÏù¥ÏÉÅÏπò(IQR)")
        if include.loc[idx]:
            reasons.append("Ìè¨Ìï®" if not r else "Ìè¨Ìï®(ÏòàÏô∏Î≥¥ÏôÑ): " + ", ".join(r))
        else:
            reasons.append("Ï†úÏô∏" if not r else "Ï†úÏô∏: " + ", ".join(r))

    summary = {
        "mode": mode,
        "hyb_min": hyb_min,
        "iqr_k": iqr_k,
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
        "kept": int(include.sum()),
        "total": int(len(d)),
    }
    return include, pd.Series(reasons, index=d.index), summary


def apply_agent_to_log(
    log_all: pd.DataFrame,
    boq_id: int,
    mode: str = "Í∑†Ìòï",
    min_keep: int = 3,
    max_keep: int = 50,
):
    mask = log_all["BOQ_ID"].astype(int) == int(boq_id)
    sub = log_all.loc[mask].copy()
    if sub.empty:
        return log_all, None

    inc, reason_s, summary = suggest_include_for_one_boq(sub, mode=mode, min_keep=min_keep, max_keep=max_keep)

    if "AI_Ï∂îÏ≤úÏÇ¨Ïú†" not in log_all.columns:
        log_all["AI_Ï∂îÏ≤úÏÇ¨Ïú†"] = ""
    if "AI_Î™®Îìú" not in log_all.columns:
        log_all["AI_Î™®Îìú"] = ""

    log_all.loc[mask, "Include"] = inc.values
    log_all.loc[mask, "AI_Ï∂îÏ≤úÏÇ¨Ïú†"] = reason_s.values
    log_all.loc[mask, "AI_Î™®Îìú"] = mode

    return log_all, summary


def apply_agent_to_all_boqs(
    log_all: pd.DataFrame,
    mode: str = "Í∑†Ìòï",
    min_keep: int = 3,
    max_keep: int = 50,
):
    rows = []
    for boq_id in sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist()):
        log_all, summary = apply_agent_to_log(log_all, boq_id, mode=mode, min_keep=min_keep, max_keep=max_keep)
        if summary:
            rows.append([boq_id, summary["kept"], summary["total"], summary["mode"]])
    sum_df = pd.DataFrame(rows, columns=["BOQ_ID", "Ìè¨Ìï®Ïàò", "ÌõÑÎ≥¥Ïàò", "Î™®Îìú"])
    return log_all, sum_df


# =========================
# üìù Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú ÏÉùÏÑ±(ÏöîÏïΩ/ÏÉÅÏÑ∏)
# =========================
def build_report_tables(log_df: pd.DataFrame, result_df: pd.DataFrame):
    if log_df is None or log_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = log_df.copy()
    df["BOQ_ID"] = df["BOQ_ID"].astype(int)

    inc = df[df["Include"] == True].copy()

    detail_cols = [
        "BOQ_ID", "BOQ_ÎÇ¥Ïó≠", "BOQ_Unit",
        "ÎÇ¥Ïó≠", "Unit", "Unit Price", "ÌÜµÌôî", "Í≥ÑÏïΩÎÖÑÏõî",
        "__adj_price", "ÏÇ∞Ï∂úÌÜµÌôî",
        "__cpi_ratio", "__latest_ym", "__fx_ratio", "__fac_ratio", "__hyb",
        "Í≥µÏ¢ÖÏΩîÎìú", "Í≥µÏ¢ÖÎ™Ö",
        "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö", "ÌòëÎ†•ÏÇ¨ÏΩîÎìú", "ÌòëÎ†•ÏÇ¨Î™Ö",
        "AI_Î™®Îìú", "AI_Ï∂îÏ≤úÏÇ¨Ïú†",
    ]
    for c in detail_cols:
        if c not in inc.columns:
            inc[c] = None
    detail_df = inc[detail_cols].copy()

    rows = []
    for boq_id, g in df.groupby("BOQ_ID"):
        g_inc = g[g["Include"] == True].copy()
        total_n = len(g)
        inc_n = len(g_inc)

        adj = pd.to_numeric(g_inc.get("__adj_price", np.nan), errors="coerce")
        mean = float(adj.mean()) if inc_n else np.nan
        std = float(adj.std(ddof=0)) if inc_n else np.nan
        vmin = float(adj.min()) if inc_n else np.nan
        vmax = float(adj.max()) if inc_n else np.nan

        countries = sorted(g_inc["ÌÜµÌôî"].astype(str).str.upper().unique().tolist()) if inc_n else []
        sites = g_inc["ÌòÑÏû•ÏΩîÎìú"].astype(str).nunique() if inc_n and "ÌòÑÏû•ÏΩîÎìú" in g_inc.columns else 0
        vendors = g_inc["ÌòëÎ†•ÏÇ¨ÏΩîÎìú"].astype(str).nunique() if inc_n and "ÌòëÎ†•ÏÇ¨ÏΩîÎìú" in g_inc.columns else 0

        top_site = ""
        top_vendor = ""
        if inc_n and "ÌòÑÏû•ÏΩîÎìú" in g_inc.columns:
            vc = g_inc["ÌòÑÏû•ÏΩîÎìú"].astype(str).value_counts()
            top_site = f"{vc.index[0]} ({int(vc.iloc[0])}/{inc_n})" if len(vc) else ""
        if inc_n and "ÌòëÎ†•ÏÇ¨ÏΩîÎìú" in g_inc.columns:
            vc2 = g_inc["ÌòëÎ†•ÏÇ¨ÏΩîÎìú"].astype(str).value_counts()
            top_vendor = f"{vc2.index[0]} ({int(vc2.iloc[0])}/{inc_n})" if len(vc2) else ""

        risk = []
        if inc_n == 0:
            risk.append("Ìè¨Ìï®ÌõÑÎ≥¥ÏóÜÏùå")
        if inc_n and pd.notna(vmax) and pd.notna(vmin) and vmin > 0 and (vmax / vmin > 3):
            risk.append("Îã®Í∞ÄÌé∏Ï∞®ÌÅº(>3Î∞∞)")
        if inc_n and pd.notna(std) and pd.notna(mean) and mean != 0 and (std / mean > 0.5):
            risk.append("Î≥ÄÎèôÏÑ±ÌÅº(CV>0.5)")
        if inc_n and sites == 1 and inc_n >= 3:
            risk.append("ÌòÑÏû•Ìé∏Ìñ•(1Í∞úÌòÑÏû•)")
        if inc_n and vendors == 1 and inc_n >= 3:
            risk.append("ÏóÖÏ≤¥Ìé∏Ìñ•(1Í∞úÏóÖÏ≤¥)")

        one = g.iloc[0]
        rows.append({
            "BOQ_ID": int(boq_id),
            "BOQ_ÎÇ¥Ïó≠": one.get("BOQ_ÎÇ¥Ïó≠", ""),
            "BOQ_Unit": one.get("BOQ_Unit", ""),
            "ÌõÑÎ≥¥Ïàò": int(total_n),
            "Ìè¨Ìï®Ïàò": int(inc_n),
            "Ìè¨Ìï®Íµ≠Í∞Ä": ", ".join(countries),
            "Ìè¨Ìï®ÌòÑÏû•Ïàò": int(sites),
            "Ìè¨Ìï®ÏóÖÏ≤¥Ïàò": int(vendors),
            "ÏÇ∞Ï∂úÎã®Í∞ÄÌèâÍ∑†": mean,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÌëúÏ§ÄÌé∏Ï∞®": std,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÏµúÏ†Ä": vmin,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÏµúÍ≥†": vmax,
            "ÏµúÎπàÌòÑÏû•": top_site,
            "ÏµúÎπàÏóÖÏ≤¥": top_vendor,
            "Î¶¨Ïä§ÌÅ¨": ", ".join(risk),
        })

    summary_df = pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)

    if result_df is not None and not result_df.empty and "BOQ_ID" in result_df.columns:
        tmp = result_df.copy()
        tmp["BOQ_ID"] = tmp["BOQ_ID"].astype(int)
        keep = [c for c in ["BOQ_ID", "Final Price", "ÏÇ∞Ï∂úÍ∑ºÍ±∞", "Í∑ºÍ±∞Í≥µÏ¢Ö(ÏµúÎπà)"] if c in tmp.columns]
        summary_df = summary_df.merge(tmp[keep], on="BOQ_ID", how="left")

    return summary_df, detail_df

def build_report_tables_domestic(log_df: pd.DataFrame, result_df: pd.DataFrame):
    """
    Íµ≠ÎÇ¥ Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú ÌÖåÏù¥Î∏î ÏÉùÏÑ±(ÏöîÏïΩ/ÏÉÅÏÑ∏)
    - Ìï¥Ïô∏ TAB3 ÌòïÏãùÍ≥º ÎèôÏùºÌïú ÏÑπÏÖò Íµ¨ÏÑ±ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌïú summary/detail 2Í∞ú ÌÖåÏù¥Î∏î Î∞òÌôò
    """
    if log_df is None or log_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = log_df.copy()
    df["BOQ_ID"] = df["BOQ_ID"].astype(int)

    # Include=True ÏÉÅÏÑ∏ ÌõÑÎ≥¥
    inc = df[df["Include"] == True].copy()

    # -------------------------
    # (1) ÏÉÅÏÑ∏(detail)
    # -------------------------
    detail_cols = [
        "BOQ_ID", "BOQ_Î™ÖÏπ≠", "BOQ_Í∑úÍ≤©", "BOQ_Îã®ÏúÑ",
        "Ïã§ÌñâÎ™ÖÏπ≠", "Í∑úÍ≤©", "Îã®ÏúÑ",
        "__adj_price", "__hyb",
        "Í≥ÑÏïΩÏõî", "Î≥¥Ï†ïÎã®Í∞Ä", "Í≥ÑÏïΩÎã®Í∞Ä",
        "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö", "ÌòÑÏû•ÌäπÏÑ±",
        "ÏóÖÏ≤¥ÏΩîÎìú", "ÏóÖÏ≤¥Î™Ö",
        "Í≥µÏ¢ÖCodeÎ∂ÑÎ•ò", "ÏÑ∏Î∂ÄÎ∂ÑÎ•ò",
        "AI_Î™®Îìú", "AI_Ï∂îÏ≤úÏÇ¨Ïú†",
    ]
    for c in detail_cols:
        if c not in inc.columns:
            inc[c] = None
    detail_df = inc[detail_cols].copy()

    # -------------------------
    # (2) ÏöîÏïΩ(summary)
    # -------------------------
    rows = []
    for boq_id, g in df.groupby("BOQ_ID"):
        g_inc = g[g["Include"] == True].copy()
        total_n = len(g)
        inc_n = len(g_inc)

        adj = pd.to_numeric(g_inc.get("__adj_price", np.nan), errors="coerce")
        mean = float(adj.mean()) if inc_n else np.nan
        std = float(adj.std(ddof=0)) if inc_n else np.nan
        vmin = float(adj.min()) if inc_n else np.nan
        vmax = float(adj.max()) if inc_n else np.nan

        sites = g_inc["ÌòÑÏû•ÏΩîÎìú"].astype(str).nunique() if inc_n and "ÌòÑÏû•ÏΩîÎìú" in g_inc.columns else 0
        vendors = g_inc["ÏóÖÏ≤¥ÏΩîÎìú"].astype(str).nunique() if inc_n and "ÏóÖÏ≤¥ÏΩîÎìú" in g_inc.columns else 0

        top_site = ""
        top_vendor = ""
        if inc_n and "ÌòÑÏû•ÏΩîÎìú" in g_inc.columns:
            vc = g_inc["ÌòÑÏû•ÏΩîÎìú"].astype(str).value_counts()
            top_site = f"{vc.index[0]} ({int(vc.iloc[0])}/{inc_n})" if len(vc) else ""
        if inc_n and "ÏóÖÏ≤¥ÏΩîÎìú" in g_inc.columns:
            vc2 = g_inc["ÏóÖÏ≤¥ÏΩîÎìú"].astype(str).value_counts()
            top_vendor = f"{vc2.index[0]} ({int(vc2.iloc[0])}/{inc_n})" if len(vc2) else ""

        risk = []
        if inc_n == 0:
            risk.append("Ìè¨Ìï®ÌõÑÎ≥¥ÏóÜÏùå")
        if inc_n and pd.notna(vmax) and pd.notna(vmin) and vmin > 0 and (vmax / vmin > 3):
            risk.append("Îã®Í∞ÄÌé∏Ï∞®ÌÅº(>3Î∞∞)")
        if inc_n and pd.notna(std) and pd.notna(mean) and mean != 0 and (std / mean > 0.5):
            risk.append("Î≥ÄÎèôÏÑ±ÌÅº(CV>0.5)")
        if inc_n and sites == 1 and inc_n >= 3:
            risk.append("ÌòÑÏû•Ìé∏Ìñ•(1Í∞úÌòÑÏû•)")
        if inc_n and vendors == 1 and inc_n >= 3:
            risk.append("ÏóÖÏ≤¥Ìé∏Ìñ•(1Í∞úÏóÖÏ≤¥)")

        one = g.iloc[0]
        rows.append({
            "BOQ_ID": int(boq_id),
            "BOQ_Î™ÖÏπ≠": one.get("BOQ_Î™ÖÏπ≠", ""),
            "BOQ_Í∑úÍ≤©": one.get("BOQ_Í∑úÍ≤©", ""),
            "BOQ_Îã®ÏúÑ": one.get("BOQ_Îã®ÏúÑ", ""),
            "ÌõÑÎ≥¥Ïàò": int(total_n),
            "Ìè¨Ìï®Ïàò": int(inc_n),
            "Ìè¨Ìï®ÌòÑÏû•Ïàò": int(sites),
            "Ìè¨Ìï®ÏóÖÏ≤¥Ïàò": int(vendors),
            "ÏÇ∞Ï∂úÎã®Í∞ÄÌèâÍ∑†": mean,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÌëúÏ§ÄÌé∏Ï∞®": std,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÏµúÏ†Ä": vmin,
            "ÏÇ∞Ï∂úÎã®Í∞ÄÏµúÍ≥†": vmax,
            "ÏµúÎπàÌòÑÏû•": top_site,
            "ÏµúÎπàÏóÖÏ≤¥": top_vendor,
            "Î¶¨Ïä§ÌÅ¨": ", ".join(risk),
        })

    summary_df = pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)

    # Í≤∞Í≥º(result_df)Ïùò Final Price/ÏÇ∞Ï∂úÍ∑ºÍ±∞ Î≥ëÌï©(ÏûàÏúºÎ©¥)
    if result_df is not None and not result_df.empty and "BOQ_ID" in result_df.columns:
        tmp = result_df.copy()
        tmp["BOQ_ID"] = tmp["BOQ_ID"].astype(int)
        keep = [c for c in ["BOQ_ID", "Final Price", "ÏÇ∞Ï∂úÍ∑ºÍ±∞"] if c in tmp.columns]
        if keep:
            summary_df = summary_df.merge(tmp[keep], on="BOQ_ID", how="left")

    return summary_df, detail_df


# =========================
# ü§ñ AI ÏµúÏ¢Ö Ï†ÅÏö© Í∏∞Ï§Ä Í∏∞Î°ù/ÌëúÏãúÏö© (TAB3ÏóêÏÑú ÏÇ¨Ïö©)
# =========================
def record_ai_last_applied(
    scope: str,
    mode: str,
    min_keep: int,
    max_keep: int,
    summary: Optional[dict] = None,
    boq_id: Optional[int] = None,
):
    payload = {
        "scope": str(scope),
        "mode": str(mode),
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
    }
    if boq_id is not None:
        payload["boq_id"] = int(boq_id)

    if isinstance(summary, dict):
        for k in ["hyb_min", "iqr_k", "kept", "total"]:
            if k in summary:
                payload[k] = summary[k]

    st.session_state["ai_last_applied"] = payload


def get_ai_effective_rule_text() -> str:
    info = st.session_state.get("ai_last_applied", None)
    if not isinstance(info, dict) or not info.get("mode"):
        return "AI ÏµúÏ¢ÖÍ∏∞Ï§Ä Í∏∞Î°ù ÏóÜÏùå(ÏàòÎèô Ìé∏Ïßë ÎòêÎäî Í∏∞Î≥∏ Ïª∑Îßå Ï†ÅÏö©)"

    scope = info.get("scope", "")
    mode = info.get("mode", "")
    min_keep = info.get("min_keep", "")
    max_keep = info.get("max_keep", "")
    boq_id = info.get("boq_id", None)
    hyb_min = info.get("hyb_min", None)
    iqr_k = info.get("iqr_k", None)

    parts = []
    if scope == "ÌòÑÏû¨ BOQ" and boq_id is not None:
        parts.append(f"Ï†ÅÏö©Î≤îÏúÑ={scope}(BOQ_ID={boq_id})")
    else:
        parts.append(f"Ï†ÅÏö©Î≤îÏúÑ={scope}")

    parts.append(f"Î™®Îìú={mode}")
    parts.append(f"ÏµúÏÜåÌè¨Ìï®={min_keep}")
    parts.append(f"ÏµúÎåÄÌè¨Ìï®={max_keep}")

    if hyb_min is not None:
        parts.append(f"Ïú†ÏÇ¨ÎèÑÏµúÏÜå(hyb_min)={hyb_min}")
    if iqr_k is not None:
        parts.append(f"IQRÍ≥ÑÏàò(iqr_k)={iqr_k}")

    return " / ".join(parts)


# =========================
# üßæ Î≥¥Í≥†ÏÑú TAB3 Ïú†Ìã∏(ÌäπÏÑ±/ÌòÑÏû•/AIÍ∏∞Ï§Ä/Î∂ÑÌè¨ Í∑∏ÎûòÌîÑ)
# =========================
def build_feature_context_table(feature_master: pd.DataFrame, selected_feature_ids: list) -> pd.DataFrame:
    if not selected_feature_ids:
        return pd.DataFrame(columns=["ÌäπÏÑ±ID", "ÎåÄÍ≥µÏ¢Ö", "Ï§ëÍ≥µÏ¢Ö", "ÏÜåÍ≥µÏ¢Ö", "Cost Driver Method", "Cost Driver Condition"])

    fm = feature_master.copy()
    cols5 = ["ÎåÄÍ≥µÏ¢Ö", "Ï§ëÍ≥µÏ¢Ö", "ÏÜåÍ≥µÏ¢Ö", "Cost Driver Method", "Cost Driver Condition"]
    keep = ["ÌäπÏÑ±ID"] + cols5

    for c in keep:
        if c in fm.columns:
            fm[c] = fm[c].astype(str).fillna("").str.strip()
        else:
            fm[c] = ""

    out = fm[fm["ÌäπÏÑ±ID"].astype(str).isin([str(x) for x in selected_feature_ids])][keep].copy()
    out = out.drop_duplicates(subset=["ÌäπÏÑ±ID"]).reset_index(drop=True)
    return out


def build_site_context_table(cost_db: pd.DataFrame, selected_site_codes: list) -> pd.DataFrame:
    if not selected_site_codes:
        return pd.DataFrame(columns=["ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö"])
    tmp = cost_db[["ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö"]].copy()
    tmp = tmp.dropna(subset=["ÌòÑÏû•ÏΩîÎìú"])
    tmp["ÌòÑÏû•ÏΩîÎìú"] = tmp["ÌòÑÏû•ÏΩîÎìú"].apply(norm_site_code)
    tmp["ÌòÑÏû•Î™Ö"] = tmp["ÌòÑÏû•Î™Ö"].astype(str).fillna("").str.strip()
    tmp.loc[tmp["ÌòÑÏû•Î™Ö"].isin(["", "nan", "None"]), "ÌòÑÏû•Î™Ö"] = "(ÌòÑÏû•Î™ÖÏóÜÏùå)"
    tmp = tmp.drop_duplicates(subset=["ÌòÑÏû•ÏΩîÎìú"])
    out = tmp[tmp["ÌòÑÏû•ÏΩîÎìú"].isin([norm_site_code(x) for x in selected_site_codes])].copy()
    out = out.sort_values("ÌòÑÏû•ÏΩîÎìú").reset_index(drop=True)
    return out


def plot_distribution(series: pd.Series, title: str):
    s = pd.to_numeric(series, errors="coerce").dropna()
    fig = plt.figure()
    plt.title(title)
    if len(s) == 0:
        plt.text(0.5, 0.5, "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå", ha="center", va="center")
    else:
        plt.hist(s.values, bins=30)
        plt.xlabel("ÏÇ∞Ï∂úÎã®Í∞Ä(__adj_price)")
        plt.ylabel("ÎπàÎèÑ")
    st.pyplot(fig, clear_figure=True)


# =========================
# üìä BOQ ÎÇ¥Ïó≠Î≥Ñ ÏÇ∞Ï†êÎèÑ(Í≥ÑÏïΩÎÖÑÏõî vs ÏÇ∞Ï∂úÎã®Í∞Ä) - Ìè¨Ìï®/ÎØ∏Ìè¨Ìï® ÌëúÏãú
# =========================
def _parse_contract_month_series(s: pd.Series) -> pd.Series:
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().any():
        s2 = s.astype(str).apply(to_year_month_string)
        dt2 = pd.to_datetime(s2, errors="coerce")
        dt = dt.fillna(dt2)
    return dt


def render_boq_scatter(log_df: pd.DataFrame, base_result: pd.DataFrame):
    if log_df is None or log_df.empty:
        st.info("Î°úÍ∑∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏñ¥ Í∑∏ÎûòÌîÑÎ•º ÌëúÏãúÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    keyword = st.text_input("ÎÇ¥Ïó≠ ÌÇ§ÏõåÎìú(Ïòà: REBAR)", value="", key="report_kw")
    cand = base_result.copy() if (base_result is not None and not base_result.empty) else None

    if cand is not None and "ÎÇ¥Ïó≠" in cand.columns and "BOQ_ID" in cand.columns and keyword.strip():
        kw = keyword.strip().lower()
        cand = cand[cand["ÎÇ¥Ïó≠"].astype(str).str.lower().str.contains(kw, na=False)].copy()

    if cand is not None and not cand.empty:
        boq_ids = cand["BOQ_ID"].dropna().astype(int).unique().tolist()
        boq_ids = sorted(boq_ids)
        id_to_text = cand.set_index(cand["BOQ_ID"].astype(int))["ÎÇ¥Ïó≠"].astype(str).to_dict()
    else:
        boq_ids = sorted(log_df["BOQ_ID"].dropna().astype(int).unique().tolist())
        id_to_text = (
            log_df.dropna(subset=["BOQ_ID"])
            .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
            .groupby("BOQ_ID")["BOQ_ÎÇ¥Ïó≠"].first()
            .astype(str).to_dict()
        )

    if not boq_ids:
        st.info("ÌëúÏãúÌï† BOQ_IDÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        return

    def fmt(x: int) -> str:
        t = id_to_text.get(int(x), "")
        t = (t[:60] + "‚Ä¶") if len(t) > 60 else t
        return f"{int(x)} | {t}"

    sel = st.selectbox("Í∑∏ÎûòÌîÑ Î≥º BOQ ÏÑ†ÌÉù", options=boq_ids, format_func=fmt, key="report_boq_pick")

    sub = log_df[log_df["BOQ_ID"].astype(int) == int(sel)].copy()
    if sub.empty:
        st.info("Ìï¥Îãπ BOQ ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return

    sub["Í≥ÑÏïΩÏõî_dt"] = _parse_contract_month_series(sub["Í≥ÑÏïΩÎÖÑÏõî"])
    sub["ÏÇ∞Ï∂úÎã®Í∞Ä"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
    sub["Ìè¨Ìï®Ïó¨Î∂Ä"] = sub["Include"].fillna(False).astype(bool)
    sub["ÌëúÏãúÎÇ¥Ïó≠"] = sub["ÎÇ¥Ïó≠"].astype(str)

    chart = (
        alt.Chart(sub.dropna(subset=["Í≥ÑÏïΩÏõî_dt", "ÏÇ∞Ï∂úÎã®Í∞Ä"]))
        .mark_circle()
        .encode(
            x=alt.X("Í≥ÑÏïΩÏõî_dt:T", title="Í≥ÑÏïΩÎÖÑÏõî"),
            y=alt.Y("ÏÇ∞Ï∂úÎã®Í∞Ä:Q", title="ÏÇ∞Ï∂úÎã®Í∞Ä(ÏÇ∞Ï∂úÌÜµÌôî Í∏∞Ï§Ä)"),
            color=alt.Color("Ìè¨Ìï®Ïó¨Î∂Ä:N", title="Ìè¨Ìï®"),
            size=alt.Size("Ìè¨Ìï®Ïó¨Î∂Ä:N", title="Ìè¨Ìï®(ÌÅ¨Í∏∞)", scale=alt.Scale(range=[40, 140])),
            tooltip=[
                alt.Tooltip("ÌëúÏãúÎÇ¥Ïó≠:N", title="ÎÇ¥Ïó≠"),
                alt.Tooltip("ÏÇ∞Ï∂úÎã®Í∞Ä:Q", title="ÏÇ∞Ï∂úÎã®Í∞Ä", format=",.4f"),
                alt.Tooltip("ÌÜµÌôî:N", title="ÏõêÌÜµÌôî"),
                alt.Tooltip("Í≥ÑÏïΩÎÖÑÏõî:N", title="Í≥ÑÏïΩÎÖÑÏõî"),
                alt.Tooltip("__hyb:Q", title="Ïú†ÏÇ¨ÎèÑ", format=".2f"),
                alt.Tooltip("ÌòÑÏû•ÏΩîÎìú:N", title="ÌòÑÏû•ÏΩîÎìú"),
                alt.Tooltip("ÌòëÎ†•ÏÇ¨ÏΩîÎìú:N", title="ÌòëÎ†•ÏÇ¨ÏΩîÎìú"),
            ],
        )
        .properties(height=420)
        .interactive()
    )
    st.altair_chart(chart, use_container_width=True)

def render_boq_scatter_domestic(log_df: pd.DataFrame, base_result: pd.DataFrame):
    if log_df is None or log_df.empty:
        st.info("Î°úÍ∑∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏñ¥ Í∑∏ÎûòÌîÑÎ•º ÌëúÏãúÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
        return

    # Ìï¥Ïô∏ TAB3ÏôÄ Í∞ôÏùÄ UX: ÌÇ§ÏõåÎìúÎ°ú BOQ ÌõÑÎ≥¥Î•º Ï§ÑÏùº Ïàò ÏûàÍ≤å
    keyword = st.text_input("Î™ÖÏπ≠ ÌÇ§ÏõåÎìú(Ïòà: Ï≤†Í∑º)", value="", key="report_kw_kr")

    cand = base_result.copy() if (base_result is not None and not base_result.empty) else None

    # result_dfÏóê "Î™ÖÏπ≠" Ïª¨ÎüºÏù¥ ÏûàÏúºÎØÄÎ°ú Í∑∏Í±∏Î°ú ÌïÑÌÑ∞
    if cand is not None and "Î™ÖÏπ≠" in cand.columns and "BOQ_ID" in cand.columns and keyword.strip():
        kw = keyword.strip().lower()
        cand = cand[cand["Î™ÖÏπ≠"].astype(str).str.lower().str.contains(kw, na=False)].copy()

    if cand is not None and not cand.empty:
        boq_ids = sorted(cand["BOQ_ID"].dropna().astype(int).unique().tolist())
        id_to_text = cand.set_index(cand["BOQ_ID"].astype(int))["Î™ÖÏπ≠"].astype(str).to_dict()
    else:
        boq_ids = sorted(log_df["BOQ_ID"].dropna().astype(int).unique().tolist())
        id_to_text = (
            log_df.dropna(subset=["BOQ_ID"])
            .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
            .groupby("BOQ_ID")
            .apply(lambda g: f'{str(g["BOQ_Î™ÖÏπ≠"].iloc[0])} / {str(g["BOQ_Í∑úÍ≤©"].iloc[0])}')
            .to_dict()
        )

    if not boq_ids:
        st.info("ÌëúÏãúÌï† BOQ_IDÍ∞Ä ÏóÜÏäµÎãàÎã§.")
        return

    def fmt(x: int) -> str:
        t = id_to_text.get(int(x), "")
        t = (t[:60] + "‚Ä¶") if len(t) > 60 else t
        return f"{int(x)} | {t}"

    sel = st.selectbox("Í∑∏ÎûòÌîÑ Î≥º BOQ ÏÑ†ÌÉù(Íµ≠ÎÇ¥)", options=boq_ids, format_func=fmt, key="report_boq_pick_kr")

    sub = log_df[log_df["BOQ_ID"].astype(int) == int(sel)].copy()
    if sub.empty:
        st.info("Ìï¥Îãπ BOQ ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return

    # Í≥ÑÏïΩÏõî ÌååÏã±
    sub["Í≥ÑÏïΩÏõî_dt"] = pd.to_datetime(sub["Í≥ÑÏïΩÏõî"], errors="coerce")
    sub["ÏÇ∞Ï∂úÎã®Í∞Ä"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
    sub["Ìè¨Ìï®Ïó¨Î∂Ä"] = sub["Include"].fillna(False).astype(bool)
    sub["ÌëúÏãúÎÇ¥Ïó≠"] = sub["Ïã§ÌñâÎ™ÖÏπ≠"].astype(str)

    chart = (
        alt.Chart(sub.dropna(subset=["Í≥ÑÏïΩÏõî_dt", "ÏÇ∞Ï∂úÎã®Í∞Ä"]))
        .mark_circle()
        .encode(
            x=alt.X("Í≥ÑÏïΩÏõî_dt:T", title="Í≥ÑÏïΩÏõî"),
            y=alt.Y("ÏÇ∞Ï∂úÎã®Í∞Ä:Q", title="ÏÇ∞Ï∂úÎã®Í∞Ä(Íµ≠ÎÇ¥)"),
            color=alt.Color("Ìè¨Ìï®Ïó¨Î∂Ä:N", title="Ìè¨Ìï®"),
            size=alt.Size("Ìè¨Ìï®Ïó¨Î∂Ä:N", title="Ìè¨Ìï®(ÌÅ¨Í∏∞)", scale=alt.Scale(range=[40, 140])),
            tooltip=[
                alt.Tooltip("ÌëúÏãúÎÇ¥Ïó≠:N", title="Ïã§ÌñâÎ™ÖÏπ≠"),
                alt.Tooltip("ÏÇ∞Ï∂úÎã®Í∞Ä:Q", title="ÏÇ∞Ï∂úÎã®Í∞Ä", format=",.4f"),
                alt.Tooltip("__hyb:Q", title="Ïú†ÏÇ¨ÎèÑ", format=".2f"),
                alt.Tooltip("ÌòÑÏû•ÏΩîÎìú:N", title="ÌòÑÏû•ÏΩîÎìú"),
                alt.Tooltip("ÌòÑÏû•Î™Ö:N", title="ÌòÑÏû•Î™Ö"),
                alt.Tooltip("ÏóÖÏ≤¥ÏΩîÎìú:N", title="ÏóÖÏ≤¥ÏΩîÎìú"),
                alt.Tooltip("ÏóÖÏ≤¥Î™Ö:N", title="ÏóÖÏ≤¥Î™Ö"),
                alt.Tooltip("Í≥ÑÏïΩÏõî:N", title="Í≥ÑÏïΩÏõî"),
            ],
        )
        .properties(height=420)
        .interactive()
    )
    st.altair_chart(chart, use_container_width=True)


# =========================
# Îç∞Ïù¥ÌÑ∞ Î°úÎìú
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"


def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"ÌïÑÏàò ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")


@st.cache_data(show_spinner=False)
def load_overseas_data():
    cost_db = load_excel_from_repo("cost_db.xlsx")
    price_index = load_excel_from_repo("price_index.xlsx")
    exchange = load_excel_from_repo("exchange.xlsx")
    factor = load_excel_from_repo("Factor.xlsx")
    project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
    feature_master = load_excel_from_repo("feature_master_FID.xlsx")
    return cost_db, price_index, exchange, factor, project_feature_long, feature_master

@st.cache_data(show_spinner=False)
def load_domestic_data():
    cost_db_kr = load_excel_from_repo("cost_db (kr).xlsx")
    return cost_db_kr

# =========================
# ‚úÖ Ïª¨ÎüºÎ™Ö ÌëúÏ§ÄÌôî + alias Îß§Ìïë (KeyError Î∞©ÏßÄ)
# =========================
def _std_colname(s: str) -> str:
    s = str(s)
    s = s.replace("_", " ")
    s = re.sub(r"\s+", " ", s)
    return s.strip()


def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [_std_colname(c) for c in df.columns]
    return df


def apply_feature_column_alias(df: pd.DataFrame) -> pd.DataFrame:
    """
    feature_master_FID / project_feature_long Ïª¨ÎüºÏù¥ Ï°∞Í∏à Îã¨ÎùºÎèÑ
    ÏïÑÎûò 'ÌëúÏ§Ä Ïª¨ÎüºÎ™Ö'ÏúºÎ°ú Í∞ïÏ†ú ÎßûÏ∂§
    """
    df = df.copy()
    col_map = {}

    aliases = {
        "ÌäπÏÑ±ID": ["ÌäπÏÑ±ID", "ÌäπÏÑ± Id", "FeatureID", "Feature Id", "FID"],
        "ÎåÄÍ≥µÏ¢Ö": ["ÎåÄÍ≥µÏ¢Ö", "ÎåÄ Í≥µÏ¢Ö", "Major", "Main"],
        "Ï§ëÍ≥µÏ¢Ö": ["Ï§ëÍ≥µÏ¢Ö", "Ï§ë Í≥µÏ¢Ö", "Middle"],
        "ÏÜåÍ≥µÏ¢Ö": ["ÏÜåÍ≥µÏ¢Ö", "ÏÜå Í≥µÏ¢Ö", "Minor", "Sub"],

        "Cost Driver Type": [
            "Cost Driver Type", "CostDriver Type", "Cost DriverType",
            "Cost Driver_Type", "CostDriver_Type", "Type", "Driver Type"
        ],
        "Cost Driver Method": [
            "Cost Driver Method", "CostDriver Method", "Cost DriverMethod",
            "Cost Driver_Method", "CostDriver_Method", "Method"
        ],
        "Cost Driver Condition": [
            "Cost Driver Condition", "CostDriver Condition", "Cost DriverCondition",
            "Cost Driver_Condition", "CostDriver_Condition", "Condition"
        ],

        "ÌòÑÏû•ÏΩîÎìú": ["ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû• ÏΩîÎìú", "Site Code", "SiteCode"],
        "ÌòÑÏû•Î™Ö": ["ÌòÑÏû•Î™Ö", "ÌòÑÏû• Î™Ö", "Site Name", "SiteName"],
    }

    cols = list(df.columns)

    for std_name, cand_list in aliases.items():
        for cand in cand_list:
            cand_std = _std_colname(cand)
            if cand_std in cols:
                col_map[cand_std] = std_name
                break

    df = df.rename(columns=col_map)

    must_cols = [
        "ÌäπÏÑ±ID", "ÎåÄÍ≥µÏ¢Ö", "Ï§ëÍ≥µÏ¢Ö", "ÏÜåÍ≥µÏ¢Ö",
        "Cost Driver Type", "Cost Driver Method", "Cost Driver Condition"
    ]
    for c in must_cols:
        if c not in df.columns:
            df[c] = ""

    return df

# =========================
# ‚úÖ Îç∞Ïù¥ÌÑ∞ Î°úÎìú + ÌëúÏ§ÄÌôî/alias Ï†ÅÏö© (Ìï®Ïàò Ï†ïÏùò Ïù¥ÌõÑÏóê 1ÌöåÎßå)
# =========================
cost_db, price_index, exchange, factor, project_feature_long, feature_master = load_overseas_data()
cost_db_kr = load_domestic_data()

# (Í∂åÏû•) DBÎèÑ ÌëúÏ§ÄÌôî
cost_db = standardize_columns(cost_db)
cost_db_kr = standardize_columns(cost_db_kr)

# feature Í¥ÄÎ†® ÌëúÏ§ÄÌôî/alias
project_feature_long = standardize_columns(project_feature_long)
feature_master = standardize_columns(feature_master)

project_feature_long = apply_feature_column_alias(project_feature_long)
feature_master = apply_feature_column_alias(feature_master)



# =========================
# Session init
# =========================
if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []
if "auto_sites" not in st.session_state:
    st.session_state["auto_sites"] = []

# ‚úÖ ÌÉ≠ Ï†ÑÌôò ÏÉÅÌÉú(ÏÇ¨Ïù¥ÎìúÎ∞î Ï§ëÎ≥µ Î†åÎçî Î∞©ÏßÄÏö©)
if "active_db" not in st.session_state:
    st.session_state["active_db"] = "overseas"


# ============================================================
# ‚úÖ Íµ≠ÎÇ¥ ÌÉ≠ (UI skeleton only)
# ============================================================
def render_domestic():
    gs_header("üì¶ Íµ≠ÎÇ¥ Ïã§Ï†ÅÎã®Í∞Ä DB")

    # -------------------------
    # Sidebar: ÏÑ§Ï†ï(Íµ≠ÎÇ¥)
    # -------------------------
    st.sidebar.markdown("<div class='sb-major'>‚öôÔ∏è ÏÑ§Ï†ï</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    # 1) BOQ ÏóÖÎ°úÎìú
    with st.container(border=True):
        card_title("üì§ BOQ ÌååÏùº ÏóÖÎ°úÎìú(Íµ≠ÎÇ¥)")
        dom_boq_file = st.file_uploader(
            label="",
            type=["xlsx"],
            key="dom_boq_uploader",
            label_visibility="collapsed",
        )

    # 2) Íµ≠ÎÇ¥ ÌïÑÌÑ∞(ÌòÑÏû•ÌäπÏÑ±/ÌòÑÏû•)
    # - "Ìï¥Ïô∏ ÌäπÏÑ± ÏÑ†ÌÉù"ÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Íµ≠ÎÇ¥Îäî "ÌòÑÏû•ÌäπÏÑ±" Í∏∞Ï§ÄÏúºÎ°ú ÌïÑÌÑ∞ UI Ï†úÍ≥µ
    kr = cost_db_kr.copy()

    # ÌòÑÏû•ÌäπÏÑ±
    feat_col = "ÌòÑÏû•ÌäπÏÑ±"
    if feat_col not in kr.columns:
        kr[feat_col] = ""

    feat_options = sorted([x for x in kr[feat_col].astype(str).fillna("").unique().tolist() if x.strip() and x != "nan"])
    sel_feat = st.sidebar.multiselect(
        "üè∑Ô∏è ÌòÑÏû•ÌäπÏÑ±",
        options=feat_options,
        default=st.session_state.get("dom_sel_feat", []),
        key="dom_sel_feat",
    )

    if sel_feat:
        kr_view = kr[kr[feat_col].astype(str).isin(sel_feat)].copy()
    else:
        kr_view = kr

    # ÌòÑÏû• ÏÑ†ÌÉù(Íµ≠ÎÇ¥)
    if "ÌòÑÏû•ÏΩîÎìú" not in kr_view.columns:
        kr_view["ÌòÑÏû•ÏΩîÎìú"] = ""
    if "ÌòÑÏû•Î™Ö" not in kr_view.columns:
        kr_view["ÌòÑÏû•Î™Ö"] = ""

    site_df = kr_view[["ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö"]].copy()
    site_df = site_df.dropna(subset=["ÌòÑÏû•ÏΩîÎìú"])
    site_df["ÌòÑÏû•ÏΩîÎìú"] = site_df["ÌòÑÏû•ÏΩîÎìú"].apply(norm_site_code)
    site_df["ÌòÑÏû•Î™Ö"] = site_df["ÌòÑÏû•Î™Ö"].astype(str).fillna("").str.strip()
    site_df.loc[site_df["ÌòÑÏû•Î™Ö"].isin(["", "nan", "None"]), "ÌòÑÏû•Î™Ö"] = "(ÌòÑÏû•Î™ÖÏóÜÏùå)"
    site_df = site_df.drop_duplicates(subset=["ÌòÑÏû•ÏΩîÎìú"]).reset_index(drop=True)

    all_codes = site_df["ÌòÑÏû•ÏΩîÎìú"].tolist()
    code_to_name = dict(zip(site_df["ÌòÑÏû•ÏΩîÎìú"], site_df["ÌòÑÏû•Î™Ö"]))

    def fmt_site(code: str) -> str:
        name = code_to_name.get(code, "").strip()
        return (name[:25] + "‚Ä¶") if len(name) > 25 else name

    st.sidebar.markdown(
        f"""
        <div class="sb-row">
          <div class="sb-title">üèóÔ∏è Ïã§Ï†Å ÌòÑÏû• ÏÑ†ÌÉù</div>
          <div class="sb-muted">Í∞ÄÎä• ÌòÑÏû•: {len(all_codes)}Í∞ú</div>
        </div>
        """,
        unsafe_allow_html=True
    )
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    dom_selected_sites = st.sidebar.multiselect(
        "Íµ≠ÎÇ¥ Ïã§Ï†ÅÌòÑÏû•",
        options=all_codes,
        default=st.session_state.get("dom_selected_site_codes", []),
        key="dom_selected_site_codes",
        format_func=fmt_site,
    )

    # 3) ÏÑ§Ï†ïÍ∞í
    st.sidebar.markdown("<div class='sb-title'>üß© ÏÑ§Ï†ïÍ∞í</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    # Ìï¥Ïô∏Îûë ÎπÑÏä∑ÌïòÍ≤å Ïú†ÏßÄ
    DEFAULT_W_STR = 0.35
    w_str = DEFAULT_W_STR
    w_sem = 1.0 - w_str
    top_k_sem = 200

    dom_sim_threshold = st.sidebar.slider("Îß§Ïπ≠ Ïú†ÏÇ¨ÎèÑ Í∏∞Ï§ÄÍ∞í(%)", 0, 100, 65, 5, key="dom_sim_threshold")
    dom_cut_ratio = st.sidebar.slider("ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú® (%)", 0, 30, 20, 5, key="dom_cut_ratio") / 100.0

    sidebar_hr(thick=True, mt=10, mb=8)

    # -------------------------
    # Run / Auto Recompute(Íµ≠ÎÇ¥)
    # -------------------------
    def dom_boq_file_signature(uploaded_file) -> str:
        if uploaded_file is None:
            return "no_boq"
        try:
            b = uploaded_file.getvalue()
            if len(b) > 2_000_000:
                b = b[:1_000_000] + b[-1_000_000:]
            return hashlib.md5(b).hexdigest()
        except Exception:
            return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

    def make_dom_params_signature() -> str:
        payload = {
            "boq": dom_boq_file_signature(dom_boq_file),
            "sel_feat": sorted([str(x) for x in (sel_feat or [])]),
            "sel_sites": sorted([norm_site_code(x) for x in (dom_selected_sites or [])]),
            "sim_threshold": float(dom_sim_threshold),
            "cut_ratio": float(dom_cut_ratio),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "top_k_sem": int(top_k_sem),
        }
        s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(s.encode("utf-8")).hexdigest()

    def run_domestic_and_store(run_sig: str):
        status_box = st.empty()

        if dom_boq_file is None:
            status_box.empty()
            st.warning("Íµ≠ÎÇ¥ BOQ ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌï¥ Ï£ºÏÑ∏Ïöî.")
            return

        progress = st.progress(0.0)
        prog_text = st.empty()

        status_box.markdown("### ‚è≥ [Íµ≠ÎÇ¥] ÏÇ∞Ï∂úÏ§ë... (BOQ Î°úÎìú)")
        boq_kr = pd.read_excel(dom_boq_file, engine="openpyxl")

        # Íµ≠ÎÇ¥ BOQ Ïª¨Îüº Î≥¥Í∞ï(Ï≤´ Ïó¥: Î™ÖÏπ≠ Í∑úÍ≤© Îã®ÏúÑ ÏàòÎüâ Îã®Í∞Ä)
        need_boq_cols = ["Î™ÖÏπ≠","Í∑úÍ≤©","Îã®ÏúÑ","ÏàòÎüâ","Îã®Í∞Ä"]
        for c in need_boq_cols:
            if c not in boq_kr.columns:
                boq_kr[c] = ""

        # Íµ≠ÎÇ¥ DB ÌïÑÌÑ∞ Ï†ÅÏö©(ÌòÑÏû•ÌäπÏÑ±/ÌòÑÏû•)
        db_run = cost_db_kr.copy()
        if sel_feat:
            db_run = db_run[db_run["ÌòÑÏû•ÌäπÏÑ±"].astype(str).isin([str(x) for x in sel_feat])].copy()
        if dom_selected_sites:
            db_run = db_run[db_run["ÌòÑÏû•ÏΩîÎìú"].apply(norm_site_code).isin([norm_site_code(x) for x in dom_selected_sites])].copy()

        st.sidebar.caption(f"[Íµ≠ÎÇ¥] Ï†ÑÏ≤¥ {len(cost_db_kr):,}Í∞ú Ï§ë {len(db_run):,}Í∞úÎ°ú ÏÇ∞Ï∂ú")

        pool_sig_payload = {
            "boq": dom_boq_file_signature(dom_boq_file),
            "sel_feat": sorted([str(x) for x in (sel_feat or [])]),
            "sel_sites": sorted([norm_site_code(x) for x in (dom_selected_sites or [])]),
            "top_k_sem": int(top_k_sem),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "db_rows": int(len(db_run)),
        }
        pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

        need_new_pool = (st.session_state.get("dom_candidate_pool_sig") != pool_sig) or ("dom_candidate_pool" not in st.session_state)

        if need_new_pool:
            status_box.markdown("### ‚è≥ [Íµ≠ÎÇ¥] ÏÇ∞Ï∂úÏ§ë... (ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±)")
            with st.spinner("[Íµ≠ÎÇ¥] ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ± Ï§ë..."):
                pool = build_candidate_pool_domestic(
                    cost_db_kr=db_run,
                    boq_kr=boq_kr,
                    sim_w_str=w_str,
                    sim_w_sem=w_sem,
                    top_k_sem=top_k_sem,
                    pool_per_boq=400,
                    progress=progress,
                    prog_text=prog_text,
                )
            st.session_state["dom_candidate_pool"] = pool
            st.session_state["dom_candidate_pool_sig"] = pool_sig
        else:
            pool = st.session_state["dom_candidate_pool"]

        status_box.markdown("### ‚è≥ [Íµ≠ÎÇ¥] ÏÇ∞Ï∂úÏ§ë...")
        with st.spinner("[Íµ≠ÎÇ¥] Îπ†Î•∏ Ïû¨Í≥ÑÏÇ∞ Ï§ë..."):
            result_df, log_df = fast_recompute_from_pool_domestic(
                pool=pool,
                sim_threshold=dom_sim_threshold,
                cut_ratio=dom_cut_ratio,
            )
        # ‚úÖ ÏÇ∞Ï∂ú ÏôÑÎ£å ÌõÑ ÏßÑÌñâ ÌÖçÏä§Ìä∏ Ï†úÍ±∞
        try:
            status_box.empty()
        except Exception:
            pass
        try:
            progress.empty()
        except Exception:
            pass
        try:
            prog_text.empty()
        except Exception:
            pass

        st.session_state["dom_boq_df"] = boq_kr
        st.session_state["dom_result_df_base"] = result_df.copy()
        st.session_state["dom_log_df_base"] = log_df.copy()
        st.session_state["dom_log_df_edited"] = log_df.copy()
        st.session_state["dom_has_results"] = True
        st.session_state["dom_last_run_sig"] = run_sig

    run_dom_btn = st.sidebar.button("üöÄ ÏÇ∞Ï∂ú Ïã§Ìñâ", key="dom_run_btn")

    cur_sig = make_dom_params_signature()
    last_sig = st.session_state.get("dom_last_run_sig", None)
    needs_rerun = (last_sig is not None and cur_sig != last_sig)

    # ÏûêÎèôÏû¨ÏÇ∞Ï∂úÏùÄ Íµ≠ÎÇ¥ÎèÑ ON(ÏõêÌïòÎ©¥ FalseÎ°ú Î∞îÍæ∏Î©¥ Îê©ÎãàÎã§)
    auto_recompute = True
    auto_run = st.session_state.get("dom_has_results", False) and needs_rerun and auto_recompute

    if run_dom_btn or auto_run:
        run_domestic_and_store(cur_sig)

    # -------------------------
    # Tabs(Íµ≠ÎÇ¥)
    # -------------------------
    tab1, tab2, tab3 = st.tabs(["üìÑ BOQ Í≤∞Í≥º", "üßæ ÏÇ∞Ï∂ú Í∑ºÍ±∞(Ìé∏Ïßë Í∞ÄÎä•)", "üìù Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú"])

    with tab2:
        if not st.session_state.get("dom_has_results", False):
            st.info("ÏÇ∞Ï∂ú Ïã§Ìñâ ÌõÑ Î°úÍ∑∏Í∞Ä ÌëúÏãúÎê©ÎãàÎã§.")
        else:
            
    
            # ÌòÑÏû¨ Ìé∏Ïßë ÎåÄÏÉÅ: Ï†ÑÏ≤¥ Î°úÍ∑∏(edited)
            if "dom_log_df_edited" not in st.session_state:
                st.session_state["dom_log_df_edited"] = st.session_state.get("dom_log_df_base", pd.DataFrame()).copy()
    
            log_all = st.session_state["dom_log_df_edited"]
            if log_all is None or log_all.empty:
                st.warning("Î°úÍ∑∏ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
            else:
                # --- BOQ ÏÑ†ÌÉù ---
                boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())
    
                # ÎùºÎ≤®(BOQ_ID | Î™ÖÏπ≠/Í∑úÍ≤©) ÎßåÎì§Í∏∞
                id_to_text = (
                    log_all.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .groupby("BOQ_ID")
                    .apply(lambda g: f'{str(g["BOQ_Î™ÖÏπ≠"].iloc[0])} / {str(g["BOQ_Í∑úÍ≤©"].iloc[0])}')
                    .to_dict()
                )
    
                def fmt_boq_id(x: int) -> str:
                    t = id_to_text.get(int(x), "")
                    t = (t[:60] + "‚Ä¶") if len(t) > 60 else t
                    return f"{int(x)} | {t}"
    
                sel_id = st.selectbox(
                    "Ìé∏ÏßëÌï† BOQ ÏÑ†ÌÉù(Íµ≠ÎÇ¥)",
                    options=boq_ids,
                    format_func=fmt_boq_id,
                    key="dom_sel_boq_id",
                )
    
                # ÌòÑÏû¨ BOQ ÌõÑÎ≥¥Îßå Î≥¥Í∏∞
                log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()
                if log_view_full.empty:
                    st.info("Ìï¥Îãπ BOQ ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.")
                else:
                    # --- Î∞±ÏóÖ(ÎêòÎèåÎ¶¨Í∏∞) Ï†ÄÏû•ÏÜå ---
                    if "dom_include_backup" not in st.session_state:
                        st.session_state["dom_include_backup"] = {}
                    if "dom_include_backup_all" not in st.session_state:
                        st.session_state["dom_include_backup_all"] = None
    
                    # --- AI ÌååÎùºÎØ∏ÌÑ∞(UI) ---
                    cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
                    with cA:
                        agent_mode = st.selectbox("AI Ï∂îÏ≤ú Î™®Îìú(Íµ≠ÎÇ¥)", ["Î≥¥ÏàòÏ†Å", "Í∑†Ìòï", "Í≥µÍ≤©Ï†Å"], index=1, key="dom_agent_mode")
                    with cB:
                        min_keep = st.number_input("ÏµúÏÜå Ìè¨Ìï®", min_value=1, max_value=20, value=3, step=1, key="dom_agent_min_keep")
                    with cC:
                        max_keep = st.number_input("ÏµúÎåÄ Ìè¨Ìï®", min_value=3, max_value=200, value=50, step=1, key="dom_agent_max_keep")
                    with cD:
                        st.caption("‚Äª Ï†ÅÏö© ÌõÑ ÌôîÎ©¥Ïù¥ ÏûêÎèô Í∞±Ïã†Îê©ÎãàÎã§.")
    
                    # --- Î≤ÑÌäº(Ìï¥Ïô∏ÏôÄ ÎèôÏùº) ---
                    b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
                    with b1:
                        btn_ai_one = st.button("ü§ñ AI Ï†ÅÏö©(ÌòÑÏû¨ BOQ)", key="dom_btn_ai_one")
                    with b2:
                        btn_undo_one = st.button("‚Ü©Ô∏è ÎêòÎèåÎ¶¨Í∏∞(ÌòÑÏû¨ BOQ)", key="dom_btn_undo_one")
                    with b3:
                        btn_ai_all = st.button("ü§ñ AI Ï†ÅÏö©(Ï†ÑÏ≤¥ BOQ)", key="dom_btn_ai_all")
                    with b4:
                        btn_undo_all = st.button("‚Ü©Ô∏è ÎêòÎèåÎ¶¨Í∏∞(Ï†ÑÏ≤¥ BOQ)", key="dom_btn_undo_all")
                    
                    # --- ÎêòÎèåÎ¶¨Í∏∞(ÌòÑÏû¨ BOQ) ---
                    if btn_undo_one:
                        backup = st.session_state["dom_include_backup"].get(int(sel_id))
                        if backup is not None and len(backup) == len(log_view_full.index):
                            st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success("ÎêòÎèåÎ¶¨Í∏∞ ÏôÑÎ£å(ÌòÑÏû¨ BOQ)")
                            st.rerun()
                        else:
                            st.warning("ÎêòÎèåÎ¶¥ Î∞±ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§(ÎòêÎäî ÌõÑÎ≥¥ÌñâÏù¥ Î≥ÄÍ≤ΩÎê®).")
                    
                    # --- AI Ï†ÅÏö©(ÌòÑÏû¨ BOQ) ---
                    if btn_ai_one:
                        # ÌòÑÏû¨ BOQ Include Î∞±ÏóÖ
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
                    
                        updated, summary = apply_agent_to_log(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            boq_id=int(sel_id),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        if summary:
                            st.success(f"AI Ï†ÅÏö© ÏôÑÎ£å(ÌòÑÏû¨ BOQ): {summary['kept']}/{summary['total']} Ìè¨Ìï®, Î™®Îìú={summary['mode']}")
                    
                        # <-- ÏïàÏ†ÑÌïòÍ≤å summary Ï†ÑÎã¨
                        record_ai_last_applied("ÌòÑÏû¨ BOQ", agent_mode, int(min_keep), int(max_keep), summary, boq_id=int(sel_id))
                        st.rerun()
                    
                    # --- AI Ï†ÅÏö©(Ï†ÑÏ≤¥ BOQ) ---
                    if btn_ai_all:
                        st.session_state["dom_include_backup_all"] = st.session_state["dom_log_df_edited"][["BOQ_ID", "Include"]].copy()
                    
                        updated, sum_df = apply_agent_to_all_boqs(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        st.success("AI Ï†ÅÏö© ÏôÑÎ£å(Ï†ÑÏ≤¥ BOQ)")
                        if sum_df is not None and not sum_df.empty:
                            st.dataframe(sum_df, use_container_width=True)
                    
                        # Ï†ÑÏ≤¥ Ï†ÅÏö©ÏùÄ summaryÍ∞Ä ÏóÜÏúºÎØÄÎ°ú None Ï†ÑÎã¨
                        record_ai_last_applied("Ï†ÑÏ≤¥ BOQ", agent_mode, int(min_keep), int(max_keep), None)
                        st.rerun()
    
                    # --- Í≤∞Í≥º Ïû¨Í≥ÑÏÇ∞(Include Í∏∞Î∞ò) Ìï®Ïàò ---
                    def recompute_dom_result_from_log(cur_log: pd.DataFrame) -> pd.DataFrame:
                        rows = []
                        for boq_id, g in cur_log.groupby("BOQ_ID"):
                            g2 = g[g["Include"] == True]
                            one = g.iloc[0]
                            if g2.empty:
                                price = None
                                reason = "Îß§Ïπ≠ ÌõÑÎ≥¥ ÏóÜÏùå(ÎòêÎäî Ï†ÑÎ∂Ä Ï†úÏô∏)"
                            else:
                                price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())
                                reason = f"{len(g2)}Í∞ú ÎÇ¥Ïó≠ ÌèâÍ∑†(Íµ≠ÎÇ¥DB)"
                            rows.append({
                                "BOQ_ID": int(boq_id),
                                "Î™ÖÏπ≠": one.get("BOQ_Î™ÖÏπ≠", ""),
                                "Í∑úÍ≤©": one.get("BOQ_Í∑úÍ≤©", ""),
                                "Îã®ÏúÑ": one.get("BOQ_Îã®ÏúÑ", ""),
                                "ÏàòÎüâ": one.get("BOQ_ÏàòÎüâ", ""),
                                "Final Price": f"{price:,.2f}" if price is not None else None,
                                "ÏÇ∞Ï∂úÍ∑ºÍ±∞": reason,
                            })
                        return pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)
    
                    # --- ÎêòÎèåÎ¶¨Í∏∞(ÌòÑÏû¨ BOQ) ---
                    if btn_undo_one:
                        backup = st.session_state["dom_include_backup"].get(int(sel_id))
                        if backup is not None and len(backup) == len(log_view_full.index):
                            st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success("ÎêòÎèåÎ¶¨Í∏∞ ÏôÑÎ£å(ÌòÑÏû¨ BOQ)")
                            st.rerun()
                        else:
                            st.warning("ÎêòÎèåÎ¶¥ Î∞±ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§(ÎòêÎäî ÌõÑÎ≥¥ÌñâÏù¥ Î≥ÄÍ≤ΩÎê®).")
    
                    # --- AI Ï†ÅÏö©(ÌòÑÏû¨ BOQ) ---
                    if btn_ai_one:
                        # ÌòÑÏû¨ BOQ Include Î∞±ÏóÖ
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
    
                        updated, summary = apply_agent_to_log(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            boq_id=int(sel_id),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        if summary:
                            st.success(f"AI Ï†ÅÏö© ÏôÑÎ£å(ÌòÑÏû¨ BOQ): {summary['kept']}/{summary['total']} Ìè¨Ìï®, Î™®Îìú={summary['mode']}")
                        st.rerun()
    
                    # --- AI Ï†ÅÏö©(Ï†ÑÏ≤¥ BOQ) ---
                    if btn_ai_all:
                        st.session_state["dom_include_backup_all"] = st.session_state["dom_log_df_edited"][["BOQ_ID", "Include"]].copy()
    
                        updated, sum_df = apply_agent_to_all_boqs(
                            log_all=st.session_state["dom_log_df_edited"].copy(),
                            mode=agent_mode,
                            min_keep=int(min_keep),
                            max_keep=int(max_keep),
                        )
                        st.session_state["dom_log_df_edited"] = updated
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        st.success("AI Ï†ÅÏö© ÏôÑÎ£å(Ï†ÑÏ≤¥ BOQ)")
                        if sum_df is not None and not sum_df.empty:
                            st.dataframe(sum_df, use_container_width=True)
                        st.rerun()
    
                    # --- ÎêòÎèåÎ¶¨Í∏∞(Ï†ÑÏ≤¥ BOQ) ---
                    if btn_undo_all:
                        backup_all = st.session_state.get("dom_include_backup_all")
                        if backup_all is None or backup_all.empty:
                            st.warning("ÎêòÎèåÎ¶¥ Ï†ÑÏ≤¥ Î∞±ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§.")
                        else:
                            cur = st.session_state["dom_log_df_edited"].copy()
                            b = backup_all.copy()
                            b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                            cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)
    
                            cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                            cur["Include"] = cur["Include"].fillna(False).astype(bool)
    
                            st.session_state["dom_log_df_edited"] = cur
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success("ÎêòÎèåÎ¶¨Í∏∞ ÏôÑÎ£å(Ï†ÑÏ≤¥ BOQ)")
                            st.rerun()

                    # =========================
                    # (Íµ≠ÎÇ¥) ÌïÑÌÑ∞/Ïª∑ Ï°∞Ï†ï UI (ÌòÑÏû¨ BOQ)
                    # =========================
                    # ÌïÑÌÑ∞ ÎåÄÏÉÅ Ïª¨Îüº Î≥¥Í∞ï
                    for c in ["ÌòÑÏû•Î™Ö", "ÏÑ∏Î∂ÄÎ∂ÑÎ•ò", "__hyb", "__adj_price"]:
                        if c not in log_view_full.columns:
                            log_view_full[c] = None
                    
                    # Ïà´ÏûêÌòï Ï†ïÎ¶¨
                    log_view_full["__hyb_num"] = pd.to_numeric(log_view_full["__hyb"], errors="coerce").fillna(0.0)
                    log_view_full["__price_num"] = pd.to_numeric(log_view_full["__adj_price"], errors="coerce").fillna(np.nan)
                    
                    with st.expander("üîé ÌïÑÌÑ∞(ÌòÑÏû•Î™Ö/ÏÑ∏Î∂ÄÎ∂ÑÎ•ò/Ïú†ÏÇ¨ÎèÑ) + Ïª∑ ÎπÑÏú® Ï°∞Ï†ï", expanded=True):
                        # 1) ÌòÑÏû•Î™Ö ÌïÑÌÑ∞
                        site_opts = sorted([
                            x for x in log_view_full["ÌòÑÏû•Î™Ö"].astype(str).fillna("").unique().tolist()
                            if x.strip() and x not in ["nan", "None"]
                        ])
                        sel_sites_nm = st.multiselect(
                            "ÌòÑÏû•Î™Ö ÌïÑÌÑ∞(ÏÑ†ÌÉù Ïãú Ìï¥Îãπ ÌòÑÏû•Îßå ÌëúÏãú/Ï†ÅÏö©)",
                            options=site_opts,
                            default=st.session_state.get("dom_f_site_nm", []),
                            key="dom_f_site_nm",
                        )
                    
                        # 2) ÏÑ∏Î∂ÄÎ∂ÑÎ•ò ÌïÑÌÑ∞
                        sub_opts = sorted([
                            x for x in log_view_full["ÏÑ∏Î∂ÄÎ∂ÑÎ•ò"].astype(str).fillna("").unique().tolist()
                            if x.strip() and x not in ["nan", "None"]
                        ])
                        sel_sub = st.multiselect(
                            "ÏÑ∏Î∂ÄÎ∂ÑÎ•ò ÌïÑÌÑ∞(ÏÑ†ÌÉù Ïãú Ìï¥Îãπ Î∂ÑÎ•òÎßå ÌëúÏãú/Ï†ÅÏö©)",
                            options=sub_opts,
                            default=st.session_state.get("dom_f_sub", []),
                            key="dom_f_sub",
                        )
                    
                        # 3) Ïú†ÏÇ¨ÎèÑ ÌïÑÌÑ∞(Î≤îÏúÑ)
                        hyb_min_default = float(st.session_state.get("dom_f_hyb_min", 0.0))
                        hyb_max_default = float(st.session_state.get("dom_f_hyb_max", 100.0))
                        hyb_min, hyb_max = st.slider(
                            "Îß§Ïπ≠ Ïú†ÏÇ¨ÎèÑ (%)",
                            min_value=0.0,
                            max_value=100.0,
                            value=(hyb_min_default, hyb_max_default),
                            step=1.0,
                            key="dom_f_hyb_range",
                        )
                        st.session_state["dom_f_hyb_min"] = hyb_min
                        st.session_state["dom_f_hyb_max"] = hyb_max
                    
                        # 4) ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú®(ÌòÑÏû¨ BOQ Ï†ÑÏö©)
                        cut_pct = st.slider(
                            "ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú®(ÌòÑÏû¨ BOQ, %)",
                            min_value=0,
                            max_value=30,
                            value=int(st.session_state.get("dom_cut_pct_tab2", 20)),
                            step=5,
                            key="dom_cut_pct_tab2",
                        )
                        cut_ratio_local = float(cut_pct) / 100.0
                    
                        cbtn1, cbtn2, cbtn3 = st.columns([1.4, 1.2, 1.4])
                        with cbtn1:
                            btn_apply_filter_cut = st.button("‚úÇÔ∏è ÌïÑÌÑ∞+Ïª∑ Ï†ÅÏö©(Include ÏûêÎèô Ïû¨ÏÑ§Ï†ï)", key="dom_btn_apply_filter_cut")
                        with cbtn2:
                            btn_reset_to_default = st.button("‚Ü©Ô∏è DefaultIncludeÎ°ú Ï¥àÍ∏∞Ìôî(ÌòÑÏû¨ BOQ)", key="dom_btn_reset_default")
                        with cbtn3:
                            st.caption("‚Äª ‚ÄòÌïÑÌÑ∞+Ïª∑ Ï†ÅÏö©‚ÄôÏùÄ ÌòÑÏû¨ BOQÏùò IncludeÎ•º ÌïÑÌÑ∞ Í≤∞Í≥º Í∏∞Ï§ÄÏúºÎ°ú Îã§Ïãú ÏÑ∏ÌåÖÌï©ÎãàÎã§.")
                    
                    # --- ÌïÑÌÑ∞ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±(ÌëúÏãú + Ïª∑ Ï†ÅÏö©Ïóê Í≥µÌÜµ ÏÇ¨Ïö©) ---
                    mask = pd.Series(True, index=log_view_full.index)
                    
                    if sel_sites_nm:
                        mask &= log_view_full["ÌòÑÏû•Î™Ö"].astype(str).isin([str(x) for x in sel_sites_nm])
                    
                    if sel_sub:
                        mask &= log_view_full["ÏÑ∏Î∂ÄÎ∂ÑÎ•ò"].astype(str).isin([str(x) for x in sel_sub])
                    
                    mask &= log_view_full["__hyb_num"].between(float(hyb_min), float(hyb_max))
                    
                    # ÌëúÏãúÏö©(ÌïÑÌÑ∞ Ï†ÅÏö©Îêú ÌõÑÎ≥¥Îßå Î≥¥Ïó¨Ï§å)
                    log_view_full_filtered = log_view_full.loc[mask].copy()
                    
                    # --- DefaultInclude Ï¥àÍ∏∞Ìôî(ÌòÑÏû¨ BOQ) ---
                    if btn_reset_to_default:
                        # Î∞±ÏóÖ Ï†ÄÏû•(ÌòÑÏû¨ BOQ)
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
                    
                        # DefaultInclude Í∏∞Ï§ÄÏúºÎ°ú Include Î≥µÏõê
                        base_inc = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "DefaultInclude"].fillna(False).astype(bool)
                        st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = base_inc.values
                    
                        st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                        st.success("ÌòÑÏû¨ BOQÎ•º DefaultInclude Í∏∞Ï§ÄÏúºÎ°ú Ï¥àÍ∏∞ÌôîÌñàÏäµÎãàÎã§.")
                        st.rerun()
                    
                    # --- ÌïÑÌÑ∞+Ïª∑ Ï†ÅÏö©(ÌòÑÏû¨ BOQ) ---
                    if btn_apply_filter_cut:
                        # Î∞±ÏóÖ Ï†ÄÏû•(ÌòÑÏû¨ BOQ)
                        st.session_state["dom_include_backup"][int(sel_id)] = st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"].copy()
                    
                        # 1) ÌòÑÏû¨ BOQ Ï†ÑÏ≤¥ IncludeÎ•º Ïö∞ÏÑ† FalseÎ°ú
                        st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = False
                    
                        # 2) ÌïÑÌÑ∞ ÌÜµÍ≥º ÌõÑÎ≥¥Îßå Í∞ÄÏßÄÍ≥† Ïª∑ Ï†ÅÏö©
                        sub = log_view_full.loc[mask].copy()
                        sub["__price_num"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
                    
                        sub = sub.dropna(subset=["__price_num"]).sort_values("__price_num").copy()
                        n = len(sub)
                        cut = max(0, int(n * cut_ratio_local)) if n > 5 else 0
                    
                        if n == 0:
                            st.warning("ÌïÑÌÑ∞ Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.")
                        else:
                            if cut > 0:
                                keep_mask = np.zeros(n, dtype=bool)
                                keep_mask[cut:n - cut] = True
                            else:
                                keep_mask = np.ones(n, dtype=bool)
                    
                            kept_index = sub.index[keep_mask]
                            st.session_state["dom_log_df_edited"].loc[kept_index, "Include"] = True
                    
                            # DefaultIncludeÎèÑ Í∞ôÏù¥ Í∞±Ïã†(ÏõêÌïòÎ©¥ Ï†úÍ±∞ Í∞ÄÎä•)
                            st.session_state["dom_log_df_edited"].loc[log_view_full.index, "DefaultInclude"] = False
                            st.session_state["dom_log_df_edited"].loc[kept_index, "DefaultInclude"] = True
                    
                            st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
                            st.success(f"ÌïÑÌÑ∞+Ïª∑ Ï†ÅÏö© ÏôÑÎ£å: {len(kept_index)}/{n} Ìè¨Ìï®")
                        st.rerun()
                        
                    # Ïù¥ÌõÑ Ìé∏Ïßë ÌôîÎ©¥ÏùÄ 'ÌïÑÌÑ∞Îêú ÌõÑÎ≥¥'Î•º Î≥¥Ïó¨Ï£ºÎèÑÎ°ù ÍµêÏ≤¥
                    log_view_full = log_view_full_filtered
                    
    
                    # --- ÌôîÎ©¥Ïóê Î≥¥Ïó¨Ï§Ñ Ïª¨Îüº(Íµ≠ÎÇ¥) ---
                    display_cols = [
                        "Include", "DefaultInclude",
                        "Ïã§ÌñâÎ™ÖÏπ≠", "Í∑úÍ≤©", "Îã®ÏúÑ", "ÏàòÎüâ",
                        "Î≥¥Ï†ïÎã®Í∞Ä", "Í≥ÑÏïΩÎã®Í∞Ä", "Í≥ÑÏïΩÏõî",
                        "__adj_price", "__hyb",
                        "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö", "ÌòÑÏû•ÌäπÏÑ±",
                        "ÏóÖÏ≤¥ÏΩîÎìú", "ÏóÖÏ≤¥Î™Ö",
                        "Í≥µÏ¢ÖCodeÎ∂ÑÎ•ò", "ÏÑ∏Î∂ÄÎ∂ÑÎ•ò",
                    ]
                    for c in display_cols:
                        if c not in log_view_full.columns:
                            log_view_full[c] = None
    
                    log_view = log_view_full[display_cols].copy()
    
                    edited_view = st.data_editor(
                        log_view,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "Include": st.column_config.CheckboxColumn("Ìè¨Ìï®", help="ÌèâÍ∑†Îã®Í∞Ä ÏÇ∞Ï∂ú Ìè¨Ìï®/Ï†úÏô∏"),
                            "DefaultInclude": st.column_config.CheckboxColumn("Í∏∞Î≥∏Ìè¨Ìï®", help="Ï¥àÍ∏∞ ÏûêÎèô Ìè¨Ìï® Ïó¨Î∂Ä(Ïª∑ Î°úÏßÅ)"),
                            "__adj_price": st.column_config.NumberColumn("ÏÇ∞Ï∂úÎã®Í∞Ä", format="%.2f"),
                            "__hyb": st.column_config.NumberColumn("Ïú†ÏÇ¨ÎèÑ", format="%.2f"),
                            "Î≥¥Ï†ïÎã®Í∞Ä": st.column_config.NumberColumn("Î≥¥Ï†ïÎã®Í∞Ä", format="%.2f"),
                            "Í≥ÑÏïΩÎã®Í∞Ä": st.column_config.NumberColumn("Í≥ÑÏïΩÎã®Í∞Ä", format="%.2f"),
                        },
                        disabled=[c for c in log_view.columns if c not in ["Include"]],
                        key="dom_log_editor_oneboq",
                    )
    
                    # --- Ìé∏Ïßë Î∞òÏòÅ(ÌòÑÏû¨ BOQ rowsÎßå) ---
                    st.session_state["dom_log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values
    
                    # --- Í≤∞Í≥º Ïû¨Í≥ÑÏÇ∞(Include Î∞òÏòÅ) ---
                    st.session_state["dom_result_df_adjusted"] = recompute_dom_result_from_log(st.session_state["dom_log_df_edited"])
    
                    # Ï∞∏Í≥†Ïö©: ÌòÑÏû¨ BOQ Ìè¨Ìï® ÌõÑÎ≥¥ Ïàò
                    inc_n = int(pd.Series(edited_view["Include"]).sum())
                    st.caption(f"ÌòÑÏû¨ BOQ Ìè¨Ìï® ÌõÑÎ≥¥: {inc_n}Í∞ú")
    
    
    
    with tab1:
        if not st.session_state.get("dom_has_results", False):
            st.info("Íµ≠ÎÇ¥ BOQ ÏóÖÎ°úÎìú ÌõÑ 'ÏÇ∞Ï∂ú Ïã§Ìñâ(Íµ≠ÎÇ¥)'ÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.")
        else:
            # ‚úÖ Ìï¥Ïô∏ TAB1Í≥º ÎèôÏùº Ìå®ÌÑ¥: adjusted Ïö∞ÏÑ†, ÏóÜÏúºÎ©¥ base
            show_df = st.session_state.get(
                "dom_result_df_adjusted",
                st.session_state.get("dom_result_df_base", pd.DataFrame())
            ).copy()
    
            # (ÏÑ†ÌÉù) ÌëúÏãúÏö© Ï†ïÎ¶¨: BOQ_ID Í∏∞Ï§Ä Ï†ïÎ†¨/Ïª¨Îüº ÏàúÏÑú Ï†ïÎ¶¨ Îì±
            if "BOQ_ID" in show_df.columns:
                try:
                    show_df["BOQ_ID"] = show_df["BOQ_ID"].astype(int)
                    show_df = show_df.sort_values("BOQ_ID").reset_index(drop=True)
                except Exception:
                    pass
    
            st.dataframe(show_df, use_container_width=True)

    
    with tab3:
        if not st.session_state.get("dom_has_results", False):
            st.info("ÏÇ∞Ï∂ú Ïã§Ìñâ ÌõÑ Î≥¥Í≥†ÏÑú/Îã§Ïö¥Î°úÎìúÍ∞Ä Í∞ÄÎä•Ìï©ÎãàÎã§.")
        else:
            st.markdown("## üìù Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú(Íµ≠ÎÇ¥)")
    
            base_result = st.session_state.get(
                "dom_result_df_adjusted",
                st.session_state.get("dom_result_df_base", pd.DataFrame())
            ).copy()
    
            log_for_report = st.session_state.get(
                "dom_log_df_edited",
                st.session_state.get("dom_log_df_base", pd.DataFrame())
            ).copy()
    
            # 1) Í≥µÏ¢Ö ÌäπÏÑ±(Íµ≠ÎÇ¥ÏóêÎäî Ìï¥Ïô∏Ï≤òÎüº feature_master Ïó∞ÎèôÏù¥ ÏóÜÏúºÎØÄÎ°ú, ÎèôÏùº ÏÑπÏÖòÏùÄ "ÌòÑÏû•ÌäπÏÑ± ÏÑ†ÌÉùÍ∞í"ÏúºÎ°ú ÎåÄÏ≤¥)
            st.markdown("### 1) Í≥µÏ¢Ö ÌäπÏÑ±")
            _sel_feat = st.session_state.get("dom_sel_feat", [])
            if not _sel_feat:
                st.info("ÏÑ†ÌÉùÎêú ÌòÑÏû•ÌäπÏÑ±Ïù¥ ÏóÜÏäµÎãàÎã§.")
            else:
                st.dataframe(pd.DataFrame({"ÌòÑÏû•ÌäπÏÑ±(ÏÑ†ÌÉù)": list(_sel_feat)}), use_container_width=True)
    
            # 2) Ïã§Ï†Å ÌòÑÏû• Î¶¨Ïä§Ìä∏
            st.markdown("### 2) Ïã§Ï†Å ÌòÑÏû• Î¶¨Ïä§Ìä∏")
            _sel_sites = st.session_state.get("dom_selected_site_codes", [])
            st_sites = build_site_context_table(cost_db_kr, _sel_sites)
            if st_sites.empty:
                st.info("ÏÑ†ÌÉùÎêú ÌòÑÏû•Ïù¥ ÏóÜÏäµÎãàÎã§.")
            else:
                st.dataframe(st_sites, use_container_width=True)
    
            # 3) Îã®Í∞Ä Ï∂îÏ∂ú Í∑ºÍ±∞(Ï°∞Í±¥)
            st.markdown("### 3) Îã®Í∞Ä Ï∂îÏ∂ú Í∑ºÍ±∞(Ï°∞Í±¥)")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("Îß§Ïπ≠ Ïú†ÏÇ¨ÎèÑ, (%)", f"{float(st.session_state.get('dom_sim_threshold', 0.0)):.0f}")
            with c2:
                st.metric("ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú®(%)", f"{float(st.session_state.get('dom_cut_ratio', 0.0)):.0f}")
            with c3:
                st.metric("DB", "Íµ≠ÎÇ¥DB")
    
            # 4) AI Ï†ÅÏö© Ïãú ÏµúÏ¢Ö Í∏∞Ï§Ä(Ìï¥Ïô∏ÏôÄ ÎèôÏùº Î¨∏Íµ¨)
            st.markdown("### 4) AI Ï†ÅÏö© Ïãú ÏµúÏ¢Ö Í∏∞Ï§Ä")
            st.write(get_ai_effective_rule_text())
    
            # 5) Ïã§Ï†Å Îã®Í∞Ä BOQ(Í≤∞Í≥º)
            st.markdown("### 5) Ïã§Ï†Å Îã®Í∞Ä BOQ(Í≤∞Í≥º)")
            if base_result is None or base_result.empty:
                st.warning("Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä ÏÇ∞Ï∂ú Ïã§Ìñâ ÌõÑ Îã§Ïãú ÏãúÎèÑÌïòÏÑ∏Ïöî.")
            else:
                st.dataframe(base_result, use_container_width=True)
    
            # 6~7 ÌÖåÏù¥Î∏î ÏÉùÏÑ±/Í∞±Ïã†
            if st.button("üìù Î≥¥Í≥†ÏÑú ÏÉùÏÑ±/Í∞±Ïã†(Íµ≠ÎÇ¥)", key="btn_build_report_kr"):
                summary_df, detail_df = build_report_tables_domestic(log_for_report, base_result)
                st.session_state["dom_report_summary_df"] = summary_df
                st.session_state["dom_report_detail_df"] = detail_df
    
            summary_df = st.session_state.get("dom_report_summary_df", pd.DataFrame())
            detail_df = st.session_state.get("dom_report_detail_df", pd.DataFrame())
    
            st.markdown("### 6) Í∞Å ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Í∑ºÍ±∞(ÌèâÍ∑†)")
            if summary_df is None or summary_df.empty:
                st.info("Î≥¥Í≥†ÏÑúÎ•º Î≥¥Î†§Î©¥ 'Î≥¥Í≥†ÏÑú ÏÉùÏÑ±/Í∞±Ïã†(Íµ≠ÎÇ¥)'ÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.")
            else:
                st.dataframe(summary_df, use_container_width=True)
    
            st.markdown("### 7) Í∞Å ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Í∑ºÍ±∞(ÏÑ†ÌÉùÎêú ÎÇ¥Ïó≠)")
            if detail_df is not None and not detail_df.empty:
                st.dataframe(detail_df, use_container_width=True)
            else:
                st.info("Include=True ÏÉÅÏÑ∏ ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§(Ï†ÑÎ∂Ä Ï†úÏô∏ÎêòÏóàÍ±∞ÎÇò ÌõÑÎ≥¥Í∞Ä ÏóÜÏùå).")
    
            # 8) Î∂ÑÌè¨ Í∑∏ÎûòÌîÑ
            st.markdown("### 8) ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Î∂ÑÌè¨")
            render_boq_scatter_domestic(log_for_report, base_result)
    
            # -------------------------
            # Excel Îã§Ïö¥Î°úÎìú(Ìï¥Ïô∏ ÌòïÏãùÍ≥º ÎèôÏùº: result + log + report 2ÏãúÌä∏)
            # -------------------------
            out_result = base_result.copy()
            out_log = log_for_report.copy()
            rep_sum = st.session_state.get("dom_report_summary_df", pd.DataFrame())
            rep_det = st.session_state.get("dom_report_detail_df", pd.DataFrame())
    
            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as writer:
                out_result.to_excel(writer, index=False, sheet_name="boq_with_price_kr")
                out_log.to_excel(writer, index=False, sheet_name="calculation_log_kr")
                if rep_sum is not None and not rep_sum.empty:
                    rep_sum.to_excel(writer, index=False, sheet_name="report_summary_kr")
                if rep_det is not None and not rep_det.empty:
                    rep_det.to_excel(writer, index=False, sheet_name="report_detail_kr")
            bio.seek(0)
    
            st.download_button(
                "‚¨áÔ∏è Excel Îã§Ïö¥Î°úÎìú(Íµ≠ÎÇ¥)",
                data=bio.read(),
                file_name="result_unitrate_kr.xlsx",
                key="dom_download_btn",
            )

# ============================================================
# ‚úÖ Ìï¥Ïô∏ ÌÉ≠ (Í∏∞Ï°¥ ÏΩîÎìú Ï†ÑÏ≤¥Î•º Ìï®ÏàòÎ°ú Í∞êÏãº Î≤ÑÏ†Ñ)
# ============================================================
def render_overseas():
    gs_header("üì¶ Ìï¥Ïô∏ Ïã§Ï†ÅÎã®Í∞Ä DB")

    # =========================
    # Sidebar: ÏÑ§Ï†ï
    # =========================
    st.sidebar.markdown("<div class='sb-major'>‚öôÔ∏è ÏÑ§Ï†ï</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    use_site_filter = True

    DEFAULT_W_STR = 0.3
    DEFAULT_TOP_K_SEM = 200
    w_str = DEFAULT_W_STR
    w_sem = 1.0 - w_str
    top_k_sem = DEFAULT_TOP_K_SEM

    boq_file = None

    # =========================
    # (1) BOQ ÏóÖÎ°úÎìú (Î®ºÏ†Ä!)
    # =========================
    with st.container(border=True):
        card_title("üì§ BOQ ÌååÏùº ÏóÖÎ°úÎìú")
    
        boq_file = st.file_uploader(
            label="",
            type=["xlsx"],
            label_visibility="collapsed",
            key="boq_uploader_overseas",
        )
    # =========================
    # (2) Î©îÏù∏: BOQ ÏóÖÎ°úÎìú ÏïÑÎûò ÌäπÏÑ± ÏÑ†ÌÉù UI
    # =========================
    auto_sites = []
    
    if boq_file is not None:
        with st.container(border=True):
            card_title("üè∑Ô∏è ÌîÑÎ°úÏ†ùÌä∏ ÌäπÏÑ± ÏÑ†ÌÉù", "")
            st.markdown(
                "<div class='dash-muted'>ÌîÑÎ°úÏ†ùÌä∏ ÌäπÏÑ±ÏùÑ ÏÑ†ÌÉùÌïòÎ©¥ Í¥ÄÎ†® ÌòÑÏû•Ïù¥ ÏûêÎèôÏúºÎ°ú Ï∂îÏ≤úÎê©ÎãàÎã§.</div>",
                unsafe_allow_html=True
            )
    
            fm = feature_master.copy()
    
            cols6 = ["ÎåÄÍ≥µÏ¢Ö", "Ï§ëÍ≥µÏ¢Ö", "ÏÜåÍ≥µÏ¢Ö", "Cost Driver Type", "Cost Driver Method", "Cost Driver Condition"]
            need_cols = ["ÌäπÏÑ±ID"] + cols6
    
            for c in need_cols:
                if c not in fm.columns:
                    fm[c] = ""
                fm[c] = fm[c].astype(str).fillna("").str.strip()
    
            if ("ÌäπÏÑ±ID" in project_feature_long.columns) and ("ÌòÑÏû•ÏΩîÎìú" in project_feature_long.columns):
                site_cnt = project_feature_long.groupby("ÌäπÏÑ±ID")["ÌòÑÏû•ÏΩîÎìú"].nunique().astype(int).to_dict()
            else:
                site_cnt = {}
    
            fm["ÌòÑÏû•Ïàò"] = fm["ÌäπÏÑ±ID"].map(site_cnt).fillna(0).astype(int)
    
            fm["ÎùºÎ≤®"] = fm.apply(
                lambda r: f'{r["ÌäπÏÑ±ID"]} | {r["ÎåÄÍ≥µÏ¢Ö"]}/{r["Ï§ëÍ≥µÏ¢Ö"]}/{r["ÏÜåÍ≥µÏ¢Ö"]} | '
                          f'{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                          f'ÌòÑÏû• {r["ÌòÑÏû•Ïàò"]}Í∞ú',
                axis=1
            )
    
            keyword = st.text_input(
                "ÌäπÏÑ± Î™©Î°ù ÌïÑÌÑ∞(ÌÇ§ÏõåÎìú)",
                value="",
                placeholder="Ïòà: DCM, Jet, ÏßÄÎ∞òÍ∞úÎüâ, ÎèÑÏã¨ ...",
                key="feature_keyword_overseas",
            )
    
            fm_view = fm
            if keyword.strip():
                kw = keyword.strip().lower()
                fm_view = fm[fm["ÎùºÎ≤®"].str.lower().str.contains(kw, na=False)].copy()
    
            options = fm_view["ÎùºÎ≤®"].tolist()
            label_to_id = dict(zip(fm_view["ÎùºÎ≤®"], fm_view["ÌäπÏÑ±ID"]))
    
            # ‚úÖ ÌïÑÌÑ∞ Î∞îÍøîÎèÑ Í∏∞Ï°¥ ÏÑ†ÌÉù Ïú†ÏßÄ
            master_label_to_id = dict(zip(fm["ÎùºÎ≤®"], fm["ÌäπÏÑ±ID"]))
            master_id_to_label = {}
            for lab, fid in master_label_to_id.items():
                master_id_to_label.setdefault(fid, lab)
    
            current_selected_ids = st.session_state.get("selected_feature_ids", [])
            current_labels = [master_id_to_label[fid] for fid in current_selected_ids if fid in master_id_to_label]
    
            new_selected_labels = st.multiselect(
                "ÌäπÏÑ± ÏÑ†ÌÉù(Îã§Ï§ë ÏÑ†ÌÉù Í∞ÄÎä•)",
                options=options,
                default=[lab for lab in current_labels if lab in options],
                key="selected_features_labels_overseas",
            )
    
            new_ids = [label_to_id[lab] for lab in new_selected_labels]
            kept_ids = [
                fid for fid in current_selected_ids
                if (fid in master_id_to_label and master_id_to_label[fid] not in options)
            ]
            merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))
            st.session_state["selected_feature_ids"] = merged_ids
    
            # ‚úÖ auto_sites Í≥ÑÏÇ∞/Ï†ÄÏû•(Í∏∞Îä• Ïú†ÏßÄ)
            if merged_ids:
                auto_sites = (
                    project_feature_long[
                        project_feature_long["ÌäπÏÑ±ID"].astype(str).isin([str(x) for x in merged_ids])
                    ]["ÌòÑÏû•ÏΩîÎìú"].astype(str).unique().tolist()
                )
            else:
                auto_sites = []
    
            new_auto_sites = sorted({
                norm_site_code(x)
                for x in (auto_sites or [])
                if norm_site_code(x)
            })
            st.session_state["auto_sites"] = new_auto_sites
    
    else:
        st.info("BOQ ÏóÖÎ°úÎìú ÌõÑ ÌîÑÎ°úÏ†ùÌä∏ ÌäπÏÑ±ÏùÑ ÏÑ†ÌÉùÌï† Ïàò ÏûàÏäµÎãàÎã§.")

    # =========================
    # (3) ÏÇ¨Ïù¥ÎìúÎ∞î: Ïã§Ï†Å ÌòÑÏû• ÏÑ†ÌÉù
    # =========================
    selected_site_codes = None

    if use_site_filter:
        _sel_cnt = len(set(
            st.session_state.get("selected_auto_codes", [])
            + st.session_state.get("selected_extra_codes", [])
        ))
        
        st.sidebar.markdown(
            f"""
            <div class="sb-row">
              <div class="sb-title">üèóÔ∏è Ïã§Ï†Å ÌòÑÏû• ÏÑ†ÌÉù</div>
              <div class="sb-muted">ÏÑ†ÌÉù ÌòÑÏû•: {_sel_cnt}Í∞ú</div>
            </div>
            """,
            unsafe_allow_html=True
        )
        st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

        auto_sites = st.session_state.get("auto_sites", [])

        # 1) cost_dbÏóêÏÑú Ï†ÑÏ≤¥ ÌòÑÏû• Î™©Î°ù ÎßåÎì§Í∏∞
        site_df = cost_db[["ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö"]].copy()
        site_df = site_df.dropna(subset=["ÌòÑÏû•ÏΩîÎìú"])

        site_df["ÌòÑÏû•ÏΩîÎìú"] = site_df["ÌòÑÏû•ÏΩîÎìú"].apply(norm_site_code)
        site_df["ÌòÑÏû•Î™Ö"] = site_df["ÌòÑÏû•Î™Ö"].astype(str).fillna("").str.strip()
        site_df.loc[site_df["ÌòÑÏû•Î™Ö"].isin(["", "nan", "None"]), "ÌòÑÏû•Î™Ö"] = "(ÌòÑÏû•Î™ÖÏóÜÏùå)"
        site_df = site_df.drop_duplicates(subset=["ÌòÑÏû•ÏΩîÎìú"]).reset_index(drop=True)

        all_codes = site_df["ÌòÑÏû•ÏΩîÎìú"].tolist()
        code_to_name = dict(zip(site_df["ÌòÑÏû•ÏΩîÎìú"], site_df["ÌòÑÏû•Î™Ö"]))

        auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
        auto_codes = [c for c in auto_codes_raw if c in code_to_name]
        other_codes = [c for c in all_codes if c not in set(auto_codes)]

        def fmt_site_code(code: str) -> str:
            name = code_to_name.get(code, "")
            name = name.strip()
            if len(name) > 25:
                return name[:25] + "‚Ä¶"
            return name

        # ‚úÖ auto ÌõÑÎ≥¥Í∞Ä Î∞îÎÄåÎ©¥ Ï¶âÏãú Ï†ÑÏ≤¥ ÏÑ†ÌÉù ÏÉÅÌÉú
        auto_sig = "|".join(auto_codes)
        if st.session_state.get("_auto_sig") != auto_sig:
            st.session_state["_auto_sig"] = auto_sig
            st.session_state["selected_auto_codes"] = list(auto_codes)

        if "selected_auto_codes" not in st.session_state:
            st.session_state["selected_auto_codes"] = list(auto_codes)
        if "selected_extra_codes" not in st.session_state:
            st.session_state["selected_extra_codes"] = []

        selected_auto_codes = st.sidebar.multiselect(
            "Ïã§Ï†ÅÌòÑÏû•",
            options=auto_codes,
            key="selected_auto_codes",
            format_func=fmt_site_code,
        )

        selected_extra_codes = st.sidebar.multiselect(
            "Ï∂îÍ∞Ä Ïã§Ï†ÅÌòÑÏû•",
            options=other_codes,
            key="selected_extra_codes",
            format_func=fmt_site_code,
        )

        selected_site_codes = sorted(set(selected_auto_codes + selected_extra_codes))

    # =========================
    # Í∏∞ÌÉÄ Ïä¨ÎùºÏù¥Îçî/ÌÜµÌôî ÏÑ†ÌÉù
    # =========================
    st.sidebar.markdown("<div class='sb-title'>üß© ÏÑ§Ï†ïÍ∞í</div>", unsafe_allow_html=True)
    st.sidebar.markdown("<hr class='sb-hr'/>", unsafe_allow_html=True)

    sim_threshold = st.sidebar.slider("Îß§Ïπ≠ Ïú†ÏÇ¨ÎèÑ Í∏∞Ï§ÄÍ∞í(%)", 0, 100, 60, 5)
    cut_ratio = st.sidebar.slider("ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú® (%)", 0, 30, 20, 5) / 100.0

    target_options = sorted(factor["Íµ≠Í∞Ä"].astype(str).str.upper().unique().tolist())
    default_idx = target_options.index("KRW") if "KRW" in target_options else 0
    target_currency = st.sidebar.selectbox("ÏÇ∞Ï∂úÌÜµÌôî", options=target_options, index=default_idx)

    missing_exchange = exchange[exchange["ÌÜµÌôî"].astype(str).str.upper() == target_currency].empty
    missing_factor = factor[factor["Íµ≠Í∞Ä"].astype(str).str.upper() == target_currency].empty

    if missing_exchange:
        st.sidebar.error(f"ÏÑ†ÌÉùÌïú ÏÇ∞Ï∂úÌÜµÌôî '{target_currency}'Ïóê ÎåÄÌïú ÌôòÏú® Ï†ïÎ≥¥Í∞Ä exchange.xlsxÏóê ÏóÜÏäµÎãàÎã§.")
    if missing_factor:
        st.sidebar.error(f"ÏÑ†ÌÉùÌïú ÏÇ∞Ï∂úÌÜµÌôî '{target_currency}'Ïóê ÎåÄÌïú ÏßÄÏàò Ï†ïÎ≥¥Í∞Ä Factor.xlsxÏóê ÏóÜÏäµÎãàÎã§.")

    sidebar_hr(thick=True, mt=10, mb=8)

    # =========================
    # Run / Auto Recompute
    # =========================
    auto_recompute = True  # UIÎäî Ïà®Í∏∞ÏßÄÎßå Í∏∞Îä•ÏùÄ Ìï≠ÏÉÅ ON

    def boq_file_signature(uploaded_file) -> str:
        if uploaded_file is None:
            return "no_boq"
        try:
            b = uploaded_file.getvalue()
            if len(b) > 2_000_000:
                b = b[:1_000_000] + b[-1_000_000:]
            return hashlib.md5(b).hexdigest()
        except Exception:
            return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

    def make_params_signature() -> str:
        payload = {
            "boq": boq_file_signature(boq_file),
            "use_site_filter": bool(use_site_filter),
            "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
            "sim_threshold": float(sim_threshold),
            "cut_ratio": float(cut_ratio),
            "target_currency": str(target_currency),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "top_k_sem": int(top_k_sem),
        }
        s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
        return hashlib.md5(s.encode("utf-8")).hexdigest()

    def run_calculation_and_store(run_sig: str):
        status_box = st.empty()

        if boq_file is None:
            status_box.empty()
            st.warning("BOQ ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌï¥ Ï£ºÏÑ∏Ïöî.")
            return
        if missing_exchange or missing_factor:
            status_box.empty()
            st.error("ÏÇ∞Ï∂úÌÜµÌôîÏóê ÌïÑÏöîÌïú ÌôòÏú®/ÏßÄÏàò Ï†ïÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§.")
            return

        progress = st.progress(0.0)
        prog_text = st.empty()

        status_box.markdown("### ‚è≥ ÏÇ∞Ï∂úÏ§ë... (BOQ Î°úÎìú/ÌïÑÌÑ∞ÎßÅ)")
        boq = pd.read_excel(boq_file, engine="openpyxl")

        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["ÌòÑÏû•ÏΩîÎìú"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(f"Ï†ÑÏ≤¥ {len(cost_db):,}Í∞ú ÎÇ¥Ïó≠ Ï§ë {len(cost_db_run):,}Í∞ú ÎÇ¥Ïó≠ÏúºÎ°ú ÏÇ∞Ï∂ú Ïã§Ìñâ")

        pool_sig_payload = {
            "boq": boq_file_signature(boq_file),
            "use_site_filter": bool(use_site_filter),
            "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
            "top_k_sem": int(top_k_sem),
            "w_str": float(w_str),
            "w_sem": float(w_sem),
            "cost_db_rows": int(len(cost_db_run)),
        }
        pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

        need_new_pool = (st.session_state.get("candidate_pool_sig") != pool_sig) or ("candidate_pool" not in st.session_state)

        if need_new_pool:
            status_box.markdown("### ‚è≥ ÏÇ∞Ï∂úÏ§ë... (ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±)")
            with st.spinner("ÌõÑÎ≥¥ ÌíÄ ÏÉùÏÑ±(ÏµúÏ¥à/ÌòÑÏû•Î≥ÄÍ≤Ω Ïãú Ïò§Îûò Í±∏Î¶¥ Ïàò ÏûàÏùå)..."):
                pool = build_candidate_pool(
                    cost_db=cost_db_run,
                    boq=boq,
                    price_index=price_index,
                    sim_w_str=w_str,
                    sim_w_sem=w_sem,
                    top_k_sem=top_k_sem,
                    pool_per_boq=400,
                    progress=progress,
                    prog_text=prog_text,
                )
            st.session_state["candidate_pool"] = pool
            st.session_state["candidate_pool_sig"] = pool_sig
        else:
            pool = st.session_state["candidate_pool"]

        status_box.markdown("### ‚è≥ ÏÇ∞Ï∂úÏ§ë...")
        with st.spinner("Îπ†Î•∏ Ïû¨Í≥ÑÏÇ∞ Ï§ë)..."):
            result_df, log_df = fast_recompute_from_pool(
                pool=pool,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
            )
        # ‚úÖ ÏÇ∞Ï∂ú ÏôÑÎ£å ÌõÑ ÏßÑÌñâ Î¨∏Íµ¨/ÌîÑÎ°úÍ∑∏Î†àÏä§ Ï†úÍ±∞ (ÎÇ®Îäî Î¨∏Íµ¨ Î∞©ÏßÄ)
        try:
            status_box.empty()
        except Exception:
            pass
        try:
            progress.empty()
        except Exception:
            pass
        try:
            prog_text.empty()
        except Exception:
            pass

        st.session_state["boq_df"] = boq
        st.session_state["result_df_base"] = result_df.copy()
        st.session_state["log_df_base"] = log_df.copy()
        st.session_state["log_df_edited"] = log_df.copy()
        st.session_state.pop("result_df_adjusted", None)
        st.session_state["has_results"] = True
        st.session_state["last_run_sig"] = run_sig

    run_btn = st.sidebar.button("üöÄ ÏÇ∞Ï∂ú Ïã§Ìñâ")
    current_sig = make_params_signature()
    last_sig = st.session_state.get("last_run_sig", None)
    needs_rerun = (last_sig is not None and current_sig != last_sig)

    if st.session_state.get("has_results", False) and needs_rerun and not auto_recompute:
        st.sidebar.warning("‚ö†Ô∏è Ï°∞Í±¥Ïù¥ Î≥ÄÍ≤ΩÎêòÏóàÏäµÎãàÎã§. Îã§Ïãú ÏÇ∞Ï∂ú Ïã§ÌñâÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.")

    auto_run = st.session_state.get("has_results", False) and needs_rerun and auto_recompute

    if run_btn or auto_run:
        if auto_run:
            st.sidebar.info("‚ÑπÔ∏è Ï°∞Í±¥ Î≥ÄÍ≤Ω Í∞êÏßÄ ‚Üí ÏûêÎèô Ïû¨ÏÇ∞Ï∂ú Ï§ë (Î°úÍ∑∏ Ìé∏ÏßëÍ∞íÏùÄ Ï¥àÍ∏∞ÌôîÎê©ÎãàÎã§)")
        run_calculation_and_store(current_sig)

    if st.session_state.get("has_results", False):
        boq = st.session_state["boq_df"]
        result_df = st.session_state["result_df_base"]
        log_df = st.session_state["log_df_base"]

        def recompute_result_from_log(edited_log: pd.DataFrame) -> pd.DataFrame:
            base = st.session_state["result_df_base"].copy()

            out_prices = []
            for boq_id, g in edited_log.groupby("BOQ_ID"):
                g2 = g[g["Include"] == True].copy()
                if g2.empty:
                    out_prices.append((int(boq_id), None, target_currency, "Îß§Ïπ≠ ÌõÑÎ≥¥ ÏóÜÏùå(ÎòêÎäî Ï†ÑÎ∂Ä Ï†úÏô∏)", ""))
                    continue

                final_price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())

                currencies = sorted(g2["ÌÜµÌôî"].astype(str).str.upper().unique().tolist())
                reason_text = f"{len(currencies)}Í∞úÍµ≠({', '.join(currencies)}) {len(g2)}Í∞ú ÎÇ¥Ïó≠ Í∑ºÍ±∞"

                vc = g2["Í≥µÏ¢ÖÏΩîÎìú"].astype(str).value_counts()
                top_code = vc.index[0] if len(vc) else ""
                top_cnt = int(vc.iloc[0]) if len(vc) else 0
                top_work = f"{top_code} ({top_cnt}/{len(g2)})" if top_code else ""

                out_prices.append((int(boq_id), f"{final_price:,.2f}", target_currency, reason_text, top_work))

            upd = pd.DataFrame(out_prices, columns=["BOQ_ID", "Final Price", "ÏÇ∞Ï∂úÌÜµÌôî", "ÏÇ∞Ï∂úÍ∑ºÍ±∞", "Í∑ºÍ±∞Í≥µÏ¢Ö(ÏµúÎπà)"])

            base = base.drop(
                columns=[c for c in ["Final Price", "ÏÇ∞Ï∂úÌÜµÌôî", "ÏÇ∞Ï∂úÍ∑ºÍ±∞", "Í∑ºÍ±∞Í≥µÏ¢Ö(ÏµúÎπà)"] if c in base.columns],
                errors="ignore"
            )
            base = base.merge(upd, on="BOQ_ID", how="left")
            return base

        tab1, tab2, tab3 = st.tabs(["üìÑ BOQ Í≤∞Í≥º", "üßæ ÏÇ∞Ï∂ú Í∑ºÍ±∞(Ìé∏Ïßë Í∞ÄÎä•)", "üìù Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú"])

        with tab2:
            st.caption("‚úÖ Ï≤¥ÌÅ¨ Ìï¥Ï†úÌïòÎ©¥ ÌèâÍ∑†Îã®Í∞Ä ÏÇ∞Ï∂úÏóêÏÑú Ï†úÏô∏Îê©ÎãàÎã§. Ï≤¥ÌÅ¨ÌïòÎ©¥ Ìè¨Ìï®Îê©ÎãàÎã§.")

            if "log_df_edited" not in st.session_state:
                st.session_state["log_df_edited"] = log_df.copy()

            log_all = st.session_state["log_df_edited"]

            boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())

            base_for_label = st.session_state.get("result_df_base", pd.DataFrame()).copy()
            boq_text_col = "ÎÇ¥Ïó≠" if ("ÎÇ¥Ïó≠" in base_for_label.columns) else None

            if boq_text_col and ("BOQ_ID" in base_for_label.columns):
                id_to_text = (
                    base_for_label.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .set_index("BOQ_ID")[boq_text_col]
                    .astype(str)
                    .to_dict()
                )
            else:
                id_to_text = (
                    log_all.dropna(subset=["BOQ_ID"])
                    .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                    .groupby("BOQ_ID")["BOQ_ÎÇ¥Ïó≠"].first()
                    .astype(str)
                    .to_dict()
                )

            def fmt_boq_id(x: int) -> str:
                t = id_to_text.get(int(x), "")
                t = (t[:60] + "‚Ä¶") if len(t) > 60 else t
                return f"{int(x)} | {t}"

            sel_id = st.selectbox(
                "Ìé∏ÏßëÌï† BOQ ÏÑ†ÌÉù",
                options=boq_ids,
                format_func=fmt_boq_id,
                key="sel_boq_id"
            )

            log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()

            if "_include_backup" not in st.session_state:
                st.session_state["_include_backup"] = {}
            if "_include_backup_all" not in st.session_state:
                st.session_state["_include_backup_all"] = None

            cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
            with cA:
                agent_mode = st.selectbox("AI Ï∂îÏ≤ú Î™®Îìú", ["Î≥¥ÏàòÏ†Å", "Í∑†Ìòï", "Í≥µÍ≤©Ï†Å"], index=1, key="agent_mode")
            with cB:
                min_keep = st.number_input("ÏµúÏÜå Ìè¨Ìï®", min_value=1, max_value=20, value=3, step=1, key="agent_min_keep")
            with cC:
                max_keep = st.number_input("ÏµúÎåÄ Ìè¨Ìï®", min_value=3, max_value=200, value=50, step=1, key="agent_max_keep")
            with cD:
                st.caption("‚Äª Ï†ÅÏö© ÌõÑ ÌôîÎ©¥Ïù¥ ÏûêÎèô Í∞±Ïã†Îê©ÎãàÎã§.")

            b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
            with b1:
                btn_ai_one = st.button("ü§ñ AI Ï†ÅÏö©(ÌòÑÏû¨ BOQ)", key="btn_ai_one")
            with b2:
                btn_undo_one = st.button("‚Ü©Ô∏è ÎêòÎèåÎ¶¨Í∏∞(ÌòÑÏû¨ BOQ)", key="btn_undo_one")
            with b3:
                btn_ai_all = st.button("ü§ñ AI Ï†ÅÏö©(Ï†ÑÏ≤¥ BOQ)", key="btn_ai_all")
            with b4:
                btn_undo_all = st.button("‚Ü©Ô∏è ÎêòÎèåÎ¶¨Í∏∞(Ï†ÑÏ≤¥ BOQ)", key="btn_undo_all")

            if btn_undo_one:
                backup = st.session_state["_include_backup"].get(int(sel_id))
                if backup is not None and len(backup) == len(log_view_full.index):
                    st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                    st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                    st.success("ÎêòÎèåÎ¶¨Í∏∞ ÏôÑÎ£å(ÌòÑÏû¨ BOQ)")
                    st.rerun()
                else:
                    st.warning("ÎêòÎèåÎ¶¥ Î∞±ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§(ÎòêÎäî ÌõÑÎ≥¥ÌñâÏù¥ Î≥ÄÍ≤ΩÎê®).")

            if btn_ai_one:
                st.session_state["_include_backup"][int(sel_id)] = st.session_state["log_df_edited"].loc[log_view_full.index, "Include"].copy()
                updated, summary = apply_agent_to_log(
                    log_all=st.session_state["log_df_edited"].copy(),
                    boq_id=int(sel_id),
                    mode=agent_mode,
                    min_keep=int(min_keep),
                    max_keep=int(max_keep),
                )
                st.session_state["log_df_edited"] = updated
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                if summary:
                    st.success(f"AI Ï†ÅÏö© ÏôÑÎ£å(ÌòÑÏû¨ BOQ): {summary['kept']}/{summary['total']} Ìè¨Ìï®, Î™®Îìú={summary['mode']}")
                record_ai_last_applied("ÌòÑÏû¨ BOQ", agent_mode, int(min_keep), int(max_keep), summary, boq_id=int(sel_id))
                st.rerun()

            if btn_ai_all:
                st.session_state["_include_backup_all"] = st.session_state["log_df_edited"][["BOQ_ID", "Include"]].copy()
                updated, sum_df = apply_agent_to_all_boqs(
                    log_all=st.session_state["log_df_edited"].copy(),
                    mode=agent_mode,
                    min_keep=int(min_keep),
                    max_keep=int(max_keep),
                )
                st.session_state["log_df_edited"] = updated
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("AI Ï†ÅÏö© ÏôÑÎ£å(Ï†ÑÏ≤¥ BOQ)")
                if sum_df is not None and not sum_df.empty:
                    st.dataframe(sum_df, use_container_width=True)
                record_ai_last_applied("Ï†ÑÏ≤¥ BOQ", agent_mode, int(min_keep), int(max_keep), None)
                st.rerun()

            if btn_undo_all:
                backup_all = st.session_state.get("_include_backup_all")
                if backup_all is None or backup_all.empty:
                    st.warning("ÎêòÎèåÎ¶¥ Ï†ÑÏ≤¥ Î∞±ÏóÖÏù¥ ÏóÜÏäµÎãàÎã§.")
                else:
                    cur = st.session_state["log_df_edited"].copy()
                    b = backup_all.copy()
                    b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                    cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)

                    cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                    cur["Include"] = cur["Include"].fillna(False).astype(bool)

                    st.session_state["log_df_edited"] = cur
                    st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                    st.success("ÎêòÎèåÎ¶¨Í∏∞ ÏôÑÎ£å(Ï†ÑÏ≤¥ BOQ)")
                    st.rerun()

            display_cols = [
                "Include", "DefaultInclude",
                "ÎÇ¥Ïó≠", "Unit",
                "Unit Price", "ÌÜµÌôî", "Í≥ÑÏïΩÎÖÑÏõî",
                "__adj_price", "ÏÇ∞Ï∂úÌÜµÌôî",
                "__cpi_ratio", "__latest_ym",
                "__fx_ratio",
                "__fac_ratio",
                "__hyb",
                "Í≥µÏ¢ÖÏΩîÎìú", "Í≥µÏ¢ÖÎ™Ö",
                "ÌòÑÏû•ÏΩîÎìú", "ÌòÑÏû•Î™Ö",
                "ÌòëÎ†•ÏÇ¨ÏΩîÎìú", "ÌòëÎ†•ÏÇ¨Î™Ö",
            ]

            for c in display_cols:
                if c not in log_view_full.columns:
                    log_view_full[c] = None

            log_view = log_view_full[display_cols].copy()

            edited_view = st.data_editor(
                log_view,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Include": st.column_config.CheckboxColumn("Ìè¨Ìï®", help="ÌèâÍ∑†Îã®Í∞Ä ÏÇ∞Ï∂ú Ìè¨Ìï®/Ï†úÏô∏"),
                    "DefaultInclude": st.column_config.CheckboxColumn("Í∏∞Î≥∏Ìè¨Ìï®", help="Ï¥àÍ∏∞ ÏûêÎèô Ìè¨Ìï® Ïó¨Î∂Ä(Ïª∑ Î°úÏßÅ)"),
                    "ÎÇ¥Ïó≠": st.column_config.TextColumn("ÎÇ¥Ïó≠", width="large"),
                    "Unit": st.column_config.TextColumn("Îã®ÏúÑ(Unit)"),
                    "Unit Price": st.column_config.NumberColumn("ÏõêÎã®Í∞Ä", format="%.4f"),
                    "ÌÜµÌôî": st.column_config.TextColumn("ÏõêÌÜµÌôî"),
                    "Í≥ÑÏïΩÎÖÑÏõî": st.column_config.TextColumn("Í≥ÑÏïΩÎÖÑÏõî"),
                    "__adj_price": st.column_config.NumberColumn("ÏÇ∞Ï∂úÎã®Í∞Ä(ÏÇ∞Ï∂úÌÜµÌôî Í∏∞Ï§Ä)", format="%.4f"),
                    "ÏÇ∞Ï∂úÌÜµÌôî": st.column_config.TextColumn("ÏÇ∞Ï∂úÌÜµÌôî"),
                    "__cpi_ratio": st.column_config.NumberColumn("Î¨ºÍ∞ÄÎ≥¥Ï†ïÍ≥ÑÏàò(CPI)", format="%.6f"),
                    "__latest_ym": st.column_config.TextColumn("Î¨ºÍ∞ÄÏßÄÏàò ÏµúÏã†Ïõî"),
                    "__fx_ratio": st.column_config.NumberColumn("ÌôòÏú®Î≥¥Ï†ïÍ≥ÑÏàò", format="%.6f"),
                    "__fac_ratio": st.column_config.NumberColumn("Íµ≠Í∞ÄÎ≥¥Ï†ïÍ≥ÑÏàò(Factor)", format="%.6f"),
                    "__hyb": st.column_config.NumberColumn("Ïú†ÏÇ¨ÎèÑÏ†êÏàò", format="%.2f"),
                    "Í≥µÏ¢ÖÏΩîÎìú": st.column_config.TextColumn("Í≥µÏ¢ÖÏΩîÎìú"),
                    "Í≥µÏ¢ÖÎ™Ö": st.column_config.TextColumn("Í≥µÏ¢ÖÎ™Ö"),
                    "ÌòÑÏû•ÏΩîÎìú": st.column_config.TextColumn("ÌòÑÏû•ÏΩîÎìú"),
                    "ÌòÑÏû•Î™Ö": st.column_config.TextColumn("ÌòÑÏû•Î™Ö"),
                    "ÌòëÎ†•ÏÇ¨ÏΩîÎìú": st.column_config.TextColumn("ÌòëÎ†•ÏÇ¨ÏΩîÎìú"),
                    "ÌòëÎ†•ÏÇ¨Î™Ö": st.column_config.TextColumn("ÌòëÎ†•ÏÇ¨Î™Ö"),
                },
                disabled=[c for c in log_view.columns if c not in ["Include"]],
                key="log_editor",
            )

            st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])

        with tab1:
            show_df = st.session_state.get("result_df_adjusted", result_df).copy()

            if "ÌÜµÌôî" in show_df.columns:
                show_df = show_df.drop(columns=["ÌÜµÌôî"])

            if "Final Price" in show_df.columns:
                if "ÏÇ∞Ï∂úÌÜµÌôî" not in show_df.columns:
                    show_df["ÏÇ∞Ï∂úÌÜµÌôî"] = target_currency

                cols = show_df.columns.tolist()
                cols.remove("ÏÇ∞Ï∂úÌÜµÌôî")
                fp_idx = cols.index("Final Price")
                cols.insert(fp_idx + 1, "ÏÇ∞Ï∂úÌÜµÌôî")
                show_df = show_df[cols]

            st.dataframe(show_df, use_container_width=True)

        with tab3:
            st.markdown("## üìù Í∑ºÍ±∞ Î≥¥Í≥†ÏÑú")

            base_result = st.session_state.get("result_df_adjusted", st.session_state.get("result_df_base", pd.DataFrame()))
            log_for_report = st.session_state.get("log_df_edited", st.session_state.get("log_df_base", pd.DataFrame()))

            st.markdown("### 1) Í≥µÏ¢Ö ÌäπÏÑ±")
            sel_features = st.session_state.get("selected_feature_ids", [])
            ft = build_feature_context_table(feature_master, sel_features)
            if ft.empty:
                st.info("ÏÑ†ÌÉùÎêú ÌäπÏÑ±IDÍ∞Ä ÏóÜÏäµÎãàÎã§.")
            else:
                st.dataframe(ft, use_container_width=True)

            st.markdown("### 2) Ïã§Ï†Å ÌòÑÏû• Î¶¨Ïä§Ìä∏")
            try:
                _sel_sites = selected_site_codes if (selected_site_codes is not None) else []
            except Exception:
                _sel_sites = []
            st_sites = build_site_context_table(cost_db, _sel_sites)
            if st_sites.empty:
                st.info("ÏÑ†ÌÉùÎêú ÌòÑÏû•Ïù¥ ÏóÜÏäµÎãàÎã§(ÎòêÎäî ÌòÑÏû• ÌïÑÌÑ∞ ÎØ∏ÏÇ¨Ïö©).")
            else:
                st.dataframe(st_sites, use_container_width=True)

            st.markdown("### 3) Îã®Í∞Ä Ï∂îÏ∂ú Í∑ºÍ±∞(Ï°∞Í±¥)")
            c1, c2, c3 = st.columns(3)
            with c1:
                st.metric("Îß§Ïπ≠ Ïú†ÏÇ¨ÎèÑ, (%)", f"{float(sim_threshold):.0f}")
            with c2:
                st.metric("ÏÉÅ/ÌïòÏúÑ Ïª∑ ÎπÑÏú®(%)", f"{float(cut_ratio) * 100 :.0f}")
            with c3:
                st.metric("ÏÇ∞Ï∂úÌÜµÌôî", str(target_currency))

            st.markdown("### 4) AI Ï†ÅÏö© Ïãú ÏµúÏ¢Ö Í∏∞Ï§Ä")
            st.write(get_ai_effective_rule_text())

            st.markdown("### 5) Ïã§Ï†Å Îã®Í∞Ä BOQ(Í≤∞Í≥º)")
            if base_result is None or base_result.empty:
                st.warning("Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. Î®ºÏ†Ä ÏÇ∞Ï∂ú Ïã§Ìñâ ÌõÑ Îã§Ïãú ÏãúÎèÑÌïòÏÑ∏Ïöî.")
            else:
                st.dataframe(base_result, use_container_width=True)

            # ‚úÖ (TAB3) Î≥¥Í≥†ÏÑú ÏûêÎèô ÏÉùÏÑ±/Í∞±Ïã† (Î≥ÄÍ≤Ω Í∞êÏßÄ)
            def _report_sig(log_df: pd.DataFrame, result_df: pd.DataFrame) -> str:
                # Include/BOQ_ID/__adj_priceÎßå Î∞îÎÄåÏñ¥ÎèÑ ÏöîÏïΩ/ÏÉÅÏÑ∏Í∞Ä Î∞îÎÄåÎØÄÎ°ú Ïù¥ Ï†ïÎèÑÎßå ÏÑúÎ™ÖÏúºÎ°ú ÏÇ¨Ïö©
                cols = [c for c in ["BOQ_ID", "Include", "__adj_price", "__hyb"] if c in log_df.columns]
                base = log_df[cols].copy() if cols else log_df.copy()
                s1 = file_fingerprint(base, cols) if cols else hashlib.md5(str(base.shape).encode()).hexdigest()
            
                s2 = ""
                if result_df is not None and not result_df.empty:
                    cols2 = [c for c in ["BOQ_ID", "Final Price"] if c in result_df.columns]
                    if cols2:
                        s2 = file_fingerprint(result_df[cols2].copy(), cols2)
                    else:
                        s2 = hashlib.md5(str(result_df.shape).encode()).hexdigest()
            
                return hashlib.md5((s1 + "|" + s2).encode("utf-8")).hexdigest()
            
            cur_rep_sig = _report_sig(log_for_report, base_result)
            prev_rep_sig = st.session_state.get("report_sig", None)
            
            if (prev_rep_sig != cur_rep_sig) or ("report_summary_df" not in st.session_state) or ("report_detail_df" not in st.session_state):
                summary_df, detail_df = build_report_tables(log_for_report, base_result)
                st.session_state["report_summary_df"] = summary_df
                st.session_state["report_detail_df"] = detail_df
                st.session_state["report_sig"] = cur_rep_sig
            
            summary_df = st.session_state.get("report_summary_df", pd.DataFrame())
            detail_df = st.session_state.get("report_detail_df", pd.DataFrame())

            st.markdown("### 6) Í∞Å ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Í∑ºÍ±∞(ÌèâÍ∑†)")
            if summary_df is None or summary_df.empty:
                st.info("Î≥¥Í≥†ÏÑúÎ•º Î≥¥Î†§Î©¥ 'Î≥¥Í≥†ÏÑú ÏÉùÏÑ±/Í∞±Ïã†'ÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.")
            else:
                st.dataframe(summary_df, use_container_width=True)

            st.markdown("### 7) Í∞Å ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Í∑ºÍ±∞(ÏÑ†ÌÉùÎêú ÎÇ¥Ïó≠)")
            if detail_df is not None and not detail_df.empty:
                st.dataframe(detail_df, use_container_width=True)
            else:
                st.info("Include=True ÏÉÅÏÑ∏ ÌõÑÎ≥¥Í∞Ä ÏóÜÏäµÎãàÎã§(Ï†ÑÎ∂Ä Ï†úÏô∏ÎêòÏóàÍ±∞ÎÇò ÌõÑÎ≥¥Í∞Ä ÏóÜÏùå).")

            st.markdown("### 8) ÎÇ¥Ïó≠Î≥Ñ Îã®Í∞Ä Î∂ÑÌè¨")
            render_boq_scatter(log_for_report, base_result)

            out_result = st.session_state.get("result_df_adjusted", result_df).copy()
            out_log = st.session_state.get("log_df_edited", log_df).copy()

        

# ============================================================
# ‚úÖ ÏÉÅÎã® ÌÉ≠(Ìï¥Ïô∏/Íµ≠ÎÇ¥) + ÏÇ¨Ïù¥ÎìúÎ∞î Ï§ëÎ≥µ Î†åÎçî Î∞©ÏßÄ Î°úÏßÅ
# - StreamlitÏùÄ ÌÉ≠Ïù¥ ÏûàÏñ¥ÎèÑ ÏΩîÎìúÍ∞Ä Îëò Îã§ Ïã§ÌñâÎêòÎäî Í≤ΩÏö∞Í∞Ä ÎßéÏïÑÏÑú,
#   active_db ÏÉÅÌÉúÎ°ú "ÌïúÏ™ΩÎßå" Ïã§Ï†ú Î†åÎçîÌïòÎèÑÎ°ù Íµ¨ÏÑ±
# ============================================================
tab_over, tab_dom = st.tabs(["üåç Ìï¥Ïô∏ Ïã§Ï†ÅÎã®Í∞Ä DB", "üá∞üá∑ Ïã§Ï†ÅÎã®Í∞Ä DB"])

with tab_over:
    if st.session_state["active_db"] != "overseas":
        if st.button("Ïù¥ ÌÉ≠ÏúºÎ°ú Ï†ÑÌôò", key="switch_to_overseas"):
            st.session_state["active_db"] = "overseas"
            st.rerun()
        st.info("ÌòÑÏû¨ ÌôúÏÑ± ÌôîÎ©¥ÏùÄ Íµ≠ÎÇ¥ ÌÉ≠ÏûÖÎãàÎã§. Ï†ÑÌôò Î≤ÑÌäºÏùÑ ÎàåÎü¨ ÌôúÏÑ±ÌôîÌïòÏÑ∏Ïöî.")
    else:
        render_overseas()

with tab_dom:
    if st.session_state["active_db"] != "domestic":
        if st.button("Ïù¥ ÌÉ≠ÏúºÎ°ú Ï†ÑÌôò", key="switch_to_domestic"):
            st.session_state["active_db"] = "domestic"
            st.rerun()
        st.info("ÌòÑÏû¨ ÌôúÏÑ± ÌôîÎ©¥ÏùÄ Ìï¥Ïô∏ ÌÉ≠ÏûÖÎãàÎã§. Ï†ÑÌôò Î≤ÑÌäºÏùÑ ÎàåÎü¨ ÌôúÏÑ±ÌôîÌïòÏÑ∏Ïöî.")
    else:
        render_domestic()






























