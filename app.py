import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

st.markdown(f"""
<style>
  .main {{ background-color: {BG_LIGHT}; }}
  .gs-header {{
     color: white;
     background: linear-gradient(90deg, {CI_BLUE} 0%, {CI_TEAL} 100%);
     padding: 14px 16px;
     border-radius: 10px;
     font-size: 26px; font-weight: 700;
  }}
  div[data-baseweb="select"] > div {{
     background-color: white !important;
     border: 1px solid {CI_BLUE} !important;
     border-radius: 6px !important;
  }}
  div[data-baseweb="select"] span {{
     background-color: {CI_TEAL} !important;
     color: white !important;
     border-radius: 4px !important;
     padding: 2px 6px !important;
  }}
  .stDownloadButton button {{
     background-color:{CI_BLUE}; color:white; border-radius:8px; padding:8px 14px; border:0;
  }}
  .stDownloadButton button:hover {{ background-color:{CI_TEAL}; color:white; }}
  .gs-card {{
    background-color: white;
    border: 1px solid #e8eef3;
    border-radius: 10px;
    padding: 12px 14px;
    box-shadow: 0 1px 2px rgba(0,0,0,0.04);
  }}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='gs-header'>ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB</div>", unsafe_allow_html=True)
st.write("")


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None

def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()

def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode()); hasher.update(tail.encode())
    return hasher.hexdigest()

def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s


# =========================
# ë³´ì • ë¡œì§
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now  = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None

def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        usd_to   = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0

def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(from_currency).upper(), "ì§€ìˆ˜"].values
        f_to   = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(to_currency).upper(), "ì§€ìˆ˜"].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"

def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))

def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index

def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0

def match_items_faiss(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
    w_str: float,
    w_sem: float,
    top_k_sem: int,
    progress=None,
    prog_text=None,
):
    work = cost_db.copy()
    work["__ë‚´ì—­_norm"] = work["ë‚´ì—­"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_ê³„ì•½ì›”"] = robust_parse_contract_month(work["ê³„ì•½ë…„ì›”"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_ê³„ì•½ì›”"].notna())].copy()

    price_index = price_index.copy()
    price_index["ë…„ì›”"] = price_index["ë…„ì›”"].apply(to_year_month_string)

    fp = file_fingerprint(work, ["__ë‚´ì—­_norm","__Unit_norm","í†µí™”","Unit Price","_ê³„ì•½ì›”"])
    embs = compute_or_load_embeddings(work["__ë‚´ì—­_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    results, logs = [], []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"ì‚°ì¶œ ì§„í–‰ë¥ : {i}/{total} í•­ëª© ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i/total)

        boq_item = str(boq_row.get("ë‚´ì—­", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]; sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)
        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        hyb = hybrid_scores(boq_text_norm, unit_df["__ë‚´ì—­_norm"], unit_df["__sem"].to_numpy(), w_str, w_sem)
        unit_df["__hyb"] = hyb

        unit_df = unit_df[unit_df["__hyb"] >= sim_threshold].copy()
        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        adj_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("í†µí™”","")).upper().strip()
            unit_price = float(r.get("Unit Price", 0.0))
            contract_ym = to_year_month_string(r.get("_ê³„ì•½ì›”"))

            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index, c_currency, contract_ym)
            fx_ratio  = get_exchange_rate(exchange, c_currency, target_currency)
            fac_ratio = get_factor_ratio(factor, c_currency, target_currency)

            adj_price = unit_price * cpi_ratio * fx_ratio * fac_ratio

            adj_list.append({
                **r.to_dict(),
                "__adj_price": adj_price,
                "__base_cpi": base_cpi,
                "__latest_cpi": latest_cpi,
                "__latest_ym": latest_ym,
                "__cpi_ratio": cpi_ratio,
                "__fx_ratio": fx_ratio,
                "__fac_ratio": fac_ratio,
                "__hyb": r["__hyb"],
            })
        unit_df = pd.DataFrame(adj_list)

        unit_df = unit_df.sort_values("__adj_price")
        n = len(unit_df)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0
        kept = unit_df.iloc[cut:n-cut] if cut > 0 else unit_df.copy()

        currencies = sorted(kept["í†µí™”"].astype(str).str.upper().unique().tolist())
        reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(kept)}ê°œ ë‚´ì—­ ê·¼ê±°"

        final_price = float(kept["__adj_price"].mean()) if not kept.empty else None

        res_row = dict(boq_row)
        res_row["Final Price"] = f"{final_price:,.2f}" if final_price is not None else None
        res_row["ì‚°ì¶œê·¼ê±°"] = reason_text
        results.append(res_row)

    return pd.DataFrame(results), pd.DataFrame(logs)


# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")

cost_db     = load_excel_from_repo("cost_db.xlsx")
price_index = load_excel_from_repo("price_index.xlsx")
exchange    = load_excel_from_repo("exchange.xlsx")
factor      = load_excel_from_repo("Factor.xlsx")
project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
feature_master = load_excel_from_repo("feature_master_FID.xlsx")


# =========================
# Session init
# =========================
if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []
if "auto_sites" not in st.session_state:
    st.session_state["auto_sites"] = []


# =========================
# Sidebar: ì„¤ì •
# =========================
st.sidebar.header("âš™ï¸ ì„¤ì •")
st.sidebar.caption("â‘ ~â‘¥ ìˆœì„œëŒ€ë¡œ ì„¤ì •í•˜ì„¸ìš”.")

use_site_filter = st.sidebar.checkbox(
    "í˜„ì¥ í•„í„° ì‚¬ìš©(ì¶”ì²œ)",
    value=True
)

DEFAULT_W_STR = 0.3
DEFAULT_TOP_K_SEM = 200
w_str = DEFAULT_W_STR
w_sem = 1.0 - w_str
top_k_sem = DEFAULT_TOP_K_SEM


# =========================
# (1) BOQ ì—…ë¡œë“œ (ë¨¼ì €!)
# =========================
with st.container():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    boq_file = st.file_uploader(
        "ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ",
        type=["xlsx"],
        help="BOQëŠ” ìµœì†Œí•œ 'ë‚´ì—­', 'Unit' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤."
    )
    st.markdown("</div>", unsafe_allow_html=True)


# =========================
# (2) ë©”ì¸: BOQ ì—…ë¡œë“œ ì•„ë˜ íŠ¹ì„± ì„ íƒ UI
# =========================
auto_sites = []

if use_site_filter:
    if boq_file is not None:
        st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
        st.markdown("### ğŸ·ï¸ í”„ë¡œì íŠ¸ íŠ¹ì„± ì„ íƒ (176ê°œ ì „ì²´)")

        fm = feature_master.copy()
        cols6 = ["ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]
        for c in ["íŠ¹ì„±ID"] + cols6:
            fm[c] = fm[c].astype(str).fillna("").str.strip()

        site_cnt = project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"].nunique().astype(int).to_dict()
        fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)

        fm["ë¼ë²¨"] = fm.apply(
            lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | '
                      f'{r["Cost Driver Type"]}/{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                      f'í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
            axis=1
        )

        keyword = st.text_input("íŠ¹ì„± ëª©ë¡ í•„í„°(í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ: DCM, Jet, ì§€ë°˜ê°œëŸ‰, ë„ì‹¬ ...")
        fm_view = fm
        if keyword.strip():
            kw = keyword.strip().lower()
            fm_view = fm[fm["ë¼ë²¨"].str.lower().str.contains(kw, na=False)].copy()

        options = fm_view["ë¼ë²¨"].tolist()
        label_to_id = dict(zip(fm_view["ë¼ë²¨"], fm_view["íŠ¹ì„±ID"]))

        # ê¸°ì¡´ ì„ íƒ ë³µì›(í•„í„°ë§ ì‹œì—ë„ ìœ ì§€)
        master_label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
        master_id_to_label = {}
        for lab, fid in master_label_to_id.items():
            master_id_to_label.setdefault(fid, lab)

        current_selected_ids = st.session_state["selected_feature_ids"]
        current_labels = [master_id_to_label[fid] for fid in current_selected_ids if fid in master_id_to_label]

        new_selected_labels = st.multiselect(
            "íŠ¹ì„± ì„ íƒ(ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
            options=options,
            default=[lab for lab in current_labels if lab in options]
        )

        new_ids = [label_to_id[lab] for lab in new_selected_labels]
        kept_ids = [fid for fid in current_selected_ids if (fid in master_id_to_label and master_id_to_label[fid] not in options)]
        merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))

        st.session_state["selected_feature_ids"] = merged_ids

        st.markdown("#### âœ… ì„ íƒëœ íŠ¹ì„±ID")
        if merged_ids:
            st.write(merged_ids)
            del_ids = st.multiselect("ì œê±°í•  íŠ¹ì„±ID ì„ íƒ", options=merged_ids, default=[])
            c1, c2 = st.columns(2)
            with c1:
                if st.button("ğŸ—‘ï¸ ì„ íƒ ì œê±°"):
                    st.session_state["selected_feature_ids"] = [x for x in merged_ids if x not in del_ids]
            with c2:
                if st.button("ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”"):
                    st.session_state["selected_feature_ids"] = []
        else:
            st.info("ì„ íƒëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
    st.info("BOQ ì—…ë¡œë“œ í›„ í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # =========================
        # BOQ ì—…ë¡œë“œ ì•„ë˜: auto_sites ê³„ì‚°
        # =========================
        if st.session_state["selected_feature_ids"]:
            auto_sites = (
                project_feature_long[
                    project_feature_long["íŠ¹ì„±ID"].astype(str).isin(
                        [str(x) for x in st.session_state["selected_feature_ids"]]
                    )
                ]["í˜„ì¥ì½”ë“œ"].astype(str).unique().tolist()
            )
        else:
            auto_sites = []
        
        st.session_state["auto_sites"] = auto_sites
        
        # =========================
        # ì‚¬ì´ë“œë°” ìë™í›„ë³´ ì¦‰ì‹œ ì„ íƒ ë°˜ì˜(ìë™ì„ íƒ)
        # =========================
        site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy().dropna(subset=["í˜„ì¥ì½”ë“œ"])
        site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
        site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
        site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
        site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"])
        site_df["label"] = site_df["í˜„ì¥ì½”ë“œ"] + " | " + site_df["í˜„ì¥ëª…"]
        
        code_to_label = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["label"]))
        auto_codes = [norm_site_code(x) for x in auto_sites]
        auto_labels = [code_to_label[c] for c in auto_codes if c in code_to_label]
        
        # âœ… ì‚¬ì´ë“œë°” multiselectì˜ defaultë¥¼ â€œìë™í›„ë³´ë¡œ ê°•ì œâ€
        st.session_state["selected_auto_labels"] = auto_labels
        
        st.success(f"ìë™ í›„ë³´ í˜„ì¥: {len(auto_sites)}ê°œ")
        if len(auto_sites) <= 30:
            st.write(auto_sites)

       
# =========================
# (3) ì‚¬ì´ë“œë°”: ì‹¤ì  í˜„ì¥ ì„ íƒ (auto_sitesê°€ sessionì— ì €ì¥ëœ ì´í›„ì—!)
# =========================
selected_site_codes = None

if use_site_filter:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ")

    # âœ… (ì„ íƒ) ë””ë²„ê·¸ ì´ˆê¸°í™” ë²„íŠ¼: ëˆ„ë¥´ë©´ ìƒíƒœë§Œ ì§€ìš°ê³  rerun
    if st.sidebar.button("ğŸ§¹ ê°•ì œ ì´ˆê¸°í™”(ë””ë²„ê·¸)"):
        for k in ["selected_auto_labels", "selected_extra_labels", "auto_sites", "selected_feature_ids"]:
            if k in st.session_state:
                del st.session_state[k]
        st.rerun()

    # âœ… í•­ìƒ auto_sitesë¥¼ ì½ê³  UIë¥¼ ê·¸ë ¤ì•¼ í•¨ (ë²„íŠ¼ if ë°–!)
    auto_sites = st.session_state.get("auto_sites", [])

    # 1) cost_dbì—ì„œ ì „ì²´ í˜„ì¥ ëª©ë¡ ë§Œë“¤ê¸°
    site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    site_df = site_df.dropna(subset=["í˜„ì¥ì½”ë“œ"])

    site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"

    site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"])
    site_df["label"] = site_df["í˜„ì¥ì½”ë“œ"] + " | " + site_df["í˜„ì¥ëª…"]

    all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()
    code_to_label = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["label"]))

    # 2) auto_sites -> auto_codes (ì¡´ì¬í•˜ëŠ” ì½”ë“œë§Œ)
    auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
    auto_codes = [c for c in auto_codes_raw if c in code_to_label]

    auto_labels = [code_to_label[c] for c in auto_codes]
    other_labels = [code_to_label[c] for c in all_codes if c not in set(auto_codes)]

    st.sidebar.caption(f"ìë™ í›„ë³´ {len(auto_labels)}ê°œ / ê¸°íƒ€ {len(other_labels)}ê°œ")

    # defaultëŠ” session_stateì— ìˆìœ¼ë©´ ê·¸ê±¸ ì“°ê³ , ì—†ìœ¼ë©´ auto_labels
    default_auto = st.session_state.get("selected_auto_labels", auto_labels)
    
    selected_auto_labels = st.sidebar.multiselect(
        "ìë™ í›„ë³´(ì œì™¸ ê°€ëŠ¥)",
        options=auto_labels,
        default=[x for x in default_auto if x in auto_labels],  # ì˜µì…˜ì— ì—†ëŠ” ê±´ ì œê±°
        key="selected_auto_labels"
    )
    selected_auto_codes = [x.split(" | ")[0] for x in selected_auto_labels]

    selected_extra_labels = st.sidebar.multiselect(
        "ê¸°íƒ€ í˜„ì¥(ì¶”ê°€ ê°€ëŠ¥)",
        options=other_labels,
        default=[],
        key="selected_extra_labels"
    )
    selected_extra_codes = [x.split(" | ")[0] for x in selected_extra_labels]

    selected_site_codes = sorted(list(set(selected_auto_codes + selected_extra_codes)))
    st.sidebar.caption(f"ìµœì¢… ì„ íƒ í˜„ì¥: {len(selected_site_codes)}ê°œ")


# =========================
# ê¸°íƒ€ ìŠ¬ë¼ì´ë”/í†µí™” ì„ íƒ
# =========================
sim_threshold = st.sidebar.slider("â‘¡ Threshold (ì»· ê¸°ì¤€, %)", 0, 100, 60, 5)
cut_ratio = st.sidebar.slider("â‘¢ ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)", 0, 30, 20, 5) / 100.0

target_options = sorted(factor["êµ­ê°€"].astype(str).str.upper().unique().tolist())
default_idx = target_options.index("KRW") if "KRW" in target_options else 0
target_currency = st.sidebar.selectbox("â‘£ ì‚°ì¶œí†µí™”", options=target_options, index=default_idx)

missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper()==target_currency].empty
missing_factor   = factor[factor["êµ­ê°€"].astype(str).str.upper()==target_currency].empty
if missing_exchange:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
if missing_factor:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")


# =========================
# Run ë²„íŠ¼
# =========================
run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰")

if run_btn:
    if boq_file is None:
        st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif missing_exchange or missing_factor:
        st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        boq = pd.read_excel(boq_file, engine="openpyxl")

        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(f"ì‹¤í–‰ìš© cost_db í–‰ìˆ˜: {len(cost_db_run):,} / ì „ì²´ {len(cost_db):,}")

        progress = st.progress(0.0)
        prog_text = st.empty()

        with st.spinner("ì„ë² ë”©/ì¸ë±ìŠ¤ ì¤€ë¹„ ë° ê³„ì‚° ì¤‘..."):
            result_df, log_df = match_items_faiss(
                cost_db=cost_db_run,
                boq=boq,
                price_index=price_index,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
                w_str=w_str,
                w_sem=w_sem,
                top_k_sem=top_k_sem,
                progress=progress,
                prog_text=prog_text,
            )

        progress.progress(1.0)
        prog_text.text("ì‚°ì¶œ ì§„í–‰ë¥ : ì™„ë£Œ")

        st.success("âœ… ì™„ë£Œ! ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")

        tab1, tab2 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸"])

        with tab1:
            if "í†µí™”" in result_df.columns:
                result_df = result_df.drop(columns=["í†µí™”"])
            st.dataframe(result_df, use_container_width=True)

        with tab2:
            st.dataframe(log_df, use_container_width=True)

        bio = io.BytesIO()
        with pd.ExcelWriter(bio, engine="openpyxl") as writer:
            result_df.to_excel(writer, index=False, sheet_name="boq_with_price")
            log_df.to_excel(writer, index=False, sheet_name="calculation_log")
        bio.seek(0)
        st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")











