import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

st.markdown(f"""
<style>
  .main {{ background-color: {BG_LIGHT}; }}

  /* ====== ì‚¬ì´ë“œë°”ì—ì„œë§Œ ê°•ì œ ì ìš©(ìš°ì„ ìˆœìœ„ â†‘) ====== */
section[data-testid="stSidebar"] div[data-baseweb="select"] > div{
  background-color: #ffffff !important;
  border: 1px solid #005EB8 !important;
  border-radius: 6px !important;
}

/* âœ… ì‚°ì¶œí†µí™”(Selectbox) ì„ íƒ í…ìŠ¤íŠ¸ë¥¼ ê²€ì •ìœ¼ë¡œ ê°•ì œ */
section[data-testid="stSidebar"] div[data-baseweb="select"] input{
  color:#000000 !important;
  -webkit-text-fill-color:#000000 !important;
}

/* ====== ë©€í‹°ì…€ë ‰íŠ¸ ì¹©(tag) : BaseWeb DOMì´ ì¼€ì´ìŠ¤ë³„ë¡œ div/span ë‘˜ ë‹¤ ë‚˜ì˜¬ ìˆ˜ ìˆì–´ ë‘˜ ë‹¤ ì¡ìŒ ====== */
section[data-testid="stSidebar"] div[data-baseweb="tag"],
section[data-testid="stSidebar"] span[data-baseweb="tag"]{
  background-color:#4DA3FF !important;   /* ë°ì€ íŒŒë€ìƒ‰ */
  border:1px solid #2F80ED !important;
  border-radius:8px !important;

  min-height:30px !important;
  height:30px !important;
  display:inline-flex !important;
  align-items:center !important;

  padding:0 10px !important;
  box-sizing:border-box !important;

  /* âœ… í­ì„ ë„“í˜€ì„œ 15ì ì˜ë¦¼ ì™„í™” */
  max-width: 280px !important;
}

/* âœ… tag ë‚´ë¶€ í…ìŠ¤íŠ¸: ellipsis ìœ ì§€ + í­ í™•ëŒ€ */
section[data-testid="stSidebar"] div[data-baseweb="tag"] span,
section[data-testid="stSidebar"] span[data-baseweb="tag"] span{
  color:#ffffff !important;
  white-space:nowrap !important;
  overflow:hidden !important;
  text-overflow:ellipsis !important;
  max-width: 230px !important;  /* 25ì ì •ë„ ë…¸ì¶œ ëª©í‘œ */
  display:inline-block !important;
}

/* âœ… tagì˜ X ì•„ì´ì½˜/ë²„íŠ¼ ìƒ‰ */
section[data-testid="stSidebar"] div[data-baseweb="tag"] svg,
section[data-testid="stSidebar"] span[data-baseweb="tag"] svg,
section[data-testid="stSidebar"] div[data-baseweb="tag"] path,
section[data-testid="stSidebar"] span[data-baseweb="tag"] path{
  fill:#ffffff !important;
}

/* hover */
section[data-testid="stSidebar"] div[data-baseweb="tag"]:hover,
section[data-testid="stSidebar"] span[data-baseweb="tag"]:hover{
  background-color:#2F80ED !important;
  border:1px solid #1C6DD0 !important;
}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='gs-header'>ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB</div>", unsafe_allow_html=True)
st.write("")


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None

def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()

def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode()); hasher.update(tail.encode())
    return hasher.hexdigest()

def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s


# =========================
# ë³´ì • ë¡œì§
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now  = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None

def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        usd_to   = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0

def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(from_currency).upper(), "ì§€ìˆ˜"].values
        f_to   = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(to_currency).upper(), "ì§€ìˆ˜"].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"

def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))

def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index

def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0

def build_candidate_pool(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    sim_w_str: float,
    sim_w_sem: float,
    top_k_sem: int,
    pool_per_boq: int = 400,
    progress=None,
    prog_text=None,
) -> pd.DataFrame:
    """
    âœ… 1ë‹¨ê³„(ë¬´ê±°ì›€): BOQë³„ í›„ë³´ í’€ ìƒì„±
    - FAISS ê²€ìƒ‰ + ë¬¸ìì—´ ì ìˆ˜ + __hyb ê³„ì‚°ê¹Œì§€ ì—¬ê¸°ì„œë§Œ ìˆ˜í–‰
    - ì‚°ì¶œí†µí™”(FX/Factor)ëŠ” ì—¬ê¸°ì„œ ê³„ì‚°í•˜ì§€ ì•ŠìŒ(ë¹ ë¥¸ ì¬ê³„ì‚°ì—ì„œ ì²˜ë¦¬)
    - CPIëŠ” í†µí™”/ê³„ì•½ì›”ì—ë§Œ ì˜ì¡´í•˜ë¯€ë¡œ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ê³„ì‚°í•´ ë‘ 
    """
    work = cost_db.copy()
    work["__ë‚´ì—­_norm"] = work["ë‚´ì—­"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_ê³„ì•½ì›”"] = robust_parse_contract_month(work["ê³„ì•½ë…„ì›”"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_ê³„ì•½ì›”"].notna())].copy()

    price_index2 = price_index.copy()
    price_index2["ë…„ì›”"] = price_index2["ë…„ì›”"].apply(to_year_month_string)

    fp = file_fingerprint(work, ["__ë‚´ì—­_norm", "__Unit_norm", "í†µí™”", "Unit Price", "_ê³„ì•½ì›”"])
    embs = compute_or_load_embeddings(work["__ë‚´ì—­_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    pool_rows = []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"í›„ë³´ í’€ ìƒì„±: {i}/{total} ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i / total)

        boq_item = str(boq_row.get("ë‚´ì—­", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]; sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        # Unit ì¼ì¹˜ í›„ë³´ë§Œ
        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)
        if unit_df.empty:
            continue

        # __hyb ê³„ì‚°(ë¬¸ìì—´+ì˜ë¯¸ ìœ ì‚¬ë„)
        hyb = hybrid_scores(boq_text_norm, unit_df["__ë‚´ì—­_norm"], unit_df["__sem"].to_numpy(), sim_w_str, sim_w_sem)
        unit_df["__hyb"] = hyb

        # ë„ˆë¬´ í° í’€ ë°©ì§€: hyb ìƒìœ„ Nê°œë§Œ ë³´ê´€
        unit_df = unit_df.sort_values("__hyb", ascending=False).head(pool_per_boq).copy()

        # CPIëŠ” í†µí™”+ê³„ì•½ì›” ê¸°ì¤€ìœ¼ë¡œ ë¯¸ë¦¬ ê³„ì‚° (ì‚°ì¶œí†µí™” ë°”ë€Œì–´ë„ ì¬ì‚¬ìš© ê°€ëŠ¥)
        # contract_ymì„ ë¬¸ìì—´ë¡œ
        unit_df["__contract_ym"] = unit_df["_ê³„ì•½ì›”"].apply(to_year_month_string)

        cpi_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("í†µí™”", "")).upper().strip()
            contract_ym = r.get("__contract_ym", None)
            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index2, c_currency, contract_ym)
            cpi_list.append((cpi_ratio, latest_ym))
        unit_df["__cpi_ratio"] = [x[0] for x in cpi_list]
        unit_df["__latest_ym"] = [x[1] for x in cpi_list]

        # BOQ ë©”íƒ€ ë¶™ì´ê¸°
        boq_id = int(i)
        unit_df["BOQ_ID"] = boq_id
        unit_df["BOQ_ë‚´ì—­"] = boq_item
        unit_df["BOQ_Unit"] = boq_unit

        pool_rows.append(unit_df)

    if not pool_rows:
        return pd.DataFrame()

    pool = pd.concat(pool_rows, ignore_index=True)

    # í’€ì—ì„œ ì•ìœ¼ë¡œ í•„ìš”í•œ ìµœì†Œ ì»¬ëŸ¼ë§Œ ìœ ì§€(ê°€ë²¼ìš´ ì¬ê³„ì‚°ìš©)
    keep_cols = [
        "BOQ_ID", "BOQ_ë‚´ì—­", "BOQ_Unit",
        "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
        "ë‚´ì—­", "Unit",
        "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
        "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
        "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        "__hyb",
        "__cpi_ratio",
        "__latest_ym",
    ]
    for c in keep_cols:
        if c not in pool.columns:
            pool[c] = None
    return pool[keep_cols].copy()


def fast_recompute_from_pool(
    pool: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    âœ… 2ë‹¨ê³„(ê°€ë²¼ì›€): í›„ë³´ í’€ì—ì„œ ë¹ ë¥¸ ì¬ê³„ì‚°
    - Threshold í•„í„°
    - ì‚°ì¶œí†µí™” ë³€ê²½: __fx_ratio, __fac_ratioë§Œ ë‹¤ì‹œ ê³„ì‚°
    - ì»·ë¹„ìœ¨ë¡œ Include/DefaultInclude ì„¤ì •
    - __adj_price = Unit Price * __cpi_ratio * __fx_ratio * __fac_ratio
    """
    if pool is None or pool.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = pool.copy()

    # 1) Threshold ì ìš©
    df = df[pd.to_numeric(df["__hyb"], errors="coerce").fillna(0) >= float(sim_threshold)].copy()
    if df.empty:
        # BOQ ê²°ê³¼ë„ BOQ_ID ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ê¸° ì–´ë µê¸° ë•Œë¬¸ì—, ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return pd.DataFrame(), pd.DataFrame()

    # 2) FX/Factor ë§µ(í†µí™”ë³„) ë§Œë“¤ì–´ vectorized ê³„ì‚°
    currencies = df["í†µí™”"].astype(str).str.upper().unique().tolist()

    fx_map = {}
    fac_map = {}
    for c in currencies:
        fx_map[c] = get_exchange_rate(exchange, c, target_currency)
        fac_map[c] = get_factor_ratio(factor, c, target_currency)

    df["í†µí™”_std"] = df["í†µí™”"].astype(str).str.upper()
    df["__fx_ratio"] = df["í†µí™”_std"].map(fx_map).fillna(1.0)
    df["__fac_ratio"] = df["í†µí™”_std"].map(fac_map).fillna(1.0)
    df["ì‚°ì¶œí†µí™”"] = target_currency

    # 3) __adj_price ê³„ì‚°
    unit_price = pd.to_numeric(df["Unit Price"], errors="coerce").fillna(0.0)
    cpi_ratio = pd.to_numeric(df["__cpi_ratio"], errors="coerce").fillna(1.0)

    df["__adj_price"] = unit_price * cpi_ratio * df["__fx_ratio"] * df["__fac_ratio"]

    # 4) BOQë³„ ì»· + Include/DefaultInclude ì„¤ì •
    df["Include"] = False
    df["DefaultInclude"] = False

    for boq_id, gidx in df.groupby("BOQ_ID").groups.items():
        sub = df.loc[gidx].sort_values("__adj_price").copy()
        n = len(sub)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n-cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        kept_index = sub.index[keep_mask]
        df.loc[kept_index, "DefaultInclude"] = True
        df.loc[kept_index, "Include"] = True

    # 5) BOQ ê²°ê³¼(result_df) ìƒì„±
    results = []
    for boq_id, sub in df.groupby("BOQ_ID"):
        inc = sub[sub["Include"] == True]
        if inc.empty:
            final_price = None
            reason_text = "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)"
            top_work = ""
        else:
            final_price = float(inc["__adj_price"].mean())
            currencies2 = sorted(inc["í†µí™”_std"].unique().tolist())
            reason_text = f"{len(currencies2)}ê°œêµ­({', '.join(currencies2)}) {len(inc)}ê°œ ë‚´ì—­ ê·¼ê±°"

            vc = inc["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(inc)})" if top_code else ""

        # BOQ ë©”íƒ€ëŠ” poolì— ìˆìŒ
        one = sub.iloc[0]
        results.append({
            "BOQ_ID": int(boq_id),
            "ë‚´ì—­": one.get("BOQ_ë‚´ì—­", ""),
            "Unit": one.get("BOQ_Unit", ""),
            "Final Price": f"{final_price:,.2f}" if final_price is not None else None,
            "ì‚°ì¶œê·¼ê±°": reason_text,
            "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)": top_work,
        })

    result_df = pd.DataFrame(results).sort_values("BOQ_ID").reset_index(drop=True)

    # 6) ì‚°ì¶œ ë¡œê·¸(log_df) ë°˜í™˜(Include í¸ì§‘ ê°€ëŠ¥í•˜ë„ë¡ í•„ìš”í•œ ì»¬ëŸ¼ í¬í•¨)
    log_cols = [
        "BOQ_ID","BOQ_ë‚´ì—­","BOQ_Unit",
        "Include","DefaultInclude",
        "ê³µì¢…ì½”ë“œ","ê³µì¢…ëª…",
        "ë‚´ì—­","Unit",
        "Unit Price","í†µí™”","ê³„ì•½ë…„ì›”",
        "__adj_price","ì‚°ì¶œí†µí™”",
        "__cpi_ratio","__latest_ym",
        "__fx_ratio","__fac_ratio",
        "__hyb",
        "í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…",
        "í˜‘ë ¥ì‚¬ì½”ë“œ","í˜‘ë ¥ì‚¬ëª…",
    ]
    for c in log_cols:
        if c not in df.columns:
            df[c] = None
    log_df = df[log_cols].copy()

    return result_df, log_df
# =========================
# ğŸ¤– Include ìë™ ì¶”ì²œ ì—ì´ì „íŠ¸(ë£° ê¸°ë°˜)
# =========================
def _to_num(s):
    return pd.to_numeric(s, errors="coerce")

def suggest_include_for_one_boq(
    df_boq: pd.DataFrame,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    d = df_boq.copy()

    hyb = _to_num(d.get("__hyb", 0)).fillna(0.0)
    price = _to_num(d.get("__adj_price", np.nan))

    if mode == "ë³´ìˆ˜ì ":
        hyb_min = 80
        iqr_k = 1.0
    elif mode == "ê³µê²©ì ":
        hyb_min = 60
        iqr_k = 2.0
    else:  # ê· í˜•
        hyb_min = 70
        iqr_k = 1.5

    keep = hyb >= hyb_min

    valid = price[price.notna()]
    low = high = None
    if len(valid) >= 5:
        q1 = valid.quantile(0.25)
        q3 = valid.quantile(0.75)
        iqr = q3 - q1
        low = q1 - iqr_k * iqr
        high = q3 + iqr_k * iqr
        keep = keep & (price.between(low, high) | price.isna())

    keep_idx = d.index[keep].tolist()
    if len(keep_idx) < int(min_keep):
        top_idx = hyb.sort_values(ascending=False).head(int(min_keep)).index.tolist()
        keep_idx = sorted(set(keep_idx) | set(top_idx))

    if len(keep_idx) > int(max_keep):
        keep_idx = hyb.loc[keep_idx].sort_values(ascending=False).head(int(max_keep)).index.tolist()

    include = pd.Series(False, index=d.index)
    include.loc[keep_idx] = True

    reasons = []
    for idx in d.index:
        r = []
        if hyb.loc[idx] < hyb_min:
            r.append(f"ìœ ì‚¬ë„<{hyb_min}")
        if low is not None and high is not None and pd.notna(price.loc[idx]):
            if price.loc[idx] < low or price.loc[idx] > high:
                r.append("ë‹¨ê°€ì´ìƒì¹˜(IQR)")
        if include.loc[idx]:
            reasons.append("í¬í•¨" if not r else "í¬í•¨(ì˜ˆì™¸ë³´ì™„): " + ", ".join(r))
        else:
            reasons.append("ì œì™¸" if not r else "ì œì™¸: " + ", ".join(r))

    summary = {
        "mode": mode,
        "hyb_min": hyb_min,
        "iqr_k": iqr_k,
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
        "kept": int(include.sum()),
        "total": int(len(d)),
    }
    return include, pd.Series(reasons, index=d.index), summary

def apply_agent_to_log(
    log_all: pd.DataFrame,
    boq_id: int,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    mask = log_all["BOQ_ID"].astype(int) == int(boq_id)
    sub = log_all.loc[mask].copy()
    if sub.empty:
        return log_all, None

    inc, reason_s, summary = suggest_include_for_one_boq(sub, mode=mode, min_keep=min_keep, max_keep=max_keep)

    if "AI_ì¶”ì²œì‚¬ìœ " not in log_all.columns:
        log_all["AI_ì¶”ì²œì‚¬ìœ "] = ""
    if "AI_ëª¨ë“œ" not in log_all.columns:
        log_all["AI_ëª¨ë“œ"] = ""

    log_all.loc[mask, "Include"] = inc.values
    log_all.loc[mask, "AI_ì¶”ì²œì‚¬ìœ "] = reason_s.values
    log_all.loc[mask, "AI_ëª¨ë“œ"] = mode

    return log_all, summary

def apply_agent_to_all_boqs(
    log_all: pd.DataFrame,
    mode: str = "ê· í˜•",
    min_keep: int = 3,
    max_keep: int = 50,
):
    rows = []
    for boq_id in sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist()):
        log_all, summary = apply_agent_to_log(log_all, boq_id, mode=mode, min_keep=min_keep, max_keep=max_keep)
        if summary:
            rows.append([boq_id, summary["kept"], summary["total"], summary["mode"]])
    sum_df = pd.DataFrame(rows, columns=["BOQ_ID", "í¬í•¨ìˆ˜", "í›„ë³´ìˆ˜", "ëª¨ë“œ"])
    return log_all, sum_df


# =========================
# ğŸ“ ê·¼ê±° ë³´ê³ ì„œ ìƒì„±(ìš”ì•½/ìƒì„¸)
# =========================
def build_report_tables(log_df: pd.DataFrame, result_df: pd.DataFrame):
    if log_df is None or log_df.empty:
        return pd.DataFrame(), pd.DataFrame()

    df = log_df.copy()
    df["BOQ_ID"] = df["BOQ_ID"].astype(int)

    inc = df[df["Include"] == True].copy()

    detail_cols = [
        "BOQ_ID","BOQ_ë‚´ì—­","BOQ_Unit",
        "ë‚´ì—­","Unit","Unit Price","í†µí™”","ê³„ì•½ë…„ì›”",
        "__adj_price","ì‚°ì¶œí†µí™”",
        "__cpi_ratio","__latest_ym","__fx_ratio","__fac_ratio","__hyb",
        "ê³µì¢…ì½”ë“œ","ê³µì¢…ëª…",
        "í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…","í˜‘ë ¥ì‚¬ì½”ë“œ","í˜‘ë ¥ì‚¬ëª…",
        "AI_ëª¨ë“œ","AI_ì¶”ì²œì‚¬ìœ ",
    ]
    for c in detail_cols:
        if c not in inc.columns:
            inc[c] = None
    detail_df = inc[detail_cols].copy()

    rows = []
    for boq_id, g in df.groupby("BOQ_ID"):
        g_inc = g[g["Include"] == True].copy()
        total_n = len(g)
        inc_n = len(g_inc)

        adj = pd.to_numeric(g_inc.get("__adj_price", np.nan), errors="coerce")
        mean = float(adj.mean()) if inc_n else np.nan
        std = float(adj.std(ddof=0)) if inc_n else np.nan
        vmin = float(adj.min()) if inc_n else np.nan
        vmax = float(adj.max()) if inc_n else np.nan

        countries = sorted(g_inc["í†µí™”"].astype(str).str.upper().unique().tolist()) if inc_n else []
        sites = g_inc["í˜„ì¥ì½”ë“œ"].astype(str).nunique() if inc_n and "í˜„ì¥ì½”ë“œ" in g_inc.columns else 0
        vendors = g_inc["í˜‘ë ¥ì‚¬ì½”ë“œ"].astype(str).nunique() if inc_n and "í˜‘ë ¥ì‚¬ì½”ë“œ" in g_inc.columns else 0

        top_site = ""
        top_vendor = ""
        if inc_n and "í˜„ì¥ì½”ë“œ" in g_inc.columns:
            vc = g_inc["í˜„ì¥ì½”ë“œ"].astype(str).value_counts()
            top_site = f"{vc.index[0]} ({int(vc.iloc[0])}/{inc_n})" if len(vc) else ""
        if inc_n and "í˜‘ë ¥ì‚¬ì½”ë“œ" in g_inc.columns:
            vc2 = g_inc["í˜‘ë ¥ì‚¬ì½”ë“œ"].astype(str).value_counts()
            top_vendor = f"{vc2.index[0]} ({int(vc2.iloc[0])}/{inc_n})" if len(vc2) else ""

        risk = []
        if inc_n == 0:
            risk.append("í¬í•¨í›„ë³´ì—†ìŒ")
        if inc_n and pd.notna(vmax) and pd.notna(vmin) and vmin > 0 and (vmax / vmin > 3):
            risk.append("ë‹¨ê°€í¸ì°¨í¼(>3ë°°)")
        if inc_n and pd.notna(std) and pd.notna(mean) and mean != 0 and (std / mean > 0.5):
            risk.append("ë³€ë™ì„±í¼(CV>0.5)")
        if inc_n and sites == 1 and inc_n >= 3:
            risk.append("í˜„ì¥í¸í–¥(1ê°œí˜„ì¥)")
        if inc_n and vendors == 1 and inc_n >= 3:
            risk.append("ì—…ì²´í¸í–¥(1ê°œì—…ì²´)")

        one = g.iloc[0]
        rows.append({
            "BOQ_ID": int(boq_id),
            "BOQ_ë‚´ì—­": one.get("BOQ_ë‚´ì—­",""),
            "BOQ_Unit": one.get("BOQ_Unit",""),
            "í›„ë³´ìˆ˜": int(total_n),
            "í¬í•¨ìˆ˜": int(inc_n),
            "í¬í•¨êµ­ê°€": ", ".join(countries),
            "í¬í•¨í˜„ì¥ìˆ˜": int(sites),
            "í¬í•¨ì—…ì²´ìˆ˜": int(vendors),
            "ì‚°ì¶œë‹¨ê°€í‰ê· ": mean,
            "ì‚°ì¶œë‹¨ê°€í‘œì¤€í¸ì°¨": std,
            "ì‚°ì¶œë‹¨ê°€ìµœì €": vmin,
            "ì‚°ì¶œë‹¨ê°€ìµœê³ ": vmax,
            "ìµœë¹ˆí˜„ì¥": top_site,
            "ìµœë¹ˆì—…ì²´": top_vendor,
            "ë¦¬ìŠ¤í¬": ", ".join(risk),
        })

    summary_df = pd.DataFrame(rows).sort_values("BOQ_ID").reset_index(drop=True)

    if result_df is not None and not result_df.empty and "BOQ_ID" in result_df.columns:
        tmp = result_df.copy()
        tmp["BOQ_ID"] = tmp["BOQ_ID"].astype(int)
        keep = [c for c in ["BOQ_ID","Final Price","ì‚°ì¶œê·¼ê±°","ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in tmp.columns]
        summary_df = summary_df.merge(tmp[keep], on="BOQ_ID", how="left")

    return summary_df, detail_df

# =========================
# ğŸ¤– AI ìµœì¢… ì ìš© ê¸°ì¤€ ê¸°ë¡/í‘œì‹œìš© (TAB3ì—ì„œ ì‚¬ìš©)
# =========================
def record_ai_last_applied(
    scope: str,
    mode: str,
    min_keep: int,
    max_keep: int,
    summary: Optional[dict] = None,
    boq_id: Optional[int] = None,
):
    """
    scope: "í˜„ì¬ BOQ" or "ì „ì²´ BOQ"
    summary: suggest_include_for_one_boq()ì—ì„œ ë°˜í™˜í•œ summary(ìˆìœ¼ë©´ hyb_min, iqr_k í¬í•¨)
    boq_id: scopeê°€ "í˜„ì¬ BOQ"ì¼ ë•Œ ì–´ë–¤ BOQì— ì ìš©í–ˆëŠ”ì§€ ê¸°ë¡ìš©
    """
    payload = {
        "scope": str(scope),
        "mode": str(mode),
        "min_keep": int(min_keep),
        "max_keep": int(max_keep),
    }
    if boq_id is not None:
        payload["boq_id"] = int(boq_id)

    if isinstance(summary, dict):
        for k in ["hyb_min", "iqr_k", "kept", "total"]:
            if k in summary:
                payload[k] = summary[k]

    st.session_state["ai_last_applied"] = payload


def get_ai_effective_rule_text() -> str:
    info = st.session_state.get("ai_last_applied", None)
    if not isinstance(info, dict) or not info.get("mode"):
        return "AI ìµœì¢…ê¸°ì¤€ ê¸°ë¡ ì—†ìŒ(ìˆ˜ë™ í¸ì§‘ ë˜ëŠ” ê¸°ë³¸ ì»·ë§Œ ì ìš©)"

    scope = info.get("scope", "")
    mode = info.get("mode", "")
    min_keep = info.get("min_keep", "")
    max_keep = info.get("max_keep", "")
    boq_id = info.get("boq_id", None)
    hyb_min = info.get("hyb_min", None)
    iqr_k = info.get("iqr_k", None)

    parts = []
    if scope == "í˜„ì¬ BOQ" and boq_id is not None:
        parts.append(f"ì ìš©ë²”ìœ„={scope}(BOQ_ID={boq_id})")
    else:
        parts.append(f"ì ìš©ë²”ìœ„={scope}")

    parts.append(f"ëª¨ë“œ={mode}")
    parts.append(f"ìµœì†Œí¬í•¨={min_keep}")
    parts.append(f"ìµœëŒ€í¬í•¨={max_keep}")

    if hyb_min is not None:
        parts.append(f"ìœ ì‚¬ë„ìµœì†Œ(hyb_min)={hyb_min}")
    if iqr_k is not None:
        parts.append(f"IQRê³„ìˆ˜(iqr_k)={iqr_k}")

    return " / ".join(parts)

# =========================
# ğŸ§¾ ë³´ê³ ì„œ TAB3 ìœ í‹¸(íŠ¹ì„±/í˜„ì¥/AIê¸°ì¤€/ë¶„í¬ ê·¸ë˜í”„)
# =========================
import matplotlib.pyplot as plt

def build_feature_context_table(feature_master: pd.DataFrame, selected_feature_ids: list) -> pd.DataFrame:
    if not selected_feature_ids:
        return pd.DataFrame(columns=["íŠ¹ì„±ID","ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"])
    fm = feature_master.copy()
    cols6 = ["ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]
    keep = ["íŠ¹ì„±ID"] + cols6
    for c in keep:
        if c in fm.columns:
            fm[c] = fm[c].astype(str).fillna("").str.strip()
        else:
            fm[c] = ""
    out = fm[fm["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in selected_feature_ids])][keep].copy()
    out = out.drop_duplicates(subset=["íŠ¹ì„±ID"]).reset_index(drop=True)
    return out

def build_site_context_table(cost_db: pd.DataFrame, selected_site_codes: list) -> pd.DataFrame:
    if not selected_site_codes:
        return pd.DataFrame(columns=["í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…"])
    tmp = cost_db[["í˜„ì¥ì½”ë“œ","í˜„ì¥ëª…"]].copy()
    tmp = tmp.dropna(subset=["í˜„ì¥ì½”ë“œ"])
    tmp["í˜„ì¥ì½”ë“œ"] = tmp["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    tmp["í˜„ì¥ëª…"] = tmp["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    tmp.loc[tmp["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
    tmp = tmp.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"])
    out = tmp[tmp["í˜„ì¥ì½”ë“œ"].isin([norm_site_code(x) for x in selected_site_codes])].copy()
    out = out.sort_values("í˜„ì¥ì½”ë“œ").reset_index(drop=True)
    return out

def plot_distribution(series: pd.Series, title: str):
    s = pd.to_numeric(series, errors="coerce").dropna()
    fig = plt.figure()
    plt.title(title)
    if len(s) == 0:
        plt.text(0.5, 0.5, "ë°ì´í„° ì—†ìŒ", ha="center", va="center")
    else:
        plt.hist(s.values, bins=30)
        plt.xlabel("ì‚°ì¶œë‹¨ê°€(__adj_price)")
        plt.ylabel("ë¹ˆë„")
    st.pyplot(fig, clear_figure=True)

# =========================
# ğŸ“Š BOQ ë‚´ì—­ë³„ ì‚°ì ë„(ê³„ì•½ë…„ì›” vs ì‚°ì¶œë‹¨ê°€) - í¬í•¨/ë¯¸í¬í•¨ í‘œì‹œ
# =========================
def _parse_contract_month_series(s: pd.Series) -> pd.Series:
    # "2019-11" / ë‚ ì§œ / ê¸°íƒ€ê°€ ì„ì—¬ ìˆì–´ë„ ìµœëŒ€í•œ datetimeìœ¼ë¡œ
    dt = pd.to_datetime(s, errors="coerce")
    if dt.isna().any():
        # fallback: YYYY-MM í˜•íƒœë¡œ ì •ê·œí™” í›„ ì¬íŒŒì‹±
        s2 = s.astype(str).apply(to_year_month_string)
        dt2 = pd.to_datetime(s2, errors="coerce")
        dt = dt.fillna(dt2)
    return dt

def render_boq_scatter(log_df: pd.DataFrame, base_result: pd.DataFrame):
    if log_df is None or log_df.empty:
        st.info("ë¡œê·¸ ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ê²€ìƒ‰(ì˜ˆ: REBAR)
    keyword = st.text_input("ë‚´ì—­ í‚¤ì›Œë“œ(ì˜ˆ: REBAR)", value="", key="report_kw")
    cand = base_result.copy() if (base_result is not None and not base_result.empty) else None

    if cand is not None and "ë‚´ì—­" in cand.columns and "BOQ_ID" in cand.columns and keyword.strip():
        kw = keyword.strip().lower()
        cand = cand[cand["ë‚´ì—­"].astype(str).str.lower().str.contains(kw, na=False)].copy()

    # ì„ íƒ í›„ë³´ BOQ_ID ëª©ë¡
    if cand is not None and not cand.empty:
        boq_ids = cand["BOQ_ID"].dropna().astype(int).unique().tolist()
        boq_ids = sorted(boq_ids)
        id_to_text = cand.set_index(cand["BOQ_ID"].astype(int))["ë‚´ì—­"].astype(str).to_dict()
    else:
        boq_ids = sorted(log_df["BOQ_ID"].dropna().astype(int).unique().tolist())
        id_to_text = (
            log_df.dropna(subset=["BOQ_ID"])
            .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
            .groupby("BOQ_ID")["BOQ_ë‚´ì—­"].first()
            .astype(str).to_dict()
        )

    if not boq_ids:
        st.info("í‘œì‹œí•  BOQ_IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    def fmt(x: int) -> str:
        t = id_to_text.get(int(x), "")
        t = (t[:60] + "â€¦") if len(t) > 60 else t
        return f"{int(x)} | {t}"

    sel = st.selectbox("ê·¸ë˜í”„ ë³¼ BOQ ì„ íƒ", options=boq_ids, format_func=fmt, key="report_boq_pick")

    sub = log_df[log_df["BOQ_ID"].astype(int) == int(sel)].copy()
    if sub.empty:
        st.info("í•´ë‹¹ BOQ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # x, y ì¤€ë¹„
    sub["ê³„ì•½ì›”_dt"] = _parse_contract_month_series(sub["ê³„ì•½ë…„ì›”"])
    sub["ì‚°ì¶œë‹¨ê°€"] = pd.to_numeric(sub["__adj_price"], errors="coerce")
    sub["í¬í•¨ì—¬ë¶€"] = sub["Include"].fillna(False).astype(bool)

    # í‘œì‹œìš© ìµœì†Œ ì»¬ëŸ¼ë§Œ
    sub["í‘œì‹œë‚´ì—­"] = sub["ë‚´ì—­"].astype(str)

    # Altair ì‚°ì ë„
    # - ìƒ‰: í¬í•¨ì—¬ë¶€(ìë™ ìŠ¤í‚´)
    # - í¬ê¸°: í¬í•¨=Trueë©´ í¬ê²Œ
    chart = (
        alt.Chart(sub.dropna(subset=["ê³„ì•½ì›”_dt", "ì‚°ì¶œë‹¨ê°€"]))
        .mark_circle()
        .encode(
            x=alt.X("ê³„ì•½ì›”_dt:T", title="ê³„ì•½ë…„ì›”"),
            y=alt.Y("ì‚°ì¶œë‹¨ê°€:Q", title="ì‚°ì¶œë‹¨ê°€(ì‚°ì¶œí†µí™” ê¸°ì¤€)"),
            color=alt.Color("í¬í•¨ì—¬ë¶€:N", title="í¬í•¨"),
            size=alt.Size("í¬í•¨ì—¬ë¶€:N", title="í¬í•¨(í¬ê¸°)", scale=alt.Scale(range=[40, 140])),
            tooltip=[
                alt.Tooltip("í‘œì‹œë‚´ì—­:N", title="ë‚´ì—­"),
                alt.Tooltip("ì‚°ì¶œë‹¨ê°€:Q", title="ì‚°ì¶œë‹¨ê°€", format=",.4f"),
                alt.Tooltip("í†µí™”:N", title="ì›í†µí™”"),
                alt.Tooltip("ê³„ì•½ë…„ì›”:N", title="ê³„ì•½ë…„ì›”"),
                alt.Tooltip("__hyb:Q", title="ìœ ì‚¬ë„", format=".2f"),
                alt.Tooltip("í˜„ì¥ì½”ë“œ:N", title="í˜„ì¥ì½”ë“œ"),
                alt.Tooltip("í˜‘ë ¥ì‚¬ì½”ë“œ:N", title="í˜‘ë ¥ì‚¬ì½”ë“œ"),
            ],
        )
        .properties(height=420)
        .interactive()
    )
    st.altair_chart(chart, use_container_width=True)

# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")

cost_db     = load_excel_from_repo("cost_db.xlsx")
price_index = load_excel_from_repo("price_index.xlsx")
exchange    = load_excel_from_repo("exchange.xlsx")
factor      = load_excel_from_repo("Factor.xlsx")
project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
feature_master = load_excel_from_repo("feature_master_FID.xlsx")


# =========================
# Session init
# =========================
if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []
if "auto_sites" not in st.session_state:
    st.session_state["auto_sites"] = []


# =========================
# Sidebar: ì„¤ì •
# =========================
st.sidebar.header("âš™ï¸ ì„¤ì •")

# âœ… í˜„ì¥í•„í„°ëŠ” ê¸°ëŠ¥ì ìœ¼ë¡œ ê³„ì† ì‚¬ìš©(í•­ìƒ True)í•˜ë˜, í™”ë©´ì—ëŠ” ë…¸ì¶œí•˜ì§€ ì•ŠìŒ
use_site_filter = True

DEFAULT_W_STR = 0.3
DEFAULT_TOP_K_SEM = 200
w_str = DEFAULT_W_STR
w_sem = 1.0 - w_str
top_k_sem = DEFAULT_TOP_K_SEM


# =========================
# (1) BOQ ì—…ë¡œë“œ (ë¨¼ì €!)
# =========================
with st.container():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    boq_file = st.file_uploader("ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
    st.markdown("</div>", unsafe_allow_html=True)


# =========================
# (2) ë©”ì¸: BOQ ì—…ë¡œë“œ ì•„ë˜ íŠ¹ì„± ì„ íƒ UI
# =========================
auto_sites = []

if boq_file is not None:
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    st.markdown("### ğŸ·ï¸ í”„ë¡œì íŠ¸ íŠ¹ì„± ì„ íƒ (176ê°œ ì „ì²´)")

    fm = feature_master.copy()
    cols6 = ["ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]
    for c in ["íŠ¹ì„±ID"] + cols6:
        fm[c] = fm[c].astype(str).fillna("").str.strip()

    site_cnt = project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"].nunique().astype(int).to_dict()
    fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)

    fm["ë¼ë²¨"] = fm.apply(
        lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | '
                  f'{r["Cost Driver Type"]}/{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                  f'í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
        axis=1
    )

    keyword = st.text_input("íŠ¹ì„± ëª©ë¡ í•„í„°(í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ: DCM, Jet, ì§€ë°˜ê°œëŸ‰, ë„ì‹¬ ...")
    fm_view = fm
    if keyword.strip():
        kw = keyword.strip().lower()
        fm_view = fm[fm["ë¼ë²¨"].str.lower().str.contains(kw, na=False)].copy()

    options = fm_view["ë¼ë²¨"].tolist()
    label_to_id = dict(zip(fm_view["ë¼ë²¨"], fm_view["íŠ¹ì„±ID"]))

    # ê¸°ì¡´ ì„ íƒ ë³µì›(í•„í„°ë§ ì‹œì—ë„ ìœ ì§€)
    master_label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
    master_id_to_label = {}
    for lab, fid in master_label_to_id.items():
        master_id_to_label.setdefault(fid, lab)

    current_selected_ids = st.session_state.get("selected_feature_ids", [])
    current_labels = [master_id_to_label[fid] for fid in current_selected_ids if fid in master_id_to_label]

    new_selected_labels = st.multiselect(
        "íŠ¹ì„± ì„ íƒ(ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
        options=options,
        default=[lab for lab in current_labels if lab in options]
    )

    new_ids = [label_to_id[lab] for lab in new_selected_labels]
    kept_ids = [fid for fid in current_selected_ids if (fid in master_id_to_label and master_id_to_label[fid] not in options)]
    merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))
    st.session_state["selected_feature_ids"] = merged_ids

    st.markdown("#### âœ… ì„ íƒëœ íŠ¹ì„±ID")
    if merged_ids:
        st.write(merged_ids)
        del_ids = st.multiselect("ì œê±°í•  íŠ¹ì„±ID ì„ íƒ", options=merged_ids, default=[])
        c1, c2 = st.columns(2)
        with c1:
            if st.button("ğŸ—‘ï¸ ì„ íƒ ì œê±°"):
                st.session_state["selected_feature_ids"] = [x for x in merged_ids if x not in del_ids]
        with c2:
            if st.button("ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”"):
                st.session_state["selected_feature_ids"] = []
    else:
        st.info("ì„ íƒëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")

    # auto_sites ê³„ì‚°
    if st.session_state["selected_feature_ids"]:
        auto_sites = (
            project_feature_long[
                project_feature_long["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in st.session_state["selected_feature_ids"]])
            ]["í˜„ì¥ì½”ë“œ"].astype(str).unique().tolist()
        )
    else:
        auto_sites = []

    # í‘œì¤€í™” + ì •ë ¬í•´ì„œ session ì €ì¥
    new_auto_sites = sorted({
        norm_site_code(x)
        for x in (auto_sites or [])
        if norm_site_code(x)
    })
    st.session_state["auto_sites"] = new_auto_sites

    st.success(f"ìë™ í›„ë³´ í˜„ì¥: {len(new_auto_sites)}ê°œ")
    if len(new_auto_sites) <= 30:
        st.write(new_auto_sites)

    st.markdown("</div>", unsafe_allow_html=True)
else:
    st.info("BOQ ì—…ë¡œë“œ í›„ í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# (3) ì‚¬ì´ë“œë°”: ì‹¤ì  í˜„ì¥ ì„ íƒ
# =========================
selected_site_codes = None

if use_site_filter:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ")

    auto_sites = st.session_state.get("auto_sites", [])

    # 1) cost_dbì—ì„œ ì „ì²´ í˜„ì¥ ëª©ë¡ ë§Œë“¤ê¸°
    site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    site_df = site_df.dropna(subset=["í˜„ì¥ì½”ë“œ"])

    site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"
    site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"]).reset_index(drop=True)

    all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()
    code_to_name = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["í˜„ì¥ëª…"]))

    # 2) auto_sites -> auto_codes (ì¡´ì¬í•˜ëŠ” ì½”ë“œë§Œ)
    auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
    auto_codes = [c for c in auto_codes_raw if c in code_to_name]

    other_codes = [c for c in all_codes if c not in set(auto_codes)]

    # âœ… í‘œì‹œìš©(í˜„ì¥ëª…ë§Œ, ìµœëŒ€ 25ì)
    def fmt_site_code(code: str) -> str:
        name = code_to_name.get(code, "")
        name = name.strip()
        if len(name) > 25:
            return name[:25] + "â€¦"
        return name

    # =========================
    # âœ… auto í›„ë³´ê°€ ë°”ë€Œë©´: ìë™ í›„ë³´ë¥¼ "ì¦‰ì‹œ ì „ì²´ ì„ íƒ" ìƒíƒœë¡œ ì„¸íŒ…
    # =========================
    auto_sig = "|".join(auto_codes)

    if st.session_state.get("_auto_sig") != auto_sig:
        st.session_state["_auto_sig"] = auto_sig
        st.session_state["selected_auto_codes"] = list(auto_codes)

    if "selected_auto_codes" not in st.session_state:
        st.session_state["selected_auto_codes"] = list(auto_codes)
    if "selected_extra_codes" not in st.session_state:
        st.session_state["selected_extra_codes"] = []

    # âœ… ì½”ë“œë¡œ ì„ íƒí•˜ë˜, í™”ë©´ì—ëŠ” í˜„ì¥ëª…ë§Œ ë³´ì´ê²Œ(format_func)
    selected_auto_codes = st.sidebar.multiselect(
        "ì‹¤ì í˜„ì¥",
        options=auto_codes,
        key="selected_auto_codes",
        format_func=fmt_site_code,
    )

    selected_extra_codes = st.sidebar.multiselect(
        "ì¶”ê°€ ì‹¤ì í˜„ì¥",
        options=other_codes,
        key="selected_extra_codes",
        format_func=fmt_site_code,
    )

    selected_site_codes = sorted(set(selected_auto_codes + selected_extra_codes))
    st.sidebar.caption(f"ì„ íƒ í˜„ì¥: {len(selected_site_codes)}ê°œ")


# =========================
# ê¸°íƒ€ ìŠ¬ë¼ì´ë”/í†µí™” ì„ íƒ
# =========================
sim_threshold = st.sidebar.slider("Threshold (ì»· ê¸°ì¤€, %)", 0, 100, 60, 5)
cut_ratio = st.sidebar.slider("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)", 0, 30, 20, 5) / 100.0

target_options = sorted(factor["êµ­ê°€"].astype(str).str.upper().unique().tolist())
default_idx = target_options.index("KRW") if "KRW" in target_options else 0
target_currency = st.sidebar.selectbox("ì‚°ì¶œí†µí™”", options=target_options, index=default_idx)

missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper()==target_currency].empty
missing_factor   = factor[factor["êµ­ê°€"].astype(str).str.upper()==target_currency].empty
if missing_exchange:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
if missing_factor:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")


# =========================
# Run / Auto Recompute
# =========================
# âœ… ìë™ ì¬ì‚°ì¶œ í† ê¸€(ì‚¬ì´ë“œë°”)
auto_recompute = True  # âœ… UIëŠ” ìˆ¨ê¸°ì§€ë§Œ ê¸°ëŠ¥ì€ í•­ìƒ ON

def boq_file_signature(uploaded_file) -> str:
    """BOQ íŒŒì¼ì´ ë°”ë€Œì—ˆëŠ”ì§€ ê°ì§€í•˜ê¸° ìœ„í•œ ê°„ë‹¨ ì„œëª…(í•´ì‹œ)."""
    if uploaded_file is None:
        return "no_boq"
    try:
        b = uploaded_file.getvalue()
        # ë„ˆë¬´ í¬ë©´ ì•/ë’¤ ì¼ë¶€ë§Œ í•´ì‹œ
        if len(b) > 2_000_000:
            b = b[:1_000_000] + b[-1_000_000:]
        return hashlib.md5(b).hexdigest()
    except Exception:
        # fallback
        return f"{getattr(uploaded_file, 'name', 'boq')}_{getattr(uploaded_file, 'size', '')}"

def make_params_signature() -> str:
    payload = {
        "boq": boq_file_signature(boq_file),
        "use_site_filter": bool(use_site_filter),
        "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
        "sim_threshold": float(sim_threshold),
        "cut_ratio": float(cut_ratio),
        "target_currency": str(target_currency),
        "w_str": float(w_str),
        "w_sem": float(w_sem),
        "top_k_sem": int(top_k_sem),
    }
    s = json.dumps(payload, ensure_ascii=False, sort_keys=True)
    return hashlib.md5(s.encode("utf-8")).hexdigest()

def run_calculation_and_store(run_sig: str):
    """'ì‚°ì¶œ ì‹¤í–‰'ê³¼ ë™ì¼í•œ íš¨ê³¼: ê³„ì‚° â†’ session_state ì €ì¥ â†’ í¸ì§‘ê°’ ì´ˆê¸°í™”"""
    if boq_file is None:
        st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        return
    if missing_exchange or missing_factor:
        st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    boq = pd.read_excel(boq_file, engine="openpyxl")

    if use_site_filter and selected_site_codes is not None:
        cost_db_run = cost_db[
            cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
        ].copy()
    else:
        cost_db_run = cost_db.copy()

    st.sidebar.caption(
    f"ì „ì²´ {len(cost_db):,}ê°œ ë‚´ì—­ ì¤‘ {len(cost_db_run):,}ê°œ ë‚´ì—­ìœ¼ë¡œ ì‚°ì¶œ ì‹¤í–‰"
    )

    progress = st.progress(0.0)
    prog_text = st.empty()

    # âœ… í›„ë³´í’€ ì¬ì‚¬ìš©ì„ ìœ„í•œ ì‹œê·¸ë‹ˆì²˜(í˜„ì¥í•„í„°/BOQ/DBê°€ ë°”ë€” ë•Œë§Œ ìƒˆë¡œ ìƒì„±)
    pool_sig_payload = {
        "boq": boq_file_signature(boq_file),
        "use_site_filter": bool(use_site_filter),
        "selected_site_codes": sorted([norm_site_code(x) for x in (selected_site_codes or [])]),
        "top_k_sem": int(top_k_sem),
        "w_str": float(w_str),
        "w_sem": float(w_sem),
        "cost_db_rows": int(len(cost_db_run)),
    }
    pool_sig = hashlib.md5(json.dumps(pool_sig_payload, sort_keys=True).encode("utf-8")).hexdigest()

    # 1) í›„ë³´í’€ ìƒì„±(ë¬´ê±°ì›€) - í•„ìš”í•œ ê²½ìš°ì—ë§Œ
    need_new_pool = (st.session_state.get("candidate_pool_sig") != pool_sig) or ("candidate_pool" not in st.session_state)

    if need_new_pool:
        with st.spinner("í›„ë³´ í’€ ìƒì„±(ìµœì´ˆ/í˜„ì¥ë³€ê²½ ì‹œ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)..."):
            pool = build_candidate_pool(
                cost_db=cost_db_run,
                boq=boq,
                price_index=price_index,
                sim_w_str=w_str,
                sim_w_sem=w_sem,
                top_k_sem=top_k_sem,
                pool_per_boq=400,
                progress=progress,
                prog_text=prog_text,
            )
        st.session_state["candidate_pool"] = pool
        st.session_state["candidate_pool_sig"] = pool_sig
    else:
        pool = st.session_state["candidate_pool"]

    # 2) ë¹ ë¥¸ ì¬ê³„ì‚°(ê°€ë²¼ì›€) - Threshold/ì»·/ì‚°ì¶œí†µí™”ëŠ” ì—¬ê¸°ì„œë§Œ ë°˜ì˜
    with st.spinner("ë¹ ë¥¸ ì¬ê³„ì‚°(Threshold/ì»·/ì‚°ì¶œí†µí™” ë°˜ì˜ ì¤‘)..."):
        result_df, log_df = fast_recompute_from_pool(
            pool=pool,
            exchange=exchange,
            factor=factor,
            sim_threshold=sim_threshold,
            cut_ratio=cut_ratio,
            target_currency=target_currency,
        )

    progress.progress(1.0)
    prog_text.text("ì‚°ì¶œ ì§„í–‰ë¥ : ì™„ë£Œ")
    st.success("âœ… ì™„ë£Œ! ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")

    # âœ… ê³„ì‚° ê²°ê³¼ ì €ì¥ (rerun ë˜ì–´ë„ ìœ ì§€)
    st.session_state["boq_df"] = boq
    st.session_state["result_df_base"] = result_df.copy()
    st.session_state["log_df_base"] = log_df.copy()
    st.session_state["log_df_edited"] = log_df.copy()   # âœ… í¸ì§‘ê°’ ì´ˆê¸°í™”(ì¬ì‚°ì¶œ=ì‹¤í–‰ê³¼ ë™ì¼íš¨ê³¼)
    st.session_state.pop("result_df_adjusted", None)    # âœ… ì¡°ì • ê²°ê³¼ ì´ˆê¸°í™”
    st.session_state["has_results"] = True

    # âœ… ì´ë²ˆ ì‹¤í–‰ ì¡°ê±´ ì„œëª… ì €ì¥
    st.session_state["last_run_sig"] = run_sig


# =========================
# (1) ì‹¤í–‰ íŠ¸ë¦¬ê±° ê²°ì •
# =========================
run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰")

current_sig = make_params_signature()
last_sig = st.session_state.get("last_run_sig", None)

needs_rerun = (last_sig is not None and current_sig != last_sig)

# ìë™ ì¬ì‚°ì¶œ OFFì¸ë° ì¡°ê±´ ë°”ë€ ê²½ìš° â†’ ê²½ê³ 
if st.session_state.get("has_results", False) and needs_rerun and not auto_recompute:
    st.sidebar.warning("âš ï¸ ì¡°ê±´ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‚°ì¶œ ì‹¤í–‰ì´ í•„ìš”í•©ë‹ˆë‹¤.")

# ìë™ ì¬ì‚°ì¶œ ONì´ê³ , ê²°ê³¼ê°€ ì´ë¯¸ ìˆê³ , ì¡°ê±´ ë°”ë€Œë©´ â†’ ìë™ ì‹¤í–‰
auto_run = st.session_state.get("has_results", False) and needs_rerun and auto_recompute

# ìµœì´ˆ ì‹¤í–‰(ê²°ê³¼ ì—†ìŒ)ì¸ë° auto_recompute ì¼œì ¸ ìˆì–´ë„, ë²„íŠ¼ ì—†ì´ ìë™ ì‹¤í–‰ì€ ë¶€ë‹´ë  ìˆ˜ ìˆì–´ ê¸°ë³¸ì€ ì•ˆ í•¨
# ì›í•˜ë©´ ì•„ë˜ ì¡°ê±´ì„ í™•ì¥í•´ì„œ 'BOQ ì—…ë¡œë“œ ì‹œ ìë™ 1íšŒ ì‹¤í–‰'ë„ ê°€ëŠ¥

# =========================
# (2) ë²„íŠ¼ ì‹¤í–‰ ë˜ëŠ” ìë™ ì‹¤í–‰
# =========================
if run_btn or auto_run:
    # ìë™ ì¬ì‚°ì¶œì´ë©´ ì‚¬ìš©ì í¸ì§‘ì´ ì´ˆê¸°í™”ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì•ˆë‚´
    if auto_run:
        st.sidebar.info("â„¹ï¸ ì¡°ê±´ ë³€ê²½ ê°ì§€ â†’ ìë™ ì¬ì‚°ì¶œ ì¤‘ (ë¡œê·¸ í¸ì§‘ê°’ì€ ì´ˆê¸°í™”ë©ë‹ˆë‹¤)")
    run_calculation_and_store(current_sig)


# =========================
# (3) ê²°ê³¼ í™”ë©´: ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ
# =========================
if st.session_state.get("has_results", False):
    boq = st.session_state["boq_df"]
    result_df = st.session_state["result_df_base"]
    log_df = st.session_state["log_df_base"]

    # -------------------------
    # ë¡œê·¸ Include ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ì¬ê³„ì‚° í•¨ìˆ˜
    # -------------------------
    def recompute_result_from_log(edited_log: pd.DataFrame) -> pd.DataFrame:
        base = st.session_state["result_df_base"].copy()

        out_prices = []
        for boq_id, g in edited_log.groupby("BOQ_ID"):
            g2 = g[g["Include"] == True].copy()
            if g2.empty:
                out_prices.append((int(boq_id), None, "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)", ""))
                continue

            final_price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())

            currencies = sorted(g2["í†µí™”"].astype(str).str.upper().unique().tolist())
            reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(g2)}ê°œ ë‚´ì—­ ê·¼ê±°"

            vc = g2["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(g2)})" if top_code else ""

            out_prices.append((int(boq_id), f"{final_price:,.2f}", reason_text, top_work))

        upd = pd.DataFrame(out_prices, columns=["BOQ_ID", "Final Price", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"])
        base = base.drop(columns=[c for c in ["Final Price", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in base.columns], errors="ignore")
        base = base.merge(upd, on="BOQ_ID", how="left")
        return base

    tab1, tab2, tab3 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸(í¸ì§‘ ê°€ëŠ¥)", "ğŸ“ ê·¼ê±° ë³´ê³ ì„œ"])

    with tab2:
        st.caption("âœ… ì²´í¬ í•´ì œí•˜ë©´ í‰ê· ë‹¨ê°€ ì‚°ì¶œì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. ì²´í¬í•˜ë©´ í¬í•¨ë©ë‹ˆë‹¤.")

        if "log_df_edited" not in st.session_state:
            st.session_state["log_df_edited"] = log_df.copy()

        log_all = st.session_state["log_df_edited"]

        # âœ… BOQ ì„ íƒì„ "ID | ë‚´ì—­"ìœ¼ë¡œ í‘œì‹œ
        boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())

        # result_df_baseì—ì„œ BOQ_IDë³„ ë‚´ì—­ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°(ìˆìœ¼ë©´ ë” ì •í™•)
        base_for_label = st.session_state.get("result_df_base", pd.DataFrame()).copy()
        boq_text_col = "ë‚´ì—­" if ("ë‚´ì—­" in base_for_label.columns) else None

        id_to_text = {}
        if boq_text_col and ("BOQ_ID" in base_for_label.columns):
            id_to_text = (
                base_for_label.dropna(subset=["BOQ_ID"])
                .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                .set_index("BOQ_ID")[boq_text_col]
                .astype(str)
                .to_dict()
            )
        else:
            # fallback: log_dfì˜ BOQ_ë‚´ì—­ ì‚¬ìš©
            tmp_map = (
                log_all.dropna(subset=["BOQ_ID"])
                .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
                .groupby("BOQ_ID")["BOQ_ë‚´ì—­"].first()
                .astype(str)
                .to_dict()
            )
            id_to_text = tmp_map

        def fmt_boq_id(x: int) -> str:
            t = id_to_text.get(int(x), "")
            t = (t[:60] + "â€¦") if len(t) > 60 else t
            return f"{int(x)} | {t}"

        sel_id = st.selectbox(
            "í¸ì§‘í•  BOQ ì„ íƒ",
            options=boq_ids,
            format_func=fmt_boq_id,
            key="sel_boq_id"
        )

        # âœ… ì„ íƒëœ BOQ í›„ë³´ë§Œ
        log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()
        # =========================
        # ğŸ¤– AI ì¶”ì²œ ì»¨íŠ¸ë¡¤ (í˜„ì¬ BOQ / ì „ì²´ BOQ)
        # =========================
        if "_include_backup" not in st.session_state:
            st.session_state["_include_backup"] = {}
        if "_include_backup_all" not in st.session_state:
            st.session_state["_include_backup_all"] = None

        cA, cB, cC, cD = st.columns([1.2, 1.0, 1.0, 1.8])
        with cA:
            agent_mode = st.selectbox("AI ì¶”ì²œ ëª¨ë“œ", ["ë³´ìˆ˜ì ", "ê· í˜•", "ê³µê²©ì "], index=1, key="agent_mode")
        with cB:
            min_keep = st.number_input("ìµœì†Œ í¬í•¨", min_value=1, max_value=20, value=3, step=1, key="agent_min_keep")
        with cC:
            max_keep = st.number_input("ìµœëŒ€ í¬í•¨", min_value=3, max_value=200, value=50, step=1, key="agent_max_keep")
        with cD:
            st.caption("â€» ì ìš© í›„ í™”ë©´ì´ ìë™ ê°±ì‹ ë©ë‹ˆë‹¤.")

        b1, b2, b3, b4 = st.columns([1.2, 1.2, 1.2, 2.4])
        with b1:
            btn_ai_one = st.button("ğŸ¤– AI ì ìš©(í˜„ì¬ BOQ)", key="btn_ai_one")
        with b2:
            btn_undo_one = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(í˜„ì¬ BOQ)", key="btn_undo_one")
        with b3:
            btn_ai_all = st.button("ğŸ¤– AI ì ìš©(ì „ì²´ BOQ)", key="btn_ai_all")
        with b4:
            btn_undo_all = st.button("â†©ï¸ ë˜ëŒë¦¬ê¸°(ì „ì²´ BOQ)", key="btn_undo_all")

        if btn_undo_one:
            backup = st.session_state["_include_backup"].get(int(sel_id))
            if backup is not None and len(backup) == len(log_view_full.index):
                st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = backup.values
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(í˜„ì¬ BOQ)")
                st.rerun()
            else:
                st.warning("ë˜ëŒë¦´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í›„ë³´í–‰ì´ ë³€ê²½ë¨).")

        if btn_ai_one:
            st.session_state["_include_backup"][int(sel_id)] = st.session_state["log_df_edited"].loc[log_view_full.index, "Include"].copy()
            updated, summary = apply_agent_to_log(
                log_all=st.session_state["log_df_edited"].copy(),
                boq_id=int(sel_id),
                mode=agent_mode,
                min_keep=int(min_keep),
                max_keep=int(max_keep),
            )
            st.session_state["log_df_edited"] = updated
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
            if summary:
                st.success(f"AI ì ìš© ì™„ë£Œ(í˜„ì¬ BOQ): {summary['kept']}/{summary['total']} í¬í•¨, ëª¨ë“œ={summary['mode']}")
            record_ai_last_applied("í˜„ì¬ BOQ", agent_mode, int(min_keep), int(max_keep), summary, boq_id=int(sel_id))
            st.rerun()

        if btn_ai_all:
            st.session_state["_include_backup_all"] = st.session_state["log_df_edited"][["BOQ_ID", "Include"]].copy()
            updated, sum_df = apply_agent_to_all_boqs(
                log_all=st.session_state["log_df_edited"].copy(),
                mode=agent_mode,
                min_keep=int(min_keep),
                max_keep=int(max_keep),
            )
            st.session_state["log_df_edited"] = updated
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
            st.success("AI ì ìš© ì™„ë£Œ(ì „ì²´ BOQ)")
            if sum_df is not None and not sum_df.empty:
                st.dataframe(sum_df, use_container_width=True)
            record_ai_last_applied("ì „ì²´ BOQ", agent_mode, int(min_keep), int(max_keep), None)
            st.rerun()

        if btn_undo_all:
            backup_all = st.session_state.get("_include_backup_all")
            if backup_all is None or backup_all.empty:
                st.warning("ë˜ëŒë¦´ ì „ì²´ ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                cur = st.session_state["log_df_edited"].copy()
                b = backup_all.copy()
                b["BOQ_ID"] = b["BOQ_ID"].astype(int)
                cur["BOQ_ID"] = cur["BOQ_ID"].astype(int)

                # BOQ_ID ê¸°ì¤€ Include ë³µì›
                cur = cur.drop(columns=["Include"], errors="ignore").merge(b, on="BOQ_ID", how="left")
                cur["Include"] = cur["Include"].fillna(False).astype(bool)

                st.session_state["log_df_edited"] = cur
                st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
                st.success("ë˜ëŒë¦¬ê¸° ì™„ë£Œ(ì „ì²´ BOQ)")
                st.rerun()

        # -------------------------
        # âœ… í™”ë©´ í‘œì‹œìš© ì»¬ëŸ¼(ì—´ ìˆœì„œ ê³ ì •)
        # - ì‚°ì¶œë‹¨ê°€(__adj_price)ì€ ì•ìª½ ìœ ì§€
        # - ì‚°ì¶œê·¼ê±°: ë¬¼ê°€ â†’ í™˜ìœ¨ â†’ êµ­ê°€ ìˆœ
        # - BOQ_ID/BOQ_ë‚´ì—­/BOQ_Unitì€ í™”ë©´ì—ì„œ ìˆ¨ê¹€(ë‹¤ìš´ë¡œë“œì—ëŠ” ë‚¨ì•„ìˆìŒ)
        # -------------------------
        display_cols = [
            "Include", "DefaultInclude",
            "ë‚´ì—­", "Unit",
            "Unit Price", "í†µí™”", "ê³„ì•½ë…„ì›”",
            "__adj_price", "ì‚°ì¶œí†µí™”",
            "__cpi_ratio", "__latest_ym",
            "__fx_ratio",
            "__fac_ratio",
            "__hyb",
            "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
            "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
            "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        ]

        for c in display_cols:
            if c not in log_view_full.columns:
                log_view_full[c] = None

        log_view = log_view_full[display_cols].copy()

        # âœ… í¸ì§‘(Includeë§Œ)
        edited_view = st.data_editor(
            log_view,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Include": st.column_config.CheckboxColumn("í¬í•¨", help="í‰ê· ë‹¨ê°€ ì‚°ì¶œ í¬í•¨/ì œì™¸"),
                "DefaultInclude": st.column_config.CheckboxColumn("ê¸°ë³¸í¬í•¨", help="ì´ˆê¸° ìë™ í¬í•¨ ì—¬ë¶€(ì»· ë¡œì§)"),

                "ë‚´ì—­": st.column_config.TextColumn("ë‚´ì—­", width="large"),
                "Unit": st.column_config.TextColumn("ë‹¨ìœ„(Unit)"),

                "Unit Price": st.column_config.NumberColumn("ì›ë‹¨ê°€", format="%.4f"),
                "í†µí™”": st.column_config.TextColumn("ì›í†µí™”"),
                "ê³„ì•½ë…„ì›”": st.column_config.TextColumn("ê³„ì•½ë…„ì›”"),

                "__adj_price": st.column_config.NumberColumn("ì‚°ì¶œë‹¨ê°€(ì‚°ì¶œí†µí™” ê¸°ì¤€)", format="%.4f"),
                "ì‚°ì¶œí†µí™”": st.column_config.TextColumn("ì‚°ì¶œí†µí™”"),

                "__cpi_ratio": st.column_config.NumberColumn("ë¬¼ê°€ë³´ì •ê³„ìˆ˜(CPI)", format="%.6f"),
                "__latest_ym": st.column_config.TextColumn("ë¬¼ê°€ì§€ìˆ˜ ìµœì‹ ì›”"),

                "__fx_ratio": st.column_config.NumberColumn("í™˜ìœ¨ë³´ì •ê³„ìˆ˜", format="%.6f"),
                "__fac_ratio": st.column_config.NumberColumn("êµ­ê°€ë³´ì •ê³„ìˆ˜(Factor)", format="%.6f"),

                "__hyb": st.column_config.NumberColumn("ìœ ì‚¬ë„ì ìˆ˜", format="%.2f"),

                "ê³µì¢…ì½”ë“œ": st.column_config.TextColumn("ê³µì¢…ì½”ë“œ"),
                "ê³µì¢…ëª…": st.column_config.TextColumn("ê³µì¢…ëª…"),

                "í˜„ì¥ì½”ë“œ": st.column_config.TextColumn("í˜„ì¥ì½”ë“œ"),
                "í˜„ì¥ëª…": st.column_config.TextColumn("í˜„ì¥ëª…"),

                "í˜‘ë ¥ì‚¬ì½”ë“œ": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ì½”ë“œ"),
                "í˜‘ë ¥ì‚¬ëª…": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ëª…"),
            },
            disabled=[c for c in log_view.columns if c not in ["Include"]],
            key="log_editor",
        )

        # âœ… ê°€ì¥ ì•ˆì „í•œ ë°˜ì˜ ë°©ì‹: ì›ë³¸ ì¸ë±ìŠ¤ë¡œ Includeë§Œ ì—…ë°ì´íŠ¸
        st.session_state["log_df_edited"].loc[log_view_full.index, "Include"] = edited_view["Include"].values

        # âœ… ì¦‰ì‹œ BOQ ê²°ê³¼ ì¬ê³„ì‚°
        st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])

    with tab1:
        show_df = st.session_state.get("result_df_adjusted", result_df).copy()
        if "í†µí™”" in show_df.columns:
            show_df = show_df.drop(columns=["í†µí™”"])
        st.dataframe(show_df, use_container_width=True)
   
    with tab3:
        st.markdown("## ğŸ“ ê·¼ê±° ë³´ê³ ì„œ(ìë™ ìƒì„±)")
        st.caption("í˜„ì¬ Include(í¬í•¨) ìƒíƒœ + ì¡°ê±´/ì„ íƒ í˜„ì¥/íŠ¹ì„± + (AI ì ìš© ì‹œ) ìµœì¢… ê¸°ì¤€ì„ í¬í•¨í•©ë‹ˆë‹¤.")
    
        base_result = st.session_state.get("result_df_adjusted", st.session_state.get("result_df_base", pd.DataFrame()))
        log_for_report = st.session_state.get("log_df_edited", st.session_state.get("log_df_base", pd.DataFrame()))
    
        # 1) ì°¾ì•„ì•¼ í•  ê³µì¢… íŠ¹ì„±(ì„ íƒëœ í”„ë¡œì íŠ¸ íŠ¹ì„±)
        st.markdown("### 1) ì°¾ì•„ì•¼ í•  ê³µì¢… íŠ¹ì„±(ì„ íƒëœ í”„ë¡œì íŠ¸ íŠ¹ì„±)")
        sel_features = st.session_state.get("selected_feature_ids", [])
        ft = build_feature_context_table(feature_master, sel_features)
        if ft.empty:
            st.info("ì„ íƒëœ íŠ¹ì„±IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.dataframe(ft, use_container_width=True)
    
        # 2) ì°¾ì€ ì‹¤ì  í˜„ì¥ ë¦¬ìŠ¤íŠ¸(ìµœì¢… ì„ íƒ í˜„ì¥)
        st.markdown("### 2) ì°¾ì€ ì‹¤ì  í˜„ì¥ ë¦¬ìŠ¤íŠ¸(ìµœì¢… ì„ íƒ í˜„ì¥)")
        try:
            _sel_sites = selected_site_codes if (selected_site_codes is not None) else []
        except Exception:
            _sel_sites = []
        st_sites = build_site_context_table(cost_db, _sel_sites)
        if st_sites.empty:
            st.info("ì„ íƒëœ í˜„ì¥ì´ ì—†ìŠµë‹ˆë‹¤(ë˜ëŠ” í˜„ì¥ í•„í„° ë¯¸ì‚¬ìš©).")
        else:
            st.dataframe(st_sites, use_container_width=True)
    
        # 3) ë‹¨ê°€ ì¶”ì¶œ ê·¼ê±°(ì¡°ê±´)
        st.markdown("### 3) ë‹¨ê°€ ì¶”ì¶œ ê·¼ê±°(ì¡°ê±´)")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("Threshold(ì»· ê¸°ì¤€, %)", f"{float(sim_threshold):.0f}")
        with c2:
            st.metric("ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨(%)", f"{float(cut_ratio)*100:.0f}")
        with c3:
            st.metric("ì‚°ì¶œí†µí™”", str(target_currency))
    
        # 4) AI ì ìš© ì‹œ ìµœì¢… ê¸°ì¤€
        st.markdown("### 4) AI ì ìš© ì‹œ ìµœì¢… ê¸°ì¤€")
        st.write(get_ai_effective_rule_text())
    
        # 5) ì‹¤ì  ë‹¨ê°€ BOQ(ê²°ê³¼)
        st.markdown("### 5) ì‹¤ì  ë‹¨ê°€ BOQ(ê²°ê³¼)")
        if base_result is None or base_result.empty:
            st.warning("ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‚°ì¶œ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            st.dataframe(base_result, use_container_width=True)
    
        # 6) ë³´ê³ ì„œ í…Œì´ë¸” ìƒì„±/ê°±ì‹ 
        if st.button("ğŸ“ ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ ", key="btn_build_report"):
            summary_df, detail_df = build_report_tables(log_for_report, base_result)
            st.session_state["report_summary_df"] = summary_df
            st.session_state["report_detail_df"] = detail_df
    
        summary_df = st.session_state.get("report_summary_df", pd.DataFrame())
        detail_df = st.session_state.get("report_detail_df", pd.DataFrame())
    
        st.markdown("### 6) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìš”ì•½)")
        if summary_df is None or summary_df.empty:
            st.info("ë³´ê³ ì„œë¥¼ ë³´ë ¤ë©´ 'ë³´ê³ ì„œ ìƒì„±/ê°±ì‹ 'ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        else:
            st.dataframe(summary_df, use_container_width=True)
    
        st.markdown("### 7) ê° ë‚´ì—­ë³„ ë‹¨ê°€ ê·¼ê±°(ìƒì„¸: Include=True í›„ë³´)")
        if detail_df is not None and not detail_df.empty:
            st.dataframe(detail_df, use_container_width=True)
        else:
            st.info("Include=True ìƒì„¸ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤(ì „ë¶€ ì œì™¸ë˜ì—ˆê±°ë‚˜ í›„ë³´ê°€ ì—†ìŒ).")
    
        # 8) ë¶„í¬ ê·¸ë˜í”„(ì „ì²´/ì„ íƒ)
        st.markdown("### 8) ë‚´ì—­ë³„ ë‹¨ê°€ ì ë¶„í¬(ê³„ì•½ë…„ì›” vs ë‹¨ê°€) - í¬í•¨/ë¯¸í¬í•¨")
        render_boq_scatter(log_for_report, base_result)
    
        # ë‹¤ìš´ë¡œë“œë„ ì¡°ì •ê°’ ê¸°ì¤€
        out_result = st.session_state.get("result_df_adjusted", result_df).copy()
        out_log = st.session_state.get("log_df_edited", log_df).copy()

    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        out_result.to_excel(writer, index=False, sheet_name="boq_with_price")
        out_log.to_excel(writer, index=False, sheet_name="calculation_log")
        rep_sum = st.session_state.get("report_summary_df", pd.DataFrame())
        rep_det = st.session_state.get("report_detail_df", pd.DataFrame())
        if rep_sum is not None and not rep_sum.empty:
            rep_sum.to_excel(writer, index=False, sheet_name="report_summary")
        if rep_det is not None and not rep_det.empty:
            rep_det.to_excel(writer, index=False, sheet_name="report_detail")
    bio.seek(0)
    st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")






























