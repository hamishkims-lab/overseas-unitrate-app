import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer, util

# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"   # GS CI Pantone 300C
CI_TEAL   = "#00BFB3"   # GS CI Pantone 3272C
BG_LIGHT  = "#F6FAFC"

st.markdown(f"""
<style>
  .main {{ background-color: {BG_LIGHT}; }}
  .gs-header {{
     color: white;
     background: linear-gradient(90deg, {CI_BLUE} 0%, {CI_TEAL} 100%);
     padding: 14px 16px;
     border-radius: 10px;
     font-size: 26px; font-weight: 700;
  }}
  /* Select / Multiselect ê³µí†µ ìŠ¤íƒ€ì¼ */
  div[data-baseweb="select"] > div {{
     background-color: white !important;
     border: 1px solid {CI_BLUE} !important;
     border-radius: 6px !important;
  }}
  div[data-baseweb="select"] span {{
     background-color: {CI_TEAL} !important;
     color: white !important;
     border-radius: 4px !important;
     padding: 2px 6px !important;
  }}
  .stDownloadButton button {{
     background-color:{CI_BLUE}; color:white; border-radius:8px; padding:8px 14px; border:0;
  }}
  .stDownloadButton button:hover {{ background-color:{CI_TEAL}; color:white; }}
  .gs-card {{
    background-color: white;
    border: 1px solid #e8eef3;
    border-radius: 10px;
    padding: 12px 14px;
    box-shadow: 0 1px 2px rgba(0,0,0,0.04);
  }}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='gs-header'>ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB</div>", unsafe_allow_html=True)
st.write("")


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def to_year_month_string(x) -> Optional[str]:
    """datetime/str â†’ 'YYYY-MM' ë¬¸ìì—´, ì‹¤íŒ¨ ì‹œ None"""
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None

def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    """YYYY-MM/ YYYYMM / YYYY.MM ë“± â†’ ì›”ì´ˆ timestampë¡œ í†µì¼"""
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()

def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode()); hasher.update(tail.encode())
    return hasher.hexdigest()

def norm_site_code(x) -> str:
    """
    í˜„ì¥ì½”ë“œ ì •ê·œí™”:
    - ê³µë°± ì œê±°
    - 190590.0 ê°™ì€ ì†Œìˆ˜ í‘œí˜„ ì œê±°
    - ìˆ«ì/ë¬¸ì í˜¼ìš© ëŒ€ë¹„
    """
    if x is None:
        return ""
    s = str(x).strip()
    # 190590.0 í˜•íƒœ ì²˜ë¦¬
    if s.endswith(".0"):
        s = s[:-2]
    # í˜¹ì‹œ ë‚¨ì•„ìˆëŠ” ì†Œìˆ˜ì  ì œê±°
    s = s.split(".")[0]
    return s


# =========================
# ë³´ì • ë¡œì§ (CPI/í™˜ìœ¨/ì§€ìˆ˜)
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    """currency(=êµ­ê°€ì½”ë“œ), contract_ym='YYYY-MM' ê¸°ì¤€ ìµœì‹ /ê³„ì•½ CPI ë¹„ìœ¨"""
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now  = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None

def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    """USD ê¸°ì¤€ í™˜ìœ¨í‘œ: USDë‹¹í™˜ìœ¨ â†’ í™˜ìœ¨ë¹„"""
    try:
        usd_from = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        usd_to   = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0

def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(from_currency).upper(), "ì§€ìˆ˜"].values
        f_to   = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(to_currency).upper(), "ì§€ìˆ˜"].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp ì‚¬ìš©)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"

def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))

def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    # normalize for cosine
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index

def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)  # inner product == cosine on normalized
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0

def match_items_faiss(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
    w_str: float,
    w_sem: float,
    top_k_sem: int,
    progress=None,
    prog_text=None,
):
    # ì „ì²˜ë¦¬ + ìœ íš¨ì„± í•„í„°
    work = cost_db.copy()
    work["__ë‚´ì—­_norm"] = work["ë‚´ì—­"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_ê³„ì•½ì›”"] = robust_parse_contract_month(work["ê³„ì•½ë…„ì›”"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_ê³„ì•½ì›”"].notna())].copy()

    # CPI/ì§€ìˆ˜ í‘œì¤€í™”
    price_index = price_index.copy()
    price_index["ë…„ì›”"] = price_index["ë…„ì›”"].apply(to_year_month_string)

    # ì„ë² ë”© & ì¸ë±ìŠ¤
    fp = file_fingerprint(work, ["__ë‚´ì—­_norm","__Unit_norm","í†µí™”","Unit Price","_ê³„ì•½ì›”"])
    embs = compute_or_load_embeddings(work["__ë‚´ì—­_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    results, logs = [], []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"ì‚°ì¶œ ì§„í–‰ë¥ : {i}/{total} í•­ëª© ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i/total)

        boq_item = str(boq_row.get("ë‚´ì—­", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        # ì¿¼ë¦¬ ì„ë² ë”©
        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        # ì˜ë¯¸ í›„ë³´
        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]; sem_scores = D[0]
        else:
            # embsëŠ” numpy float32 (normalize ì™„ë£Œ). util.cos_simì€ torch í…ì„œ ê¸°ë°˜ì´ë¯€ë¡œ
            # ê°„ë‹¨íˆ numpy dotìœ¼ë¡œ cosine(IP) ê³„ì‚°:
            all_sem = np.dot(embs, q[0])  # (N,)
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        # Unit ì¼ì¹˜
        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)

        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ì°¸ê³ ìš©: ë§¤ì¹­ í’ˆì§ˆ ê·¼ê±°)
        hyb = hybrid_scores(boq_text_norm, unit_df["__ë‚´ì—­_norm"], unit_df["__sem"].to_numpy(), w_str, w_sem)
        unit_df["__hyb"] = hyb

        # Threshold ì ìš©
        unit_df = unit_df[unit_df["__hyb"] >= sim_threshold].copy()
        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        # ë³´ì •ë‹¨ê°€ ê³„ì‚° (ë¡œê·¸ì— ë³´ì •ìš”ì†Œ í‘œê¸°)
        adj_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("í†µí™”","")).upper().strip()
            unit_price = float(r.get("Unit Price", 0.0))
            contract_ym = to_year_month_string(r.get("_ê³„ì•½ì›”"))

            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index, c_currency, contract_ym)
            fx_ratio  = get_exchange_rate(exchange, c_currency, target_currency)
            fac_ratio = get_factor_ratio(factor, c_currency, target_currency)

            adj_price = unit_price * cpi_ratio * fx_ratio * fac_ratio

            adj_list.append({
                **r.to_dict(),
                "__adj_price": adj_price,
                "__base_cpi": base_cpi,
                "__latest_cpi": latest_cpi,
                "__latest_ym": latest_ym,
                "__cpi_ratio": cpi_ratio,
                "__fx_ratio": fx_ratio,
                "__fac_ratio": fac_ratio,
                "__sem": r["__sem"],
                "__hyb": r["__hyb"],
            })
        unit_df = pd.DataFrame(adj_list)

        # ê·¹ë‹¨ì¹˜ ì»·
        unit_df = unit_df.sort_values("__adj_price")
        n = len(unit_df)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0
        kept = unit_df.iloc[cut:n-cut] if cut > 0 else unit_df.copy()
        kept_ids = set(kept.index)

        # ì‚°ì¶œê·¼ê±° í…ìŠ¤íŠ¸
        currencies = sorted(kept["í†µí™”"].astype(str).str.upper().unique().tolist())
        reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(kept)}ê°œ ë‚´ì—­ ê·¼ê±°"

        # ì‚°ì¶œ ë¡œê·¸
        for ridx, row in unit_df.iterrows():
            logs.append({
                "BOQ í•­ëª©": boq_item,
                "BOQ Unit": boq_unit,
                "ì‹¤ì ë‚´ì—­": row.get("ë‚´ì—­", None),
                "ì‹¤ì ê³„ì•½ë…„ì›”": to_year_month_string(row.get("_ê³„ì•½ì›”")),
                "ì›ë‹¨ê°€(í˜„ì§€í†µí™”)": row.get("Unit Price", None),
                "ì‹¤ì í†µí™”": row.get("í†µí™”", None),
                "ê³„ì•½CPI": row["__base_cpi"],
                "ìµœì‹ CPI": row["__latest_cpi"],
                "ìµœì‹ CPIë…„ì›”": row["__latest_ym"],
                "CPIë³´ì •": row["__cpi_ratio"],
                "ì ìš©í™˜ìœ¨": row["__fx_ratio"],
                "ê±´ì„¤ì§€ìˆ˜ë³´ì •": row["__fac_ratio"],
                "íƒ€ê²Ÿí†µí™”": target_currency,
                "ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)": row["__adj_price"],
                "í¬í•¨ì—¬ë¶€": "í¬í•¨" if ridx in kept_ids else "ì œì™¸",
            })

        # ìµœì¢…ë‹¨ê°€
        final_price = float(kept["__adj_price"].mean()) if not kept.empty else None

        res_row = dict(boq_row)
        res_row["Final Price"] = f"{final_price:,.2f}" if final_price is not None else None
        res_row["ì‚°ì¶œê·¼ê±°"] = reason_text
        results.append(res_row)

    result_df = pd.DataFrame(results)
    log_df = pd.DataFrame(logs)

    # ë³´ê¸°ìš© í¬ë§·
    if "ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)" in log_df.columns:
        log_df["ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)"] = log_df["ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)"].apply(lambda x: f"{x:,.2f}" if pd.notna(x) else None)

    return result_df, log_df


# =========================
# ë°ì´í„° ë¡œë“œ (Cloud í˜¸í™˜: repo ìƒëŒ€ê²½ë¡œ)
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(
            f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}\n"
            f"GitHub ì €ì¥ì†Œì— data/{filename} íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        )
        st.stop()
    return pd.read_excel(path, engine="openpyxl")

cost_db     = load_excel_from_repo("cost_db.xlsx")
price_index = load_excel_from_repo("price_index.xlsx")
exchange    = load_excel_from_repo("exchange.xlsx")
factor      = load_excel_from_repo("Factor.xlsx") 
project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
feature_master = load_excel_from_repo("feature_master_FID.xlsx") # âœ… ëŒ€ì†Œë¬¸ì ì •í™•íˆ!

# =========================
# Globals (Streamlit rerun ì•ˆì „)
# =========================
auto_sites = None
matched_feature_ids = []

if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []

if "manual_site_codes" not in st.session_state:
    st.session_state["manual_site_codes"] = []  # ì‚¬ìš©ìê°€ ì¶”ê°€ë¡œ ì²´í¬í•œ í˜„ì¥
if "excluded_site_codes" not in st.session_state:
    st.session_state["excluded_site_codes"] = []  # ìë™ í›„ë³´ì—ì„œ ì œì™¸í•œ í˜„ì¥


# =========================
# Sidebar (ìˆœì„œ/ë„ì›€ë§/ìš”êµ¬ì‚¬í•­ ë°˜ì˜)
# =========================
st.sidebar.header("âš™ï¸ ì„¤ì •")
st.sidebar.caption("â‘ ~â‘¥ ìˆœì„œëŒ€ë¡œ ì„¤ì •í•˜ì„¸ìš”.")

# âœ… í˜„ì¥ í•„í„° ì‚¬ìš© ì—¬ë¶€ (êµ­ê°€ í•„í„° ëŒ€ì²´)
use_site_filter = st.sidebar.checkbox(
    "í˜„ì¥ í•„í„° ì‚¬ìš©(ì¶”ì²œ)",
    value=True,
    help="í”„ë¡œì íŠ¸ íŠ¹ì„± ê¸°ë°˜ìœ¼ë¡œ í˜„ì¥ì„ ìë™ ì„ íƒí•˜ê³ , ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€/ì œì™¸í•©ë‹ˆë‹¤."
)

# âœ… (ìˆ¨ê¹€ ì²˜ë¦¬) â‘¡, â‘£ëŠ” UIì— ë…¸ì¶œí•˜ì§€ ì•Šê³  ë‚´ë¶€ ê³ ì •ê°’ ì‚¬ìš©
DEFAULT_W_STR = 0.3
DEFAULT_TOP_K_SEM = 200

w_str = DEFAULT_W_STR
w_sem = 1.0 - w_str
top_k_sem = DEFAULT_TOP_K_SEM

# â‘  ì‹¤ì ë‹¨ê°€ í•„í„°ë§ - êµ­ê°€ (í˜„ì¥ í•„í„° ë¯¸ì‚¬ìš© ì‹œì—ë§Œ)
if not use_site_filter:

    all_currencies = sorted([c for c in cost_db["í†µí™”"].astype(str).str.upper().unique() if c.strip()])
    if "" in cost_db["í†µí™”"].astype(str).unique().tolist():
        all_currencies = all_currencies + [""]

    selected_currencies = st.sidebar.multiselect(
        "â‘  ì‹¤ì ë‹¨ê°€ í•„í„°ë§ - êµ­ê°€",
        options=all_currencies,
        default=all_currencies,
        help="ì‹¤ì êµ­ê°€(í†µí™”)ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¯¸ì„ íƒ ì‹œ ì „ì²´ ì‚¬ìš©."
    )

    # í•„í„° ì ìš©
    if selected_currencies:
        cost_db = cost_db[
            cost_db["í†µí™”"].astype(str).str.upper().isin(
                [s for s in selected_currencies if s != ""] +
                ([] if "" not in selected_currencies else [""])
            )
        ]

# =========================
# ì‚¬ì´ë“œë°”: ì‹¤ì  í˜„ì¥ ì„ íƒ (ìë™ í›„ë³´ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ë™ê¸°í™” + ìˆ˜ë™ ì¶”ê°€/ì œì™¸)
# =========================
selected_site_codes = None

if use_site_filter:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ")

    site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).str.strip()
    site_df = site_df.dropna().drop_duplicates()

    site_df["label"] = site_df["í˜„ì¥ì½”ë“œ"] + " | " + site_df["í˜„ì¥ëª…"]
    all_labels = site_df["label"].sort_values().tolist()
    code_to_label = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["label"]))
    all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()

    auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
    auto_codes = [c for c in auto_codes_raw if c in code_to_label]

    missing_auto = [c for c in auto_codes_raw if c not in code_to_label]
    if missing_auto:
        st.sidebar.warning(f"cost_dbì— ì—†ëŠ” ìë™í›„ë³´ ì½”ë“œ: {missing_auto[:10]}")

    # âœ… ìë™ í›„ë³´ê°€ ë°”ë€” ë•Œ "ê¸°ë³¸ ì„ íƒ"ì„ ë™ê¸°í™”í• ì§€ ì˜µì…˜
    sync_auto = st.sidebar.checkbox("íŠ¹ì„± ë³€ê²½ ì‹œ ìë™ í›„ë³´ë¡œ ì„ íƒ ê°±ì‹ ", value=True)

    # session_stateë¡œ í˜„ì¥ ì„ íƒ ìœ ì§€
    if "selected_site_labels" not in st.session_state:
        # ìµœì´ˆ: ìë™ í›„ë³´ê°€ ìˆìœ¼ë©´ ìë™ í›„ë³´, ì—†ìœ¼ë©´ ì „ì²´
        st.session_state["selected_site_labels"] = [code_to_label[c] for c in (auto_codes if auto_codes else all_codes)]

    if sync_auto:
        # ìë™ í›„ë³´ ê¸°ë°˜ìœ¼ë¡œ ì´ˆê¸°í™”(ë‹¨, ì‚¬ìš©ìê°€ ì œì™¸/ì¶”ê°€í•œ ê±´ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì•„ë˜ì—ì„œ ì¡°ì •)
        base_codes = set(auto_codes) if auto_codes else set(all_codes)
    else:
        # ë™ê¸°í™” ë„ë©´ ê¸°ì¡´ ì„ íƒ ìœ ì§€
        base_codes = set([lab.split(" | ")[0] for lab in st.session_state["selected_site_labels"]])

    # ì‚¬ìš©ìê°€ ë”°ë¡œ ì¶”ê°€/ì œì™¸í•œ ê²ƒ ë°˜ì˜
    excluded = set(st.session_state.get("excluded_site_codes", []))
    manual_add = set(st.session_state.get("manual_site_codes", []))

    final_codes = (base_codes - excluded) | manual_add
    final_labels = [code_to_label[c] for c in all_codes if c in final_codes]

    # ìë™/ê¸°íƒ€ êµ¬ë¶„ í‘œì‹œ
    auto_labels = [code_to_label[c] for c in auto_codes]
    other_labels = [code_to_label[c] for c in all_codes if c not in set(auto_codes)]

    st.sidebar.caption(f"ìë™ í›„ë³´ {len(auto_labels)}ê°œ / ê¸°íƒ€ {len(other_labels)}ê°œ")

    # 1) ìë™ í›„ë³´(ê¸°ë³¸ í¬í•¨, ì œì™¸ ê°€ëŠ¥)
    selected_auto_labels = st.sidebar.multiselect(
        "ìë™ í›„ë³´(ì œì™¸ ê°€ëŠ¥)",
        options=auto_labels,
        default=[lab for lab in auto_labels if lab in final_labels],
        key="selected_auto_labels"
    )
    # ì—¬ê¸°ì„œ ë¹ ì§„ ìë™í›„ë³´ëŠ” excludedë¡œ ì €ì¥
    selected_auto_codes = set([lab.split(" | ")[0] for lab in selected_auto_labels])
    st.session_state["excluded_site_codes"] = [c for c in auto_codes if c not in selected_auto_codes]

    # 2) ê¸°íƒ€ í˜„ì¥(ì¶”ê°€ ê°€ëŠ¥)
    selected_extra_labels = st.sidebar.multiselect(
        "ê¸°íƒ€ í˜„ì¥(ì¶”ê°€ ê°€ëŠ¥)",
        options=other_labels,
        default=[lab for lab in other_labels if lab.split(" | ")[0] in manual_add],
        key="selected_extra_labels"
    )
    st.session_state["manual_site_codes"] = [lab.split(" | ")[0] for lab in selected_extra_labels]

    # ìµœì¢… ì„ íƒ
    selected_site_codes = sorted(list((selected_auto_codes | set(st.session_state["manual_site_codes"]))))

    st.sidebar.caption(f"ìµœì¢… ì„ íƒ í˜„ì¥: {len(selected_site_codes)}ê°œ")

# feature_master(176ê°œ) ê¸°ì¤€ ì˜µì…˜ ìƒì„±
fm = feature_master.copy()
for c in ["íŠ¹ì„±ID","ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]:
    fm[c] = fm[c].astype(str)

# ê° íŠ¹ì„±IDê°€ project_feature_longì— ëª‡ ê°œ í˜„ì¥ìœ¼ë¡œ ë§¤í•‘ë˜ëŠ”ì§€ ê³„ì‚°
site_cnt = (
    project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"]
    .nunique()
    .astype(int)
    .to_dict()
)

fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)

# UIì— ë³´ì—¬ì¤„ ë¼ë²¨ ë§Œë“¤ê¸°
fm["ë¼ë²¨"] = fm.apply(
    lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | {r["Cost Driver Type"]}/{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
    axis=1
)

label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
options = fm["ë¼ë²¨"].tolist()

selected_labels = st.sidebar.multiselect(
    "íŠ¹ì„± ì„ íƒ (176ê°œ ì „ì²´)",
    options=options,
    default=[]
)

selected_feature_ids = [label_to_id[x] for x in selected_labels]

# ì„ íƒëœ íŠ¹ì„±ID â†’ í˜„ì¥ì½”ë“œ í›„ë³´
if selected_feature_ids:
    allowed_sites = (
        project_feature_long[
            project_feature_long["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in selected_feature_ids])
        ]["í˜„ì¥ì½”ë“œ"]
        .astype(str)
        .unique()
        .tolist()
    )
else:
    allowed_sites = None



if allowed_sites is not None:
    st.sidebar.write("í˜„ì¥ì½”ë“œ(ì˜ˆì‹œ):", allowed_sites[:10])

# â‘¡ Threshold
sim_threshold = st.sidebar.slider(
    "â‘¡ Threshold (ì»· ê¸°ì¤€, %)",
    min_value=0, max_value=100, value=60, step=5,
    help="ë§¤ì¹­ ì¸ì • ìµœì†Œ ì ìˆ˜ ê¸°ì¤€ì…ë‹ˆë‹¤."
)

# â‘¢ ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨
cut_ratio = st.sidebar.slider(
    "â‘¢ ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)",
    min_value=0, max_value=30, value=20, step=5,
    help="ë³´ì •ë‹¨ê°€ ë¶„í¬ì˜ ì–‘ëë‹¨ ê·¹ë‹¨ê°’ì„ ì œê±°í•˜ëŠ” ë¹„ìœ¨ì…ë‹ˆë‹¤. í‘œë³¸ ìˆ˜ê°€ 5ê°œ ì´í•˜ì´ë©´ ì ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
) / 100.0

# â‘£ ì‚°ì¶œí†µí™” (Factor.xlsx ê¸°ì¤€) + í™˜ìœ¨/ì§€ìˆ˜ ì¡´ì¬ ê²€ì¦
target_options = sorted(factor["êµ­ê°€"].astype(str).str.upper().unique().tolist())
default_idx = target_options.index("KRW") if "KRW" in target_options else 0
target_currency = st.sidebar.selectbox(
    "â‘£ ì‚°ì¶œí†µí™”",
    options=target_options,
    index=default_idx,
    help="ìµœì¢… ì‚°ì¶œ í†µí™”(êµ­ê°€ ì§€ìˆ˜ ê¸°ì¤€)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤."
)

# =========================
# Validation ê¸°ë°˜ ì¶”ì²œ (Grid Search UI)
# =========================
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š Validation ê¸°ë°˜ ì¶”ì²œ")

def run_grid_search():
    data = {
        "Params": [
            {"top_k": 200, "threshold": 60, "string_weight": 0.3, "semantic_weight": 0.7},
            {"top_k": 300, "threshold": 65, "string_weight": 0.5, "semantic_weight": 0.5},
            {"top_k": 500, "threshold": 70, "string_weight": 0.7, "semantic_weight": 0.3},
        ],
        "Precision": [1.0, 0.85, 0.8],
        "Recall": [1.0, 0.9, 0.7],
        "F1": [1.0, 0.87, 0.74],
    }
    df = pd.DataFrame(data)
    best_idx = df["F1"].idxmax()
    best_params = df.loc[best_idx, "Params"]
    return df, best_params

if st.sidebar.button("ğŸ” Grid Search ì‹¤í–‰"):
    grid_results, best_params = run_grid_search()
    st.session_state["grid_results"] = grid_results
    st.session_state["best_params"] = best_params

if "grid_results" in st.session_state:
    st.sidebar.markdown("**ì¶”ì²œ íŒŒë¼ë¯¸í„° (F1 ìµœê³ ):**")
    st.sidebar.json(st.session_state["best_params"])

    # âœ… â‘¡/â‘£ëŠ” ìˆ¨ê¹€ì´ë¯€ë¡œ 'ì ìš©'ì€ â‘¢(threshold)ë§Œ ë°˜ì˜(í˜¼ë€ ë°©ì§€)
    if st.sidebar.button("â¬‡ï¸ ì¶”ì²œ íŒŒë¼ë¯¸í„° ì ìš©"):
        sel = st.session_state["best_params"]
        sim_threshold = sel["threshold"]
        st.sidebar.success("ì¶”ì²œ íŒŒë¼ë¯¸í„°ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤ âœ… (Thresholdë§Œ ë°˜ì˜)")

missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper()==target_currency].empty
missing_factor   = factor[factor["êµ­ê°€"].astype(str).str.upper()==target_currency].empty
if missing_exchange:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
if missing_factor:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")


# =========================
# ì—…ë¡œë“œ & ì‹¤í–‰
# =========================
with st.container():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    boq_file = st.file_uploader(
        "ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ",
        type=["xlsx"],
        help="BOQëŠ” ìµœì†Œí•œ 'ë‚´ì—­', 'Unit' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ì—…ë¡œë“œ í›„ 'ì‚°ì¶œ ì‹¤í–‰'ì„ í´ë¦­í•˜ì„¸ìš”."
    )
    st.markdown("</div>", unsafe_allow_html=True)

# =========================
# BOQ ì—…ë¡œë“œ ì•„ë˜: íŠ¹ì„± ì„ íƒ(176ê°œ ì „ì²´) + í‚¤ì›Œë“œ í•„í„° + ë‹¤ì¤‘ ì„ íƒ
# =========================
auto_sites = None  # ë§¤ rerunë§ˆë‹¤ ê³„ì‚°
selected_feature_ids = st.session_state["selected_feature_ids"]

if use_site_filter:
    if boq_file is not None:
        st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
        st.markdown("### ğŸ·ï¸ í”„ë¡œì íŠ¸ íŠ¹ì„± ì„ íƒ (176ê°œ ì „ì²´)")

        fm = feature_master.copy()
        cols6 = ["ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]
        for c in ["íŠ¹ì„±ID"] + cols6:
            fm[c] = fm[c].astype(str).fillna("").str.strip()

        # ê° íŠ¹ì„±IDê°€ project_feature_longì— ëª‡ ê°œ í˜„ì¥ìœ¼ë¡œ ë§¤í•‘ë˜ëŠ”ì§€(ì˜µì…˜)
        site_cnt = (
            project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"].nunique().astype(int).to_dict()
        )
        fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)

        fm["ë¼ë²¨"] = fm.apply(
            lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | '
                      f'{r["Cost Driver Type"]}/{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                      f'í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
            axis=1
        )

        # âœ… í‚¤ì›Œë“œë¡œ ëª©ë¡ ìì²´ë¥¼ ì¤„ì´ëŠ” í•„í„°(ì„ íƒì‚¬í•­, ë©€í‹°ì…€ë ‰íŠ¸ ê²€ìƒ‰ê³¼ ë³„ê°œ)
        keyword = st.text_input("íŠ¹ì„± ëª©ë¡ í•„í„°(í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ: DCM, Jet, ì§€ë°˜ê°œëŸ‰, ë„ì‹¬ ...")
        if keyword.strip():
            kw = keyword.strip().lower()
            fm_view = fm[fm["ë¼ë²¨"].str.lower().str.contains(kw, na=False)].copy()
        else:
            fm_view = fm

        options = fm_view["ë¼ë²¨"].tolist()
        label_to_id = dict(zip(fm_view["ë¼ë²¨"], fm_view["íŠ¹ì„±ID"]))

        # âœ… í˜„ì¬ ì„ íƒëœ IDë¥¼ ë¼ë²¨ë¡œ ë³µì›(í•„í„°ë§ìœ¼ë¡œ ë¼ë²¨ì´ ì•ˆ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ masterì—ì„œ ë³µì›)
        master_label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
        master_id_to_label = {}
        for lab, fid in master_label_to_id.items():
            master_id_to_label.setdefault(fid, lab)

        current_selected_labels = [master_id_to_label[fid] for fid in selected_feature_ids if fid in master_id_to_label]

        # âœ… ë©€í‹°ì…€ë ‰íŠ¸ (Streamlit ê¸°ë³¸ ê²€ìƒ‰ ì§€ì›)
        new_selected_labels = st.multiselect(
            "íŠ¹ì„± ì„ íƒ(ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
            options=options,
            default=[lab for lab in current_selected_labels if lab in options]  # í˜„ì¬ í•„í„° í™”ë©´ì— ë³´ì´ëŠ” ê²ƒë§Œ default
        )

        # âœ… â€œí•„í„°ë¡œ ì•ˆ ë³´ì´ëŠ” ê¸°ì¡´ ì„ íƒâ€ë„ ìœ ì§€í•˜ë©´ì„œ í•©ì¹˜ê¸°
        new_ids = [label_to_id[lab] for lab in new_selected_labels]
        # ê¸°ì¡´ ì„ íƒ ì¤‘ ì´ë²ˆ í™”ë©´ì— ì—†ì—ˆë˜ ê²ƒ ìœ ì§€
        kept_ids = [fid for fid in selected_feature_ids if fid in master_id_to_label and master_id_to_label[fid] not in options]
        merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))  # ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€

        st.session_state["selected_feature_ids"] = merged_ids
        selected_feature_ids = merged_ids

        # ì„ íƒëœ íŠ¹ì„± í‘œì‹œ + ì‚­ì œ UI
        st.markdown("#### âœ… ì„ íƒëœ íŠ¹ì„±ID")
        if selected_feature_ids:
            st.write(selected_feature_ids)

            del_ids = st.multiselect("ì œê±°í•  íŠ¹ì„±ID ì„ íƒ", options=selected_feature_ids, default=[])
            c1, c2 = st.columns(2)
            with c1:
                if st.button("ğŸ—‘ï¸ ì„ íƒ ì œê±°"):
                    st.session_state["selected_feature_ids"] = [x for x in selected_feature_ids if x not in del_ids]
            with c2:
                if st.button("ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”"):
                    st.session_state["selected_feature_ids"] = []
        else:
            st.info("ì„ íƒëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… auto_sites ê³„ì‚° (ì„ íƒëœ íŠ¹ì„±ID OR)
        if st.session_state["selected_feature_ids"]:
            auto_sites = (
                project_feature_long[
                    project_feature_long["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in st.session_state["selected_feature_ids"]])
                ]["í˜„ì¥ì½”ë“œ"].astype(str).unique().tolist()
            )
        else:
            auto_sites = []

        st.success(f"ìë™ í›„ë³´ í˜„ì¥: {len(auto_sites)}ê°œ")
        if len(auto_sites) <= 20:
            st.write(auto_sites)

        st.markdown("</div>", unsafe_allow_html=True)
    else:
        st.info("BOQ ì—…ë¡œë“œ í›„ í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰", help="í˜„ì¬ ì„¤ì •ê³¼ ì—…ë¡œë“œí•œ BOQë¡œ ë‹¨ê°€ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤. ì§„í–‰ë¥ ì´ í‘œì‹œë©ë‹ˆë‹¤.")


# =========================
# âœ… í”„ë¡œì íŠ¸ íŠ¹ì„± í•„í„° ì ìš© (í˜„ì¥ì½”ë“œ ê¸°ì¤€)
# =========================
if run_btn:
    if boq_file is None:
        st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif missing_exchange or missing_factor:
        st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # 1) BOQ ë¡œë“œ
        boq = pd.read_excel(boq_file, engine="openpyxl")

        # 2) ìµœì¢… í˜„ì¥ í•„í„° ì ìš© (E)
        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin(
                    [norm_site_code(x) for x in selected_site_codes]
                )
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(
            f"ì‹¤í–‰ìš© cost_db í–‰ìˆ˜: {len(cost_db_run):,} / ì „ì²´ {len(cost_db):,}"
        )

        # ğŸ”´ ì´ ì¤„ì˜ ë“¤ì—¬ì“°ê¸°ê°€ í•µì‹¬
        progress = st.progress(0.0)
        prog_text = st.empty()

        with st.spinner("ì„ë² ë”©/ì¸ë±ìŠ¤ ì¤€ë¹„ ë° ê³„ì‚° ì¤‘..."):
            result_df, log_df = match_items_faiss(
                cost_db=cost_db_run,
                boq=boq,
                price_index=price_index,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
                w_str=w_str,
                w_sem=w_sem,
                top_k_sem=top_k_sem,
                progress=progress,
                prog_text=prog_text,
            )

        progress.progress(1.0)
        prog_text.text("ì‚°ì¶œ ì§„í–‰ë¥ : ì™„ë£Œ")

        st.success("âœ… ì™„ë£Œ! ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")

        # --- íƒ­ ë¶„ë¦¬ ---
        tab1, tab2, tab3 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸", "â„¹ï¸ ë§¤ì¹­ ê·¼ê±° ì•ˆë‚´"])

        # ğŸ“„ BOQ ê²°ê³¼: 'í†µí™”' ì—´ ì™„ì „ ì œê±°
        with tab1:
            if "í†µí™”" in result_df.columns:
                result_df = result_df.drop(columns=["í†µí™”"])
            st.dataframe(result_df, use_container_width=True)

        # ğŸ§¾ ì‚°ì¶œ ë¡œê·¸: ì¡°ê±´ë¶€ ìƒ‰ìƒ + ë‹¤ìš´ë¡œë“œ
        with tab2:
            df_disp = log_df.copy()

            try:
                numeric = df_disp["ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)"].str.replace(",", "", regex=False).astype(float)
            except Exception:
                numeric = pd.to_numeric(df_disp["ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)"], errors="coerce")

            include_mask = df_disp["í¬í•¨ì—¬ë¶€"] == "í¬í•¨"
            avg_map = (
                pd.DataFrame({"BOQ í•­ëª©": df_disp["BOQ í•­ëª©"], "_num": numeric, "í¬í•¨ì—¬ë¶€": include_mask})
                .query("í¬í•¨ì—¬ë¶€ == True")
                .groupby("BOQ í•­ëª©")["_num"].mean()
            )

            def color_by_avg(col):
                styles = []
                for idx, v in enumerate(col):
                    try:
                        if df_disp.iloc[idx]["í¬í•¨ì—¬ë¶€"] != "í¬í•¨":
                            styles.append("")
                            continue
                        avg_val = avg_map.get(df_disp.iloc[idx]["BOQ í•­ëª©"], None)
                        vv = float(str(v).replace(",", "")) if isinstance(v, str) else float(v)
                        if avg_val is None or pd.isna(vv):
                            styles.append("")
                        else:
                            styles.append("color: green" if vv < float(avg_val) else "color: red")
                    except Exception:
                        styles.append("")
                return styles

            if "ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)" in df_disp.columns:
                styled = df_disp.style.apply(color_by_avg, subset=["ìµœì¢…ë‹¨ê°€(ë³´ì •í›„)"])
                st.dataframe(styled, use_container_width=True)
            else:
                st.dataframe(df_disp, use_container_width=True)

            bio = io.BytesIO()
            with pd.ExcelWriter(bio, engine="openpyxl") as writer:
                result_df.to_excel(writer, index=False, sheet_name="boq_with_price")
                log_df.to_excel(writer, index=False, sheet_name="calculation_log")
            bio.seek(0)
            st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")

        # â„¹ï¸ ë§¤ì¹­ ê·¼ê±° ì•ˆë‚´
        with tab3:
            st.markdown("""
**í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜(0-100)**ëŠ” *ë¬¸ìì—´ ìœ ì‚¬ë„*ì™€ *ì˜ë¯¸ ìœ ì‚¬ë„(ì„ë² ë”© ì½”ì‚¬ì¸)*ë¥¼ ê°€ì¤‘ í‰ê· í•œ ê°’ìœ¼ë¡œ,  
BOQ í•­ëª©ê³¼ ì‹¤ì  DB í•­ëª©ì´ ì™œ ë§¤ì¹­ë˜ì—ˆëŠ”ì§€ ì„¤ëª…í•˜ëŠ” ê·¼ê±° ì§€í‘œì…ë‹ˆë‹¤.  
- ë¬¸ìì—´ ìœ ì‚¬ë„: ì² ì/í† í° êµ¬ì„±ì˜ ìœ ì‚¬ì„±  
- ì˜ë¯¸ ìœ ì‚¬ë„: ë¬¸ì¥ì˜ ì˜ë¯¸ì  ê·¼ì ‘ì„±(ì–¸ì–´ëª¨ë¸ ì„ë² ë”© ì‚¬ìš©)  
- ë³¸ ì•±ì—ì„œëŠ” ì‚¬ìš©ì í˜¼ë€ì„ ì¤„ì´ê¸° ìœ„í•´ UIì— ì§€í‘œë¥¼ ìˆ¨ê¸°ê³ , **Threshold=60%** ê¸°ì¤€ìœ¼ë¡œ ìš´ìš©í•©ë‹ˆë‹¤.
            """)

# =========================
# ì„¤ëª… ì„¹ì…˜
# =========================
st.markdown("<br/>", unsafe_allow_html=True)
st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
st.subheader("ğŸ“Œ ë‹¨ê°€ ì‚°ì¶œ ê¸°ì¤€")
st.markdown("""
1. **ì‹¤ì ë‹¨ê°€ í•„í„°ë§**  
   - **êµ­ê°€(í†µí™”)**: ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥, ë¹ˆì¹¸ì€ ëª©ë¡ í•˜ë‹¨ì— í‘œì‹œ  

2. **ë§¤ì¹­ ê¸°ì¤€ (Hybrid Matching)**  
   - ë¬¸ìì—´+ì˜ë¯¸ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜(í•©ê³„=1), **Threshold** ì´ìƒë§Œ ë§¤ì¹­ ì¸ì •  

3. **ë‹¨ê°€ ë³´ì • ê³¼ì •**  
   - ê³„ì•½ì‹œì  ëŒ€ë¹„ ìµœì‹  **CPI ë³´ì •**, **í™˜ìœ¨ ë³€í™˜(USDê¸°ì¤€)**, **ê±´ì„¤ì§€ìˆ˜ ë³´ì •**  

4. **ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ ì ìš©**  
   - ê·¹ë‹¨ê°’ ì œì™¸ í›„ ì”ì—¬ í‘œë³¸ì˜ í‰ê· ì„ **ìµœì¢… ë‹¨ê°€**ë¡œ ì‚°ì •  

5. **ì¶œë ¥ (ì‚°ì¶œí†µí™” ê¸°ì¤€)**  
   - ì‚°ì¶œí†µí™”ë¡œ í™˜ì‚°ëœ BOQë³„ **ìµœì¢… ë‹¨ê°€ + ì‚°ì¶œê·¼ê±° + ë¡œê·¸**  
""")
st.markdown("</div>", unsafe_allow_html=True)



















