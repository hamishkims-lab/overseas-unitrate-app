import re
import io
import json
import hashlib
from pathlib import Path
from typing import Optional

import numpy as np
import pandas as pd
import streamlit as st
from rapidfuzz import fuzz
from sentence_transformers import SentenceTransformer


# ============ FAISS ============
try:
    import faiss  # faiss-cpu
    FAISS_OK = True
except ImportError:
    FAISS_OK = False


# =========================
# CI Theme / Title
# =========================
st.set_page_config(page_title="Overseas Unit Rate App", layout="wide")

CI_BLUE   = "#005EB8"
CI_TEAL   = "#00BFB3"
BG_LIGHT  = "#F6FAFC"

st.markdown(f"""
<style>
  .main {{ background-color: {BG_LIGHT}; }}
  .gs-header {{
     color: white;
     background: linear-gradient(90deg, {CI_BLUE} 0%, {CI_TEAL} 100%);
     padding: 14px 16px;
     border-radius: 10px;
     font-size: 26px; font-weight: 700;
  }}
  div[data-baseweb="select"] > div {{
     background-color: white !important;
     border: 1px solid {CI_BLUE} !important;
     border-radius: 6px !important;
  }}
  div[data-baseweb="select"] span {{
     background-color: {CI_TEAL} !important;
     color: white !important;
     border-radius: 4px !important;
     padding: 2px 6px !important;
  }}
  .stDownloadButton button {{
     background-color:{CI_BLUE}; color:white; border-radius:8px; padding:8px 14px; border:0;
  }}
  .stDownloadButton button:hover {{ background-color:{CI_TEAL}; color:white; }}
  .gs-card {{
    background-color: white;
    border: 1px solid #e8eef3;
    border-radius: 10px;
    padding: 12px 14px;
    box-shadow: 0 1px 2px rgba(0,0,0,0.04);
  }}
</style>
""", unsafe_allow_html=True)

st.markdown("<div class='gs-header'>ğŸ“¦ í•´ì™¸ ì‹¤ì ë‹¨ê°€ DB</div>", unsafe_allow_html=True)
st.write("")


# =========================
# Model (cached)
# =========================
@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()


# =========================
# Utils
# =========================
def norm_text(s: str) -> str:
    s = str(s).lower().strip()
    s = re.sub(r"[^a-z0-9]+", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def to_year_month_string(x) -> Optional[str]:
    try:
        dt = pd.to_datetime(x, errors="coerce")
        if pd.isna(dt):
            s = str(x)
            s2 = re.sub(r"[^0-9]", "", s)[:6]
            dt = pd.to_datetime(s2, format="%Y%m", errors="coerce")
        if pd.isna(dt):
            return None
        return dt.strftime("%Y-%m")
    except Exception:
        return None

def robust_parse_contract_month(series: pd.Series) -> pd.Series:
    dt = pd.to_datetime(series, errors="coerce", infer_datetime_format=True)
    mask = dt.isna()
    if mask.any():
        cleaned = series[mask].astype(str).str.replace(r"[^0-9]", "", regex=True).str.slice(0, 6)
        dt2 = pd.to_datetime(cleaned, format="%Y%m", errors="coerce")
        dt.loc[mask] = dt2
    return dt.dt.to_period("M").dt.to_timestamp()

def file_fingerprint(df: pd.DataFrame, cols: list) -> str:
    hasher = hashlib.md5()
    sample = df[cols].astype(str).agg("|".join, axis=1)
    head = "|".join(sample.head(1000).tolist())
    tail = "|".join(sample.tail(1000).tolist())
    hasher.update(str(df.shape).encode())
    hasher.update(head.encode()); hasher.update(tail.encode())
    return hasher.hexdigest()

def norm_site_code(x) -> str:
    if x is None:
        return ""
    s = str(x).strip()
    s = s.strip('"\''"`")
    if s.endswith(".0"):
        s = s[:-2]
    s = s.split(".")[0].strip()
    s_digits = "".join(ch for ch in s if ch.isdigit())
    if s_digits:
        s = s_digits
    if s.isdigit() and len(s) < 6:
        s = s.zfill(6)
    return s


# =========================
# ë³´ì • ë¡œì§
# =========================
def get_cpi_ratio(price_index: pd.DataFrame, currency: str, contract_ym: str):
    try:
        df = price_index[price_index["êµ­ê°€"].astype(str).str.upper() == str(currency).upper()].copy()
        if df.empty:
            return 1.0, None, None, None
        df["ë…„ì›”_std"] = df["ë…„ì›”"].apply(to_year_month_string)
        latest_ym = df["ë…„ì›”_std"].dropna().max()
        base = df.loc[df["ë…„ì›”_std"] == contract_ym, "Index"].values
        now  = df.loc[df["ë…„ì›”_std"] == latest_ym, "Index"].values
        if len(base) and len(now) and base[0] not in (0, None):
            return float(now[0]) / float(base[0]), float(base[0]), float(now[0]), latest_ym
    except Exception:
        pass
    return 1.0, None, None, None

def get_exchange_rate(exchange: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        usd_from = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(from_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        usd_to   = exchange.loc[exchange["í†µí™”"].astype(str).str.upper()==str(to_currency).upper(), "USDë‹¹í™˜ìœ¨"].values
        if len(usd_from) and len(usd_to) and float(usd_from[0]) != 0:
            return float(usd_to[0]) / float(usd_from[0])
    except Exception:
        pass
    return 1.0

def get_factor_ratio(factor: pd.DataFrame, from_currency: str, to_currency: str) -> float:
    try:
        f_from = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(from_currency).upper(), "ì§€ìˆ˜"].values
        f_to   = factor.loc[factor["êµ­ê°€"].astype(str).str.upper()==str(to_currency).upper(), "ì§€ìˆ˜"].values
        if len(f_from) and len(f_to) and float(f_from[0]) != 0:
            return float(f_to[0]) / float(f_from[0])
    except Exception:
        pass
    return 1.0


# =========================
# Embedding Cache (Cloud í˜¸í™˜: /tmp)
# =========================
CACHE_DIR = Path("/tmp/overseas_unitrate_cache")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

def embeddings_cache_paths(tag: str):
    return CACHE_DIR / f"{tag}.npy", CACHE_DIR / f"{tag}.json"

def save_embeddings(tag: str, embs: np.ndarray, meta: dict):
    npy, meta_json = embeddings_cache_paths(tag)
    np.save(npy, embs.astype("float32"))
    meta_json.write_text(json.dumps(meta, ensure_ascii=False))

def load_embeddings_if_match(tag: str, expected_meta: dict) -> Optional[np.ndarray]:
    npy, meta_json = embeddings_cache_paths(tag)
    if not npy.exists() or not meta_json.exists():
        return None
    try:
        meta = json.loads(meta_json.read_text())
        if meta == expected_meta:
            return np.load(npy)
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def compute_or_load_embeddings(cost_db_norm: pd.Series, tag: str) -> np.ndarray:
    expected = {"model": "all-MiniLM-L6-v2", "tag": tag, "count": int(cost_db_norm.shape[0])}
    cached = load_embeddings_if_match(tag, expected)
    if cached is not None:
        return cached
    texts = cost_db_norm.tolist()
    embs = model.encode(texts, batch_size=256, convert_to_tensor=False, show_progress_bar=True)
    embs = np.asarray(embs, dtype="float32")
    embs = embs / (np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12)
    save_embeddings(tag, embs, expected)
    return embs


# =========================
# FAISS helpers
# =========================
def build_faiss_index(embs: np.ndarray):
    d = embs.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(embs)
    return index

def search_faiss(index, query_vecs: np.ndarray, top_k: int = 200):
    D, I = index.search(query_vecs, top_k)
    return D, I


# =========================
# Matching
# =========================
def hybrid_scores(boq_text_norm: str, db_texts_norm: pd.Series, sem_scores: np.ndarray, w_str: float, w_sem: float) -> np.ndarray:
    sem = np.clip(sem_scores, 0.0, 1.0)
    str_scores = np.array([fuzz.token_sort_ratio(boq_text_norm, s) / 100.0 for s in db_texts_norm.tolist()], dtype="float32")
    return (w_str * str_scores + w_sem * sem) * 100.0

def match_items_faiss(
    cost_db: pd.DataFrame,
    boq: pd.DataFrame,
    price_index: pd.DataFrame,
    exchange: pd.DataFrame,
    factor: pd.DataFrame,
    sim_threshold: float,
    cut_ratio: float,
    target_currency: str,
    w_str: float,
    w_sem: float,
    top_k_sem: int,
    progress=None,
    prog_text=None,
):
    work = cost_db.copy()
    work["__ë‚´ì—­_norm"] = work["ë‚´ì—­"].apply(norm_text)
    work["__Unit_norm"] = work["Unit"].astype(str).str.lower().str.strip()
    work["_ê³„ì•½ì›”"] = robust_parse_contract_month(work["ê³„ì•½ë…„ì›”"])
    work = work[(pd.to_numeric(work["Unit Price"], errors="coerce") > 0) & (work["_ê³„ì•½ì›”"].notna())].copy()

    price_index = price_index.copy()
    price_index["ë…„ì›”"] = price_index["ë…„ì›”"].apply(to_year_month_string)

    fp = file_fingerprint(work, ["__ë‚´ì—­_norm","__Unit_norm","í†µí™”","Unit Price","_ê³„ì•½ì›”"])
    embs = compute_or_load_embeddings(work["__ë‚´ì—­_norm"], tag=f"costdb_{fp}")
    index = build_faiss_index(embs) if FAISS_OK else None

    results, logs = [], []
    total = len(boq) if len(boq) else 1

    for i, (_, boq_row) in enumerate(boq.iterrows(), start=1):
        if prog_text is not None:
            prog_text.text(f"ì‚°ì¶œ ì§„í–‰ë¥ : {i}/{total} í•­ëª© ì²˜ë¦¬ ì¤‘â€¦")
        if progress is not None:
            progress.progress(i/total)

        boq_item = str(boq_row.get("ë‚´ì—­", ""))
        boq_unit = str(boq_row.get("Unit", "")).lower().strip()
        boq_text_norm = norm_text(boq_item)

        q = model.encode([boq_text_norm], batch_size=1, convert_to_tensor=False)
        q = np.asarray(q, dtype="float32")
        q = q / (np.linalg.norm(q, axis=1, keepdims=True) + 1e-12)

        if FAISS_OK:
            D, I = search_faiss(index, q, top_k=top_k_sem)
            cand_idx = I[0]; sem_scores = D[0]
        else:
            all_sem = np.dot(embs, q[0])
            cand_idx = np.argsort(-all_sem)[:top_k_sem]
            sem_scores = all_sem[cand_idx]

        cand_df = work.iloc[cand_idx].copy()
        cand_df["__sem"] = sem_scores

        unit_df = cand_df[cand_df["__Unit_norm"] == boq_unit].reset_index(drop=True)
        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        hyb = hybrid_scores(boq_text_norm, unit_df["__ë‚´ì—­_norm"], unit_df["__sem"].to_numpy(), w_str, w_sem)
        unit_df["__hyb"] = hyb

        unit_df = unit_df[unit_df["__hyb"] >= sim_threshold].copy()
        if unit_df.empty:
            res_row = dict(boq_row)
            res_row["Final Price"] = None
            res_row["ì‚°ì¶œê·¼ê±°"] = "ë§¤ì¹­ ì—†ìŒ"
            results.append(res_row)
            continue

        adj_list = []
        for _, r in unit_df.iterrows():
            c_currency = str(r.get("í†µí™”","")).upper().strip()
            unit_price = float(r.get("Unit Price", 0.0))
            contract_ym = to_year_month_string(r.get("_ê³„ì•½ì›”"))

            cpi_ratio, base_cpi, latest_cpi, latest_ym = get_cpi_ratio(price_index, c_currency, contract_ym)
            fx_ratio  = get_exchange_rate(exchange, c_currency, target_currency)
            fac_ratio = get_factor_ratio(factor, c_currency, target_currency)

            adj_price = unit_price * cpi_ratio * fx_ratio * fac_ratio

            adj_list.append({
                **r.to_dict(),
                "__adj_price": adj_price,
                "__base_cpi": base_cpi,
                "__latest_cpi": latest_cpi,
                "__latest_ym": latest_ym,
                "__cpi_ratio": cpi_ratio,
                "__fx_ratio": fx_ratio,
                "__fac_ratio": fac_ratio,
                "__hyb": r["__hyb"],
            })
        unit_df = pd.DataFrame(adj_list)

        # -------------------------
        # (A) ì»· ê³„ì‚° + Include ê¸°ë³¸ê°’ ì§€ì •
        # -------------------------
        unit_df = unit_df.sort_values("__adj_price").reset_index(drop=True)
        n = len(unit_df)
        cut = max(0, int(n * cut_ratio)) if n > 5 else 0

        # ì»· ì ìš© í›„ ë‚¨ê¸¸ ì¸ë±ìŠ¤ ë²”ìœ„
        if cut > 0:
            keep_mask = np.zeros(n, dtype=bool)
            keep_mask[cut:n-cut] = True
        else:
            keep_mask = np.ones(n, dtype=bool)

        unit_df["Include"] = keep_mask  # âœ… ì‚¬ìš©ìê°€ logì—ì„œ ìˆ˜ì •í•  ì»¬ëŸ¼
        unit_df["DefaultInclude"] = keep_mask  # ì°¸ê³ ìš©(ì›ë˜ ê¸°ë³¸ê°’)

        # -------------------------
        # (B) ì‚°ì¶œë¡œê·¸(í›„ë³´í–‰ ë‹¨ìœ„) ëˆ„ì 
        # -------------------------
        boq_id = int(i)  # 1ë¶€í„° ì¦ê°€ (loopì˜ i ì‚¬ìš©)
        log_cols = [
            # BOQ ë©”íƒ€
            "BOQ_ID",
            "BOQ_ë‚´ì—­",
            "BOQ_Unit",

            # í›„ë³´ í•µì‹¬
            "Include",
            "DefaultInclude",
            "ê³µì¢…ì½”ë“œ",
            "ê³µì¢…ëª…",
            "ë‚´ì—­",
            "Unit",
            "Unit Price",
            "í†µí™”",
            "ê³„ì•½ë…„ì›”",
            "í˜„ì¥ì½”ë“œ",
            "í˜„ì¥ëª…",
            "í˜‘ë ¥ì‚¬ì½”ë“œ",
            "í˜‘ë ¥ì‚¬ëª…",

            # ì ìˆ˜/ë³´ì •
            "__hyb",
            "__adj_price",
            "ì‚°ì¶œí†µí™”",
            "__cpi_ratio",
            "__fx_ratio",
            "__fac_ratio",
            "__latest_ym",
        ]

        tmp = unit_df.copy()
        tmp["BOQ_ID"] = boq_id
        tmp["BOQ_ë‚´ì—­"] = boq_item
        tmp["BOQ_Unit"] = boq_unit
        tmp["ì‚°ì¶œí†µí™”"] = target_currency

        # ì—†ì„ ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ ëŒ€ë¹„(ì•ˆì „)
        for c in log_cols:
            if c not in tmp.columns:
                tmp[c] = None

        logs.extend(tmp[log_cols].to_dict("records"))

        # -------------------------
        # (C) Include=True ê¸°ì¤€ìœ¼ë¡œ Final Price ê³„ì‚° + ê³µì¢… ë¶„í¬(Aì•ˆ)
        # -------------------------
        inc = unit_df[unit_df["Include"] == True].copy()

        if inc.empty:
            final_price = None
            reason_text = "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)"
            top_work = ""
        else:
            final_price = float(inc["__adj_price"].mean())

            currencies = sorted(inc["í†µí™”"].astype(str).str.upper().unique().tolist())
            reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(inc)}ê°œ ë‚´ì—­ ê·¼ê±°"

            # âœ… Aì•ˆ: í›„ë³´ ê³µì¢…ì½”ë“œ ìµœë¹ˆê°’(Top1) í‘œì‹œ
            vc = inc["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(inc)})" if top_code else ""

        res_row = dict(boq_row)
        res_row["BOQ_ID"] = boq_id
        res_row["Final Price"] = f"{final_price:,.2f}" if final_price is not None else None
        res_row["ì‚°ì¶œê·¼ê±°"] = reason_text
        res_row["ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] = top_work
        results.append(res_row)

    return pd.DataFrame(results), pd.DataFrame(logs)


# =========================
# ë°ì´í„° ë¡œë“œ
# =========================
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def load_excel_from_repo(filename: str) -> pd.DataFrame:
    path = DATA_DIR / filename
    if not path.exists():
        st.error(f"í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path.as_posix()}")
        st.stop()
    return pd.read_excel(path, engine="openpyxl")

cost_db     = load_excel_from_repo("cost_db.xlsx")
price_index = load_excel_from_repo("price_index.xlsx")
exchange    = load_excel_from_repo("exchange.xlsx")
factor      = load_excel_from_repo("Factor.xlsx")
project_feature_long = load_excel_from_repo("project_feature_long.xlsx")
feature_master = load_excel_from_repo("feature_master_FID.xlsx")


# =========================
# Session init
# =========================
if "selected_feature_ids" not in st.session_state:
    st.session_state["selected_feature_ids"] = []
if "auto_sites" not in st.session_state:
    st.session_state["auto_sites"] = []


# =========================
# Sidebar: ì„¤ì •
# =========================
st.sidebar.header("âš™ï¸ ì„¤ì •")
st.sidebar.caption("â‘ ~â‘¥ ìˆœì„œëŒ€ë¡œ ì„¤ì •í•˜ì„¸ìš”.")

use_site_filter = st.sidebar.checkbox(
    "í˜„ì¥ í•„í„° ì‚¬ìš©(ì¶”ì²œ)",
    value=True
)

DEFAULT_W_STR = 0.3
DEFAULT_TOP_K_SEM = 200
w_str = DEFAULT_W_STR
w_sem = 1.0 - w_str
top_k_sem = DEFAULT_TOP_K_SEM


# =========================
# (1) BOQ ì—…ë¡œë“œ (ë¨¼ì €!)
# =========================
with st.container():
    st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
    boq_file = st.file_uploader("ğŸ“¤ BOQ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
    st.markdown("</div>", unsafe_allow_html=True)


# =========================
# (2) ë©”ì¸: BOQ ì—…ë¡œë“œ ì•„ë˜ íŠ¹ì„± ì„ íƒ UI
# =========================
auto_sites = []

if use_site_filter:
    if boq_file is not None:
        st.markdown("<div class='gs-card'>", unsafe_allow_html=True)
        st.markdown("### ğŸ·ï¸ í”„ë¡œì íŠ¸ íŠ¹ì„± ì„ íƒ (176ê°œ ì „ì²´)")

        fm = feature_master.copy()
        cols6 = ["ëŒ€ê³µì¢…","ì¤‘ê³µì¢…","ì†Œê³µì¢…","Cost Driver Type","Cost Driver Method","Cost Driver Condition"]
        for c in ["íŠ¹ì„±ID"] + cols6:
            fm[c] = fm[c].astype(str).fillna("").str.strip()

        site_cnt = project_feature_long.groupby("íŠ¹ì„±ID")["í˜„ì¥ì½”ë“œ"].nunique().astype(int).to_dict()
        fm["í˜„ì¥ìˆ˜"] = fm["íŠ¹ì„±ID"].map(site_cnt).fillna(0).astype(int)

        fm["ë¼ë²¨"] = fm.apply(
            lambda r: f'{r["íŠ¹ì„±ID"]} | {r["ëŒ€ê³µì¢…"]}/{r["ì¤‘ê³µì¢…"]}/{r["ì†Œê³µì¢…"]} | '
                      f'{r["Cost Driver Type"]}/{r["Cost Driver Method"]}/{r["Cost Driver Condition"]} | '
                      f'í˜„ì¥ {r["í˜„ì¥ìˆ˜"]}ê°œ',
            axis=1
        )

        keyword = st.text_input("íŠ¹ì„± ëª©ë¡ í•„í„°(í‚¤ì›Œë“œ)", value="", placeholder="ì˜ˆ: DCM, Jet, ì§€ë°˜ê°œëŸ‰, ë„ì‹¬ ...")
        fm_view = fm
        if keyword.strip():
            kw = keyword.strip().lower()
            fm_view = fm[fm["ë¼ë²¨"].str.lower().str.contains(kw, na=False)].copy()

        options = fm_view["ë¼ë²¨"].tolist()
        label_to_id = dict(zip(fm_view["ë¼ë²¨"], fm_view["íŠ¹ì„±ID"]))

        # ê¸°ì¡´ ì„ íƒ ë³µì›(í•„í„°ë§ ì‹œì—ë„ ìœ ì§€)
        master_label_to_id = dict(zip(fm["ë¼ë²¨"], fm["íŠ¹ì„±ID"]))
        master_id_to_label = {}
        for lab, fid in master_label_to_id.items():
            master_id_to_label.setdefault(fid, lab)

        current_selected_ids = st.session_state["selected_feature_ids"]
        current_labels = [master_id_to_label[fid] for fid in current_selected_ids if fid in master_id_to_label]

        new_selected_labels = st.multiselect(
            "íŠ¹ì„± ì„ íƒ(ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
            options=options,
            default=[lab for lab in current_labels if lab in options]
        )

        new_ids = [label_to_id[lab] for lab in new_selected_labels]
        kept_ids = [fid for fid in current_selected_ids if (fid in master_id_to_label and master_id_to_label[fid] not in options)]
        merged_ids = sorted(list(dict.fromkeys(kept_ids + new_ids)))

        st.session_state["selected_feature_ids"] = merged_ids

        st.markdown("#### âœ… ì„ íƒëœ íŠ¹ì„±ID")
        if merged_ids:
            st.write(merged_ids)
            del_ids = st.multiselect("ì œê±°í•  íŠ¹ì„±ID ì„ íƒ", options=merged_ids, default=[])
            c1, c2 = st.columns(2)
            with c1:
                if st.button("ğŸ—‘ï¸ ì„ íƒ ì œê±°"):
                    st.session_state["selected_feature_ids"] = [x for x in merged_ids if x not in del_ids]
            with c2:
                if st.button("ğŸ§¹ ì „ì²´ ì´ˆê¸°í™”"):
                    st.session_state["selected_feature_ids"] = []
        else:
            st.info("ì„ íƒëœ íŠ¹ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")

        # auto_sites ê³„ì‚°
        if st.session_state["selected_feature_ids"]:
            auto_sites = (
                project_feature_long[
                    project_feature_long["íŠ¹ì„±ID"].astype(str).isin([str(x) for x in st.session_state["selected_feature_ids"]])
                ]["í˜„ì¥ì½”ë“œ"].astype(str).unique().tolist()
            )
        else:
            auto_sites = []

        st.session_state["auto_sites"] = auto_sites

        # =========================
        # âœ… auto_sites ë³€ê²½ ì‹œ: ì‚¬ì´ë“œë°” ì„ íƒ UI ê°•ì œ ê°±ì‹  (ì•ˆì „ ë²„ì „)
        # =========================
        # 1) í‘œì¤€í™” + ì •ë ¬(ìˆœì„œ ì•ˆì •í™”)
        new_auto_sites = sorted({
            norm_site_code(x)
            for x in (auto_sites or [])
            if norm_site_code(x)
        })

        # 2) ì´ì „ ê°’(í‘œì¤€í™” + ì •ë ¬)
        old_auto_sites = sorted({
            norm_site_code(x)
            for x in (st.session_state.get("auto_sites", []) or [])
            if norm_site_code(x)
        })

        # 3) ë³€ê²½ëœ ê²½ìš°ì—ë§Œ session ì—…ë°ì´íŠ¸ + ì‚¬ì´ë“œë°” multiselect key ì œê±° + rerun 1íšŒ
        if new_auto_sites != old_auto_sites:
            st.session_state["auto_sites"] = new_auto_sites

            # âœ… ì‚¬ì´ë“œë°” multiselect keyë§Œ ì œê±° (default ê°±ì‹  ëª©ì )
            for k in ["selected_auto_labels", "selected_extra_labels"]:
                if k in st.session_state:
                    del st.session_state[k]

            st.rerun()
        else:
            st.session_state["auto_sites"] = new_auto_sites

        st.success(f"ìë™ í›„ë³´ í˜„ì¥: {len(new_auto_sites)}ê°œ")

        if len(new_auto_sites) <= 30:
            st.write(new_auto_sites)

        st.markdown("</div>", unsafe_allow_html=True)
    else:
        st.info("BOQ ì—…ë¡œë“œ í›„ í”„ë¡œì íŠ¸ íŠ¹ì„±ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# =========================
# (3) ì‚¬ì´ë“œë°”: ì‹¤ì  í˜„ì¥ ì„ íƒ (auto_sitesê°€ sessionì— ì €ì¥ëœ ì´í›„ì—!)
# =========================
selected_site_codes = None

if use_site_filter:
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ—ï¸ ì‹¤ì  í˜„ì¥ ì„ íƒ")

    # âœ… (ì„ íƒ) ë””ë²„ê·¸ ì´ˆê¸°í™” ë²„íŠ¼: ëˆ„ë¥´ë©´ ìƒíƒœë§Œ ì§€ìš°ê³  rerun
    if st.sidebar.button("ğŸ§¹ ê°•ì œ ì´ˆê¸°í™”(ë””ë²„ê·¸)"):
        for k in ["selected_auto_labels", "selected_extra_labels", "auto_sites", "selected_feature_ids"]:
            if k in st.session_state:
                del st.session_state[k]
        st.rerun()

    # âœ… í•­ìƒ auto_sitesë¥¼ ì½ê³  UIë¥¼ ê·¸ë ¤ì•¼ í•¨ (ë²„íŠ¼ if ë°–!)
    auto_sites = st.session_state.get("auto_sites", [])

    # 1) cost_dbì—ì„œ ì „ì²´ í˜„ì¥ ëª©ë¡ ë§Œë“¤ê¸°
    site_df = cost_db[["í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…"]].copy()
    site_df = site_df.dropna(subset=["í˜„ì¥ì½”ë“œ"])

    site_df["í˜„ì¥ì½”ë“œ"] = site_df["í˜„ì¥ì½”ë“œ"].apply(norm_site_code)
    site_df["í˜„ì¥ëª…"] = site_df["í˜„ì¥ëª…"].astype(str).fillna("").str.strip()
    site_df.loc[site_df["í˜„ì¥ëª…"].isin(["", "nan", "None"]), "í˜„ì¥ëª…"] = "(í˜„ì¥ëª…ì—†ìŒ)"

    site_df = site_df.drop_duplicates(subset=["í˜„ì¥ì½”ë“œ"])
    site_df["label"] = site_df["í˜„ì¥ì½”ë“œ"] + " | " + site_df["í˜„ì¥ëª…"]

    all_codes = site_df["í˜„ì¥ì½”ë“œ"].tolist()
    code_to_label = dict(zip(site_df["í˜„ì¥ì½”ë“œ"], site_df["label"]))

    # 2) auto_sites -> auto_codes (ì¡´ì¬í•˜ëŠ” ì½”ë“œë§Œ)
    auto_codes_raw = [norm_site_code(x) for x in (auto_sites or [])]
    auto_codes = [c for c in auto_codes_raw if c in code_to_label]

    auto_labels = [code_to_label[c] for c in auto_codes]
    other_labels = [code_to_label[c] for c in all_codes if c not in set(auto_codes)]

    st.sidebar.caption(f"ìë™ í›„ë³´ {len(auto_labels)}ê°œ / ê¸°íƒ€ {len(other_labels)}ê°œ")

    # =========================
    # âœ… auto í›„ë³´ê°€ ë°”ë€Œë©´: ì‚¬ì´ë“œë°” ìë™ í›„ë³´ë¥¼ "ì¦‰ì‹œ ì „ì²´ ì„ íƒ" ìƒíƒœë¡œ ì„¸íŒ…
    #    (ì‚¬ìš©ìëŠ” ì²´í¬ í•´ì œë¡œ ì œì™¸ ê°€ëŠ¥)
    # =========================
    auto_sig = "|".join(auto_labels)  # auto í›„ë³´ê°€ ë‹¬ë¼ì§€ë©´ ì‹œê·¸ë‹ˆì²˜ë„ ë‹¬ë¼ì§

    # 1) auto í›„ë³´ê°€ ë°”ë€ ìµœì´ˆ 1íšŒì—ë§Œ 'ì „ì²´ ì„ íƒ'ìœ¼ë¡œ ì´ˆê¸°í™”
    if st.session_state.get("_auto_sig") != auto_sig:
        st.session_state["_auto_sig"] = auto_sig
        st.session_state["selected_auto_labels"] = list(auto_labels)

    # 2) í‚¤ê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´(ìµœì´ˆ ì§„ì… ë“±) ê¸°ë³¸ê°’ ì„¸íŒ…
    if "selected_auto_labels" not in st.session_state:
        st.session_state["selected_auto_labels"] = list(auto_labels)
    if "selected_extra_labels" not in st.session_state:
        st.session_state["selected_extra_labels"] = []

    # 3) defaultë¥¼ ì“°ì§€ ë§ê³  session_state ê°’ìœ¼ë¡œ ë Œë”ë§
    selected_auto_labels = st.sidebar.multiselect(
        "ìë™ í›„ë³´(ì œì™¸ ê°€ëŠ¥)",
        options=auto_labels,
        key="selected_auto_labels",
    )
    selected_auto_codes = [x.split(" | ")[0] for x in selected_auto_labels]

    selected_extra_labels = st.sidebar.multiselect(
        "ê¸°íƒ€ í˜„ì¥(ì¶”ê°€ ê°€ëŠ¥)",
        options=other_labels,
        key="selected_extra_labels",
    )
    selected_extra_codes = [x.split(" | ")[0] for x in selected_extra_labels]

    selected_site_codes = sorted(set(selected_auto_codes + selected_extra_codes))
    st.sidebar.caption(f"ìµœì¢… ì„ íƒ í˜„ì¥: {len(selected_site_codes)}ê°œ")


# =========================
# ê¸°íƒ€ ìŠ¬ë¼ì´ë”/í†µí™” ì„ íƒ
# =========================
sim_threshold = st.sidebar.slider("â‘¡ Threshold (ì»· ê¸°ì¤€, %)", 0, 100, 60, 5)
cut_ratio = st.sidebar.slider("â‘¢ ìƒ/í•˜ìœ„ ì»· ë¹„ìœ¨ (%)", 0, 30, 20, 5) / 100.0

target_options = sorted(factor["êµ­ê°€"].astype(str).str.upper().unique().tolist())
default_idx = target_options.index("KRW") if "KRW" in target_options else 0
target_currency = st.sidebar.selectbox("â‘£ ì‚°ì¶œí†µí™”", options=target_options, index=default_idx)

missing_exchange = exchange[exchange["í†µí™”"].astype(str).str.upper()==target_currency].empty
missing_factor   = factor[factor["êµ­ê°€"].astype(str).str.upper()==target_currency].empty
if missing_exchange:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ í™˜ìœ¨ ì •ë³´ê°€ exchange.xlsxì— ì—†ìŠµë‹ˆë‹¤.")
if missing_factor:
    st.sidebar.error(f"ì„ íƒí•œ ì‚°ì¶œí†µí™” '{target_currency}'ì— ëŒ€í•œ ì§€ìˆ˜ ì •ë³´ê°€ Factor.xlsxì— ì—†ìŠµë‹ˆë‹¤.")


# =========================
# Run ë²„íŠ¼ (ê³„ì‚°ì€ ë²„íŠ¼ì—ì„œë§Œ, í™”ë©´ì€ session_state ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ)
# =========================
run_btn = st.sidebar.button("ğŸš€ ì‚°ì¶œ ì‹¤í–‰")

# 1) ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œë§Œ ê³„ì‚° ìˆ˜í–‰ + session_state ì €ì¥
if run_btn:
    if boq_file is None:
        st.warning("BOQ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    elif missing_exchange or missing_factor:
        st.error("ì‚°ì¶œí†µí™”ì— í•„ìš”í•œ í™˜ìœ¨/ì§€ìˆ˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        boq = pd.read_excel(boq_file, engine="openpyxl")

        if use_site_filter and selected_site_codes is not None:
            cost_db_run = cost_db[
                cost_db["í˜„ì¥ì½”ë“œ"].apply(norm_site_code).isin([norm_site_code(x) for x in selected_site_codes])
            ].copy()
        else:
            cost_db_run = cost_db.copy()

        st.sidebar.caption(f"ì‹¤í–‰ìš© cost_db í–‰ìˆ˜: {len(cost_db_run):,} / ì „ì²´ {len(cost_db):,}")

        progress = st.progress(0.0)
        prog_text = st.empty()

        with st.spinner("ì„ë² ë”©/ì¸ë±ìŠ¤ ì¤€ë¹„ ë° ê³„ì‚° ì¤‘..."):
            result_df, log_df = match_items_faiss(
                cost_db=cost_db_run,
                boq=boq,
                price_index=price_index,
                exchange=exchange,
                factor=factor,
                sim_threshold=sim_threshold,
                cut_ratio=cut_ratio,
                target_currency=target_currency,
                w_str=w_str,
                w_sem=w_sem,
                top_k_sem=top_k_sem,
                progress=progress,
                prog_text=prog_text,
            )

        progress.progress(1.0)
        prog_text.text("ì‚°ì¶œ ì§„í–‰ë¥ : ì™„ë£Œ")
        st.success("âœ… ì™„ë£Œ! ê²°ê³¼ í™•ì¸ ë° ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥")

        # âœ… ê³„ì‚° ê²°ê³¼ë¥¼ session_stateì— ì €ì¥ (rerun ë˜ì–´ë„ ìœ ì§€)
        st.session_state["boq_df"] = boq
        st.session_state["result_df_base"] = result_df.copy()
        st.session_state["log_df_base"] = log_df.copy()
        st.session_state["has_results"] = True

        # í¸ì§‘ë³¸ì´ ìˆìœ¼ë©´ ìµœì‹  ê³„ì‚° ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì…‹(ì›í•˜ë©´ ì´ ì¤„ì€ ì§€ì›Œë„ ë¨)
        st.session_state["log_df_edited"] = log_df.copy()
        st.session_state.pop("result_df_adjusted", None)

# 2) ë²„íŠ¼ì„ ì•ˆ ëˆŒëŸ¬ë„, ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ ê²°ê³¼/ë¡œê·¸ UIë¥¼ ë³´ì—¬ì¤Œ
if st.session_state.get("has_results", False):
    boq = st.session_state["boq_df"]
    result_df = st.session_state["result_df_base"]
    log_df = st.session_state["log_df_base"]

    # -------------------------
    # ë¡œê·¸ Include ê¸°ì¤€ìœ¼ë¡œ ê²°ê³¼ ì¬ê³„ì‚° í•¨ìˆ˜
    # -------------------------
    def recompute_result_from_log(edited_log: pd.DataFrame) -> pd.DataFrame:
        base = st.session_state["result_df_base"].copy()

        out_prices = []
        for boq_id, g in edited_log.groupby("BOQ_ID"):
            g2 = g[g["Include"] == True].copy()
            if g2.empty:
                out_prices.append((int(boq_id), None, "ë§¤ì¹­ í›„ë³´ ì—†ìŒ(ë˜ëŠ” ì „ë¶€ ì œì™¸)", ""))
                continue

            final_price = float(pd.to_numeric(g2["__adj_price"], errors="coerce").mean())

            currencies = sorted(g2["í†µí™”"].astype(str).str.upper().unique().tolist())
            reason_text = f"{len(currencies)}ê°œêµ­({', '.join(currencies)}) {len(g2)}ê°œ ë‚´ì—­ ê·¼ê±°"

            vc = g2["ê³µì¢…ì½”ë“œ"].astype(str).value_counts()
            top_code = vc.index[0] if len(vc) else ""
            top_cnt = int(vc.iloc[0]) if len(vc) else 0
            top_work = f"{top_code} ({top_cnt}/{len(g2)})" if top_code else ""

            out_prices.append((int(boq_id), f"{final_price:,.2f}", reason_text, top_work))

        upd = pd.DataFrame(out_prices, columns=["BOQ_ID", "Final Price", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"])

        base = base.drop(columns=[c for c in ["Final Price", "ì‚°ì¶œê·¼ê±°", "ê·¼ê±°ê³µì¢…(ìµœë¹ˆ)"] if c in base.columns], errors="ignore")
        base = base.merge(upd, on="BOQ_ID", how="left")
        return base

    tab1, tab2 = st.tabs(["ğŸ“„ BOQ ê²°ê³¼", "ğŸ§¾ ì‚°ì¶œ ë¡œê·¸(í¸ì§‘ ê°€ëŠ¥)"])

    with tab2:
        st.caption("âœ… ì²´í¬ í•´ì œí•˜ë©´ í‰ê· ë‹¨ê°€ ì‚°ì¶œì—ì„œ ì œì™¸ë©ë‹ˆë‹¤. ì²´í¬í•˜ë©´ í¬í•¨ë©ë‹ˆë‹¤.")

        if "log_df_edited" not in st.session_state:
            st.session_state["log_df_edited"] = log_df.copy()

        log_all = st.session_state["log_df_edited"]

        # âœ… BOQ ì„ íƒ ì˜µì…˜ì„ "ID | ë‚´ì—­" í˜•íƒœë¡œ ë³´ê¸° ì¢‹ê²Œ
        boq_ids = sorted(log_all["BOQ_ID"].dropna().astype(int).unique().tolist())

        # result_df_baseì— BOQ_IDê°€ ìˆê³  BOQ ì›ë¬¸ ë‚´ì—­ ì»¬ëŸ¼(ì˜ˆ: 'ë‚´ì—­')ì´ ìˆë‹¤ê³  ê°€ì •
        base_for_label = st.session_state["result_df_base"].copy()
        # BOQ ì› ë‚´ì—­ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë©´ ì—¬ê¸°ë§Œ ë°”ê¿”ì£¼ì„¸ìš”.
        boq_text_col = "ë‚´ì—­" if "ë‚´ì—­" in base_for_label.columns else "BOQ_ë‚´ì—­"

        id_to_text = (
            base_for_label.dropna(subset=["BOQ_ID"])
            .assign(BOQ_ID=lambda d: d["BOQ_ID"].astype(int))
            .set_index("BOQ_ID")[boq_text_col]
            .astype(str)
            .to_dict()
        )

        def fmt_boq_id(x: int) -> str:
            t = id_to_text.get(int(x), "")
            t = (t[:60] + "â€¦") if len(t) > 60 else t
            return f"{int(x)} | {t}"

        sel_id = st.selectbox(
            "í¸ì§‘í•  BOQ ì„ íƒ",
            options=boq_ids,
            format_func=fmt_boq_id,
            key="sel_boq_id",
        )

        # âœ… ì„ íƒëœ BOQ í›„ë³´ë§Œ
        log_view_full = log_all[log_all["BOQ_ID"].astype(int) == int(sel_id)].copy()

        # -------------------------
        # âœ… í™”ë©´ í‘œì‹œìš© ì»¬ëŸ¼ êµ¬ì„±/ìˆœì„œ (BOQì •ë³´ëŠ” ìˆ¨ê¹€)
        # -------------------------
        display_cols = [
            "Include", "DefaultInclude",
            "ë‚´ì—­", "Unit",
            "Unit Price", "í†µí™”",
            "__adj_price", "ì‚°ì¶œí†µí™”",
            "__cpi_ratio", "__fx_ratio", "__fac_ratio", "__latest_ym",
            "__hyb",
            "ê³µì¢…ì½”ë“œ", "ê³µì¢…ëª…",
            "í˜„ì¥ì½”ë“œ", "í˜„ì¥ëª…",
            "í˜‘ë ¥ì‚¬ì½”ë“œ", "í˜‘ë ¥ì‚¬ëª…",
        ]

        # ì—†ëŠ” ì»¬ëŸ¼ ëŒ€ë¹„(ì•ˆì „)
        for c in display_cols:
            if c not in log_view_full.columns:
                log_view_full[c] = None

        log_view = log_view_full[display_cols].copy()

        # âœ… ë‚´ì—­ í­ ë„“íˆê¸° + ë¼ë²¨ ë°”ê¾¸ê¸°(ê°€ë…ì„±)
        edited_view = st.data_editor(
            log_view,
            use_container_width=True,
            hide_index=True,
            column_config={
                "Include": st.column_config.CheckboxColumn("í¬í•¨(í‰ê·  ë°˜ì˜)", help="ì²´í¬ í•´ì œí•˜ë©´ í‰ê· ë‹¨ê°€ ì‚°ì¶œì—ì„œ ì œì™¸"),
                "DefaultInclude": st.column_config.CheckboxColumn("ê¸°ë³¸í¬í•¨", help="ì´ˆê¸° ìë™ í¬í•¨ ì—¬ë¶€(ì»· ë¡œì§ ê²°ê³¼)"),

                "ë‚´ì—­": st.column_config.TextColumn("ë‚´ì—­", width="large"),
                "Unit": st.column_config.TextColumn("Unit"),

                "Unit Price": st.column_config.NumberColumn("ì›ë‹¨ê°€(Unit Price)", format="%.4f"),
                "í†µí™”": st.column_config.TextColumn("ì›í†µí™”"),

                "__adj_price": st.column_config.NumberColumn("ì‚°ì¶œë‹¨ê°€(ë³´ì •í›„)", format="%.4f"),
                "ì‚°ì¶œí†µí™”": st.column_config.TextColumn("ì‚°ì¶œí†µí™”"),

                "__cpi_ratio": st.column_config.NumberColumn("CPI ë³´ì •", format="%.6f"),
                "__fx_ratio": st.column_config.NumberColumn("í™˜ìœ¨ ë³´ì •", format="%.6f"),
                "__fac_ratio": st.column_config.NumberColumn("Factor ë³´ì •", format="%.6f"),
                "__latest_ym": st.column_config.TextColumn("CPI ìµœì‹ ì›”"),

                "__hyb": st.column_config.NumberColumn("ìœ ì‚¬ë„ì ìˆ˜", format="%.2f"),

                "ê³µì¢…ì½”ë“œ": st.column_config.TextColumn("ê³µì¢…ì½”ë“œ"),
                "ê³µì¢…ëª…": st.column_config.TextColumn("ê³µì¢…ëª…"),

                "í˜„ì¥ì½”ë“œ": st.column_config.TextColumn("í˜„ì¥ì½”ë“œ"),
                "í˜„ì¥ëª…": st.column_config.TextColumn("í˜„ì¥ëª…"),

                "í˜‘ë ¥ì‚¬ì½”ë“œ": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ì½”ë“œ"),
                "í˜‘ë ¥ì‚¬ëª…": st.column_config.TextColumn("í˜‘ë ¥ì‚¬ëª…"),
            },
            # âœ… Includeë§Œ í¸ì§‘ ê°€ëŠ¥
            disabled=[c for c in log_view.columns if c not in ["Include"]],
            key="log_editor",
        )

        # -------------------------
        # âœ… í¸ì§‘ ë°˜ì˜: ì›ë³¸(log_all)ì˜ Includeë§Œ ì—…ë°ì´íŠ¸
        # -------------------------
        log_all_updated = log_all.copy()
        mask = log_all_updated["BOQ_ID"].astype(int) == int(sel_id)

        # í–‰ìˆ˜ ë¶ˆì¼ì¹˜ ë°©ì§€(ì•ˆì „)
        if mask.sum() == len(edited_view):
            log_all_updated.loc[mask, "Include"] = edited_view["Include"].values
            st.session_state["log_df_edited"] = log_all_updated

            # í¸ì§‘ ì¦‰ì‹œ ê²°ê³¼ ì¬ê³„ì‚°
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
        else:
            st.warning("ë¡œê·¸ í–‰ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ Include ë°˜ì˜ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")

        # BOQ_ID ë‹¨ìœ„ë¡œ Includeë§Œ ë°˜ì˜
        log_all_updated = log_all.copy()
        mask = log_all_updated["BOQ_ID"].astype(int) == int(sel_id)

        # í–‰ìˆ˜ ë¶ˆì¼ì¹˜ ë°©ì§€(ì•ˆì „)
        if mask.sum() == len(edited_view):
            log_all_updated.loc[mask, "Include"] = edited_view["Include"].values
            st.session_state["log_df_edited"] = log_all_updated

            # í¸ì§‘ ì¦‰ì‹œ ê²°ê³¼ ì¬ê³„ì‚°
            st.session_state["result_df_adjusted"] = recompute_result_from_log(st.session_state["log_df_edited"])
        else:
            st.warning("ë¡œê·¸ í–‰ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ Include ë°˜ì˜ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")

    with tab1:
        show_df = st.session_state.get("result_df_adjusted", result_df).copy()
        if "í†µí™”" in show_df.columns:
            show_df = show_df.drop(columns=["í†µí™”"])
        st.dataframe(show_df, use_container_width=True)

    # ë‹¤ìš´ë¡œë“œë„ ì¡°ì •ê°’ ê¸°ì¤€
    out_result = st.session_state.get("result_df_adjusted", result_df).copy()
    out_log = st.session_state.get("log_df_edited", log_df).copy()

    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        out_result.to_excel(writer, index=False, sheet_name="boq_with_price")
        out_log.to_excel(writer, index=False, sheet_name="calculation_log")
    bio.seek(0)
    st.download_button("â¬‡ï¸ Excel ë‹¤ìš´ë¡œë“œ", data=bio.read(), file_name="result_unitrate.xlsx")












